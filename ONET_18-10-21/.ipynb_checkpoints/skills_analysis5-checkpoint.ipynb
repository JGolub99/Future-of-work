{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e133cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  O*NET-SOC Code             Title Element ID           Element Name  \\\n",
      "0     11-1011.00  Chief Executives    2.A.1.a  Reading Comprehension   \n",
      "1     11-1011.00  Chief Executives    2.A.1.b       Active Listening   \n",
      "2     11-1011.00  Chief Executives    2.A.1.c                Writing   \n",
      "3     11-1011.00  Chief Executives    2.A.1.d               Speaking   \n",
      "4     11-1011.00  Chief Executives    2.A.1.e            Mathematics   \n",
      "\n",
      "   Data Value  Standard Error  Lower CI Bound  Upper CI Bound  \n",
      "0        4.75            0.16            4.43            5.07  \n",
      "1        4.88            0.23            4.43            5.32  \n",
      "2        4.38            0.18            4.02            4.73  \n",
      "3        4.88            0.13            4.63            5.12  \n",
      "4        3.62            0.26            3.11            4.14  \n"
     ]
    }
   ],
   "source": [
    "''' This version implements GPy to find the optimum hyperparameters '''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"Skills.xlsx\")\n",
    "#print(df.head())\n",
    "\n",
    "#Lets remove the importance values:\n",
    "\n",
    "df2 = df.loc[df[\"Scale Name\"] == \"Level\"]\n",
    "df2.reset_index(drop = True, inplace = True)\n",
    "#print(df2.head())\n",
    "\n",
    "#Lets now remove the irrelevent columns:\n",
    "\n",
    "df3 = df2.drop(columns = [\"Scale ID\",\"Scale Name\",\"N\",\"Recommend Suppress\",\"Not Relevant\",\"Date\",\"Domain Source\"])\n",
    "print(df3.head())\n",
    "\n",
    "#NOTE that we have ignored the suppress recomendations, we shall continue with this for now but will need to address this later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "420df498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30555 entries, 0 to 30554\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   O*NET-SOC Code  30555 non-null  object \n",
      " 1   Title           30555 non-null  object \n",
      " 2   Element ID      30555 non-null  object \n",
      " 3   Element Name    30555 non-null  object \n",
      " 4   Data Value      30555 non-null  float64\n",
      " 5   Standard Error  28700 non-null  float64\n",
      " 6   Lower CI Bound  28700 non-null  float64\n",
      " 7   Upper CI Bound  28700 non-null  float64\n",
      "dtypes: float64(4), object(4)\n",
      "memory usage: 1.9+ MB\n",
      "  O*NET-SOC Code             Title Element ID           Element Name  \\\n",
      "0     11-1011.00  Chief Executives    2.A.1.a  Reading Comprehension   \n",
      "1     11-1011.00  Chief Executives    2.A.1.b       Active Listening   \n",
      "2     11-1011.00  Chief Executives    2.A.1.c                Writing   \n",
      "3     11-1011.00  Chief Executives    2.A.1.d               Speaking   \n",
      "4     11-1011.00  Chief Executives    2.A.1.e            Mathematics   \n",
      "\n",
      "   Data Value  \n",
      "0        4.75  \n",
      "1        4.88  \n",
      "2        4.38  \n",
      "3        4.88  \n",
      "4        3.62  \n"
     ]
    }
   ],
   "source": [
    "#Lets now discover a bit about our data set:\n",
    "\n",
    "df3.info()\n",
    "\n",
    "#We note that there are some occupations for which the standard error and bound values are missing. Lets supress these for now:\n",
    "\n",
    "df3.drop(columns = [\"Standard Error\",\"Lower CI Bound\",\"Upper CI Bound\"],inplace = True)\n",
    "print(df3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55a1537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-398803c0bc0e>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4.drop_duplicates(inplace=True)\n",
      "<ipython-input-3-398803c0bc0e>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4[df3[\"Element Name\"][i]] = \"\"\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3437: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#I shall implement the drop_duplicates method:\n",
    "\n",
    "df4 = df3[[\"O*NET-SOC Code\",\"Title\"]]\n",
    "df4.drop_duplicates(inplace=True)\n",
    "df4.reset_index(drop = True, inplace = True)\n",
    "#print(df4.head())\n",
    "\n",
    "#We now need to add the variables. Begin by adding empty columns to the dataframe:\n",
    "\n",
    "n_jobs = len(set((df3[\"Title\"])))\n",
    "n_variables = len(set((df3[\"Element Name\"])))\n",
    "\n",
    "for i in range(n_jobs):\n",
    "    df4[df3[\"Element Name\"][i]] = \"\"\n",
    "\n",
    "#print(df4.head())\n",
    "#Now we need to fill these columns:\n",
    "\n",
    "x = df3.loc[df3[\"Title\"] == \"Chief Executives\"]\n",
    "y = x[\"Data Value\"]\n",
    "\n",
    "for i in range(n_variables):\n",
    "    df4[df4.columns[2+i]][0] = y[i]\n",
    "    \n",
    "#We now need to do this procedure for every job:\n",
    "\n",
    "for j in range(n_jobs):\n",
    "    x = df3.loc[df3[\"Title\"] == df4.iloc[j,1]]\n",
    "    y = x[\"Data Value\"]\n",
    "    y.reset_index(drop = True, inplace = True)\n",
    "    for i in range(n_variables):\n",
    "        df4[df4.columns[2+i]][j] = y[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0748248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  O*NET-SOC Code                                Title Reading Comprehension  \\\n",
      "0     11-1011.00                     Chief Executives                  4.75   \n",
      "1     11-1011.03        Chief Sustainability Officers                  4.25   \n",
      "2     11-1021.00      General and Operations Managers                   4.0   \n",
      "3     11-2011.00  Advertising and Promotions Managers                   4.0   \n",
      "4     11-2021.00                   Marketing Managers                  4.25   \n",
      "\n",
      "  Active Listening Writing Speaking Mathematics Science Critical Thinking  \\\n",
      "0             4.88    4.38     4.88        3.62    1.12              4.75   \n",
      "1              4.0    4.25     4.12        3.12    1.88              4.12   \n",
      "2              4.0    3.88      4.0         2.5    1.12               4.0   \n",
      "3             4.12    3.88     4.12        3.25    0.62              4.12   \n",
      "4             4.12    3.88     4.12        3.12     1.5              4.25   \n",
      "\n",
      "  Active Learning  ... Troubleshooting Repairing Quality Control Analysis  \\\n",
      "0            4.75  ...             0.0       0.0                      1.0   \n",
      "1            3.88  ...             0.0       0.0                      1.5   \n",
      "2            3.62  ...            1.38       0.0                     2.12   \n",
      "3            4.12  ...             0.0       0.0                      1.0   \n",
      "4            4.12  ...             0.0       0.0                     1.38   \n",
      "\n",
      "  Judgment and Decision Making Systems Analysis Systems Evaluation  \\\n",
      "0                         5.75             5.38               5.12   \n",
      "1                          4.0              4.0                4.0   \n",
      "2                         3.75              3.0               3.12   \n",
      "3                          4.0             3.12               3.75   \n",
      "4                          4.0             3.75               3.75   \n",
      "\n",
      "  Time Management Management of Financial Resources  \\\n",
      "0            4.75                               5.5   \n",
      "1            3.88                              3.12   \n",
      "2            3.75                              3.38   \n",
      "3            3.88                              3.62   \n",
      "4            3.75                              3.75   \n",
      "\n",
      "  Management of Material Resources Management of Personnel Resources  \n",
      "0                             4.75                              5.38  \n",
      "1                             2.62                               4.0  \n",
      "2                             3.25                              3.88  \n",
      "3                             2.62                              3.88  \n",
      "4                             2.75                              3.88  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "    O*NET-SOC Code                                             Title  \\\n",
      "868     53-7071.00  Gas Compressor and Gas Pumping Station Operators   \n",
      "869     53-7072.00           Pump Operators, Except Wellhead Pumpers   \n",
      "870     53-7073.00                                  Wellhead Pumpers   \n",
      "871     53-7081.00         Refuse and Recyclable Material Collectors   \n",
      "872     53-7121.00                 Tank Car, Truck, and Ship Loaders   \n",
      "\n",
      "    Reading Comprehension Active Listening Writing Speaking Mathematics  \\\n",
      "868                  3.12              3.0    2.88      3.0        2.12   \n",
      "869                   3.0              3.0    2.75     2.88        2.62   \n",
      "870                  2.88             2.75    2.12      3.0        1.62   \n",
      "871                  2.38             2.62    2.38     2.25         0.5   \n",
      "872                  3.12              3.0    2.75     2.88        2.12   \n",
      "\n",
      "    Science Critical Thinking Active Learning  ... Troubleshooting Repairing  \\\n",
      "868    1.25               3.0            2.38  ...            3.12       3.0   \n",
      "869    1.38              3.12            2.88  ...            2.88      2.75   \n",
      "870    0.12               3.0            2.12  ...             3.0      3.75   \n",
      "871     0.0               3.0             2.0  ...            2.12      2.12   \n",
      "872    0.75              2.88            2.75  ...             2.5      2.25   \n",
      "\n",
      "    Quality Control Analysis Judgment and Decision Making Systems Analysis  \\\n",
      "868                      3.0                         2.75             2.38   \n",
      "869                     2.75                          3.0             2.12   \n",
      "870                      2.5                         2.88             1.38   \n",
      "871                     2.25                         2.12              2.0   \n",
      "872                     2.88                         2.88             2.62   \n",
      "\n",
      "    Systems Evaluation Time Management Management of Financial Resources  \\\n",
      "868               2.12            2.75                              0.75   \n",
      "869               2.12            2.88                              1.12   \n",
      "870               1.38            2.75                              0.38   \n",
      "871               1.88            2.75                              0.25   \n",
      "872               2.12            2.88                              1.12   \n",
      "\n",
      "    Management of Material Resources Management of Personnel Resources  \n",
      "868                             1.25                              2.12  \n",
      "869                             1.75                              2.25  \n",
      "870                             0.88                               2.0  \n",
      "871                             0.38                               2.0  \n",
      "872                             1.88                              2.75  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df4.head())\n",
    "print(df4.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194be949",
   "metadata": {},
   "source": [
    "### We now have the skills dataframe just as we want it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edae9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets understand our data a bit:\n",
    "\n",
    "df4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb3b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "hist = df4.iloc[:,20].hist(bins=20)\n",
    "\n",
    "#We can inspect the histogram of any variable we want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3628f6e5",
   "metadata": {},
   "source": [
    "### Let's now  import another dataframe with autovalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87641e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Occupation Name BLS codes  \\\n",
      "0                            Recreational Therapists  29-1125_   \n",
      "1  First-Line Supervisors of Mechanics Installers...  49-1011_   \n",
      "2                     Emergency Management Directors  11-9161_   \n",
      "3   Mental Health and Substance Abuse Social Workers  21-1023_   \n",
      "4                                       Audiologists  29-1181_   \n",
      "\n",
      "   Training set automatable labels  \n",
      "0                              NaN  \n",
      "1                              NaN  \n",
      "2                              NaN  \n",
      "3                              NaN  \n",
      "4                              NaN  \n"
     ]
    }
   ],
   "source": [
    "df5 = pd.read_excel(\"US_data_email.xls\")\n",
    "df5 = df5[[\"Occupation Name\",\"BLS codes\",\"Training set automatable labels\"]]\n",
    "print(df5.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40868f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 702 entries, 0 to 701\n",
      "Data columns (total 3 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Occupation Name                  702 non-null    object \n",
      " 1   BLS codes                        702 non-null    object \n",
      " 2   Training set automatable labels  70 non-null     float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 16.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "422495f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Occupation Name   BLS codes  \\\n",
      "0                            Recreational Therapists  29-1125.00   \n",
      "1  First-Line Supervisors of Mechanics Installers...  49-1011.00   \n",
      "2                     Emergency Management Directors  11-9161.00   \n",
      "3   Mental Health and Substance Abuse Social Workers  21-1023.00   \n",
      "4                                       Audiologists  29-1181.00   \n",
      "\n",
      "   Training set automatable labels  \n",
      "0                              NaN  \n",
      "1                              NaN  \n",
      "2                              NaN  \n",
      "3                              NaN  \n",
      "4                              NaN  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 702 entries, 0 to 701\n",
      "Data columns (total 3 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Occupation Name                  702 non-null    object \n",
      " 1   BLS codes                        702 non-null    object \n",
      " 2   Training set automatable labels  70 non-null     float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 16.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#Lets define a function so that we can make occupation ID's consistent:\n",
    "\n",
    "def title_set(my_string):\n",
    "    my_list = []\n",
    "    my_list[:0] = my_string\n",
    "    my_list.remove(\"_\")\n",
    "    my_list.append(\".00\")\n",
    "    my_output = \"\".join(my_list)\n",
    "    return my_output\n",
    "\n",
    "#print(title_set(\"45-4023_\"))\n",
    "\n",
    "df5.iloc[:,1] = df5.iloc[:,1].apply(title_set)\n",
    "print(df5.head())\n",
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88670d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-27a20ac659ae>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4[\"Auto label value\"] = np.nan\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1700: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, v, pi)\n"
     ]
    }
   ],
   "source": [
    "#Lets now concatenate the auto labels to our 1st dataframe:\n",
    "import numpy as np\n",
    "df4[\"Auto label value\"] = np.nan\n",
    "for i in list(df5[\"BLS codes\"]):\n",
    "    df4.loc[df4[\"O*NET-SOC Code\"] == i,\"Auto label value\"] = list(df5.loc[df5[\"BLS codes\"] == i,\"Training set automatable labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f37d0dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 873 entries, 0 to 872\n",
      "Data columns (total 38 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   O*NET-SOC Code                     873 non-null    object \n",
      " 1   Title                              873 non-null    object \n",
      " 2   Reading Comprehension              873 non-null    object \n",
      " 3   Active Listening                   873 non-null    object \n",
      " 4   Writing                            873 non-null    object \n",
      " 5   Speaking                           873 non-null    object \n",
      " 6   Mathematics                        873 non-null    object \n",
      " 7   Science                            873 non-null    object \n",
      " 8   Critical Thinking                  873 non-null    object \n",
      " 9   Active Learning                    873 non-null    object \n",
      " 10  Learning Strategies                873 non-null    object \n",
      " 11  Monitoring                         873 non-null    object \n",
      " 12  Social Perceptiveness              873 non-null    object \n",
      " 13  Coordination                       873 non-null    object \n",
      " 14  Persuasion                         873 non-null    object \n",
      " 15  Negotiation                        873 non-null    object \n",
      " 16  Instructing                        873 non-null    object \n",
      " 17  Service Orientation                873 non-null    object \n",
      " 18  Complex Problem Solving            873 non-null    object \n",
      " 19  Operations Analysis                873 non-null    object \n",
      " 20  Technology Design                  873 non-null    object \n",
      " 21  Equipment Selection                873 non-null    object \n",
      " 22  Installation                       873 non-null    object \n",
      " 23  Programming                        873 non-null    object \n",
      " 24  Operations Monitoring              873 non-null    object \n",
      " 25  Operation and Control              873 non-null    object \n",
      " 26  Equipment Maintenance              873 non-null    object \n",
      " 27  Troubleshooting                    873 non-null    object \n",
      " 28  Repairing                          873 non-null    object \n",
      " 29  Quality Control Analysis           873 non-null    object \n",
      " 30  Judgment and Decision Making       873 non-null    object \n",
      " 31  Systems Analysis                   873 non-null    object \n",
      " 32  Systems Evaluation                 873 non-null    object \n",
      " 33  Time Management                    873 non-null    object \n",
      " 34  Management of Financial Resources  873 non-null    object \n",
      " 35  Management of Material Resources   873 non-null    object \n",
      " 36  Management of Personnel Resources  873 non-null    object \n",
      " 37  Auto label value                   63 non-null     float64\n",
      "dtypes: float64(1), object(37)\n",
      "memory usage: 259.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df4.info()\n",
    "\n",
    "#Note - the auto value count is supposedly 330 non-null, even though it should be 70. After creating a csv from the dataframe,\n",
    "#I found that there were 70 non-null as expected. Worth bringing up with Mike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv(\"test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e2d9a8",
   "metadata": {},
   "source": [
    "### We now have a dataset which encompass jobs titles, SOC codes, skill levels and hand picked auto labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d2e87",
   "metadata": {},
   "source": [
    "### Lets now split and standardize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc1e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To prevent information about the distribution of the test set leaking into the model, we shall first form a training set\n",
    "# and form a scaler operator from this, and then apply this to both training and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0fc4bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63 entries, 0 to 62\n",
      "Data columns (total 38 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   O*NET-SOC Code                     63 non-null     object \n",
      " 1   Title                              63 non-null     object \n",
      " 2   Reading Comprehension              63 non-null     object \n",
      " 3   Active Listening                   63 non-null     object \n",
      " 4   Writing                            63 non-null     object \n",
      " 5   Speaking                           63 non-null     object \n",
      " 6   Mathematics                        63 non-null     object \n",
      " 7   Science                            63 non-null     object \n",
      " 8   Critical Thinking                  63 non-null     object \n",
      " 9   Active Learning                    63 non-null     object \n",
      " 10  Learning Strategies                63 non-null     object \n",
      " 11  Monitoring                         63 non-null     object \n",
      " 12  Social Perceptiveness              63 non-null     object \n",
      " 13  Coordination                       63 non-null     object \n",
      " 14  Persuasion                         63 non-null     object \n",
      " 15  Negotiation                        63 non-null     object \n",
      " 16  Instructing                        63 non-null     object \n",
      " 17  Service Orientation                63 non-null     object \n",
      " 18  Complex Problem Solving            63 non-null     object \n",
      " 19  Operations Analysis                63 non-null     object \n",
      " 20  Technology Design                  63 non-null     object \n",
      " 21  Equipment Selection                63 non-null     object \n",
      " 22  Installation                       63 non-null     object \n",
      " 23  Programming                        63 non-null     object \n",
      " 24  Operations Monitoring              63 non-null     object \n",
      " 25  Operation and Control              63 non-null     object \n",
      " 26  Equipment Maintenance              63 non-null     object \n",
      " 27  Troubleshooting                    63 non-null     object \n",
      " 28  Repairing                          63 non-null     object \n",
      " 29  Quality Control Analysis           63 non-null     object \n",
      " 30  Judgment and Decision Making       63 non-null     object \n",
      " 31  Systems Analysis                   63 non-null     object \n",
      " 32  Systems Evaluation                 63 non-null     object \n",
      " 33  Time Management                    63 non-null     object \n",
      " 34  Management of Financial Resources  63 non-null     object \n",
      " 35  Management of Material Resources   63 non-null     object \n",
      " 36  Management of Personnel Resources  63 non-null     object \n",
      " 37  Auto label value                   63 non-null     float64\n",
      "dtypes: float64(1), object(37)\n",
      "memory usage: 18.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Lets now create a training set which includes only the jobs for which we have hand picked auto values:\n",
    "\n",
    "training_set = df4.dropna(axis=0,how=\"any\")\n",
    "training_set.reset_index(drop = True, inplace=True)\n",
    "#print(training_set.head())\n",
    "training_set.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c955b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets apply stratified sampling on this set to create a training and test set\n",
    "#Code taken from Hands on Machine Learning book\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "for train_index, test_index in split.split(training_set,training_set[\"Auto label value\"]):\n",
    "    strat_train_set = training_set.loc[train_index]\n",
    "    strat_test_set = training_set.loc[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04871038",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.reset_index(drop=True,inplace=True)\n",
    "strat_test_set.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7615f630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.54\n",
       "0.0    0.46\n",
       "Name: Auto label value, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set[\"Auto label value\"].value_counts()/len(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4985df74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Now that we have our training set, lets create a standardiser for it:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=True,with_std=True)\n",
    "scaler.fit(strat_train_set.iloc[:,2:37])\n",
    "scaled_training_values = scaler.transform(strat_train_set.iloc[:,2:37])\n",
    "scaled_test_values = scaler.transform(strat_test_set.iloc[:,2:37])\n",
    "scaled_train_set = strat_train_set.copy()\n",
    "scaled_test_set = strat_test_set.copy()\n",
    "#print(strat_train_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85fb4ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary = pd.DataFrame(data=scaled_training_values)\n",
    "temporary2 = pd.DataFrame(data=scaled_test_values) #we create temporary data frames from the numpy arrays we've just created\n",
    "#print(temporary)\n",
    "for i in range(2,37):\n",
    "    scaled_train_set[scaled_train_set.columns[i]] = temporary[temporary.columns[i-2]]\n",
    "    scaled_test_set[scaled_test_set.columns[i]] = temporary2[temporary2.columns[i-2]]\n",
    "\n",
    "#print(scaled_test_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0efe1133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Reading Comprehension</th>\n",
       "      <th>Active Listening</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Speaking</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Science</th>\n",
       "      <th>Critical Thinking</th>\n",
       "      <th>Active Learning</th>\n",
       "      <th>...</th>\n",
       "      <th>Repairing</th>\n",
       "      <th>Quality Control Analysis</th>\n",
       "      <th>Judgment and Decision Making</th>\n",
       "      <th>Systems Analysis</th>\n",
       "      <th>Systems Evaluation</th>\n",
       "      <th>Time Management</th>\n",
       "      <th>Management of Financial Resources</th>\n",
       "      <th>Management of Material Resources</th>\n",
       "      <th>Management of Personnel Resources</th>\n",
       "      <th>Auto label value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>1.416147</td>\n",
       "      <td>1.658374</td>\n",
       "      <td>1.365633</td>\n",
       "      <td>1.917195</td>\n",
       "      <td>1.261042</td>\n",
       "      <td>0.220817</td>\n",
       "      <td>1.625616</td>\n",
       "      <td>1.970645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.462245</td>\n",
       "      <td>-0.559854</td>\n",
       "      <td>3.198755</td>\n",
       "      <td>3.231506</td>\n",
       "      <td>2.796083</td>\n",
       "      <td>3.000691</td>\n",
       "      <td>3.518175</td>\n",
       "      <td>3.370579</td>\n",
       "      <td>3.269982</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-3071.00</td>\n",
       "      <td>Transportation, Storage, and Distribution Mana...</td>\n",
       "      <td>0.471545</td>\n",
       "      <td>0.428166</td>\n",
       "      <td>0.442029</td>\n",
       "      <td>0.640730</td>\n",
       "      <td>0.757520</td>\n",
       "      <td>-0.360280</td>\n",
       "      <td>0.700087</td>\n",
       "      <td>0.603361</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.360652</td>\n",
       "      <td>0.576425</td>\n",
       "      <td>0.525771</td>\n",
       "      <td>1.025229</td>\n",
       "      <td>1.216929</td>\n",
       "      <td>1.436145</td>\n",
       "      <td>1.634337</td>\n",
       "      <td>1.785321</td>\n",
       "      <td>1.403902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-9031.00</td>\n",
       "      <td>Education and Childcare Administrators, Presch...</td>\n",
       "      <td>0.622682</td>\n",
       "      <td>0.481653</td>\n",
       "      <td>0.871310</td>\n",
       "      <td>0.696228</td>\n",
       "      <td>0.433029</td>\n",
       "      <td>-0.104950</td>\n",
       "      <td>0.589576</td>\n",
       "      <td>0.879327</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.462245</td>\n",
       "      <td>0.327864</td>\n",
       "      <td>0.840981</td>\n",
       "      <td>0.634534</td>\n",
       "      <td>0.901098</td>\n",
       "      <td>1.436145</td>\n",
       "      <td>1.564887</td>\n",
       "      <td>1.735155</td>\n",
       "      <td>1.650365</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-9151.00</td>\n",
       "      <td>Social and Community Service Managers</td>\n",
       "      <td>0.622682</td>\n",
       "      <td>0.815949</td>\n",
       "      <td>0.871310</td>\n",
       "      <td>0.862724</td>\n",
       "      <td>0.701574</td>\n",
       "      <td>0.995613</td>\n",
       "      <td>0.755342</td>\n",
       "      <td>0.879327</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.462245</td>\n",
       "      <td>0.173993</td>\n",
       "      <td>1.143583</td>\n",
       "      <td>1.358469</td>\n",
       "      <td>1.445634</td>\n",
       "      <td>1.651944</td>\n",
       "      <td>1.452030</td>\n",
       "      <td>0.992692</td>\n",
       "      <td>2.096347</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13-1031.00</td>\n",
       "      <td>Claims Adjusters, Examiners, and Investigators</td>\n",
       "      <td>0.547113</td>\n",
       "      <td>0.401422</td>\n",
       "      <td>0.546097</td>\n",
       "      <td>0.529733</td>\n",
       "      <td>0.634437</td>\n",
       "      <td>-0.377889</td>\n",
       "      <td>0.589576</td>\n",
       "      <td>0.164325</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.462245</td>\n",
       "      <td>0.398881</td>\n",
       "      <td>0.513163</td>\n",
       "      <td>-0.146855</td>\n",
       "      <td>-0.122629</td>\n",
       "      <td>-0.254284</td>\n",
       "      <td>0.644672</td>\n",
       "      <td>0.169964</td>\n",
       "      <td>-0.403496</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>53-2031.00</td>\n",
       "      <td>Flight Attendants</td>\n",
       "      <td>-0.158189</td>\n",
       "      <td>-0.521234</td>\n",
       "      <td>-0.585643</td>\n",
       "      <td>0.349363</td>\n",
       "      <td>-0.685909</td>\n",
       "      <td>-0.325062</td>\n",
       "      <td>0.064649</td>\n",
       "      <td>-0.224536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.462245</td>\n",
       "      <td>0.765805</td>\n",
       "      <td>-0.419860</td>\n",
       "      <td>-0.790353</td>\n",
       "      <td>-0.732510</td>\n",
       "      <td>-0.146384</td>\n",
       "      <td>-0.388400</td>\n",
       "      <td>-0.271500</td>\n",
       "      <td>-0.403496</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>53-3033.00</td>\n",
       "      <td>Light Truck Drivers</td>\n",
       "      <td>-1.102791</td>\n",
       "      <td>-1.015992</td>\n",
       "      <td>-1.079967</td>\n",
       "      <td>-1.038099</td>\n",
       "      <td>-0.417364</td>\n",
       "      <td>-0.659633</td>\n",
       "      <td>-0.957578</td>\n",
       "      <td>-1.328398</td>\n",
       "      <td>...</td>\n",
       "      <td>2.077561</td>\n",
       "      <td>0.919676</td>\n",
       "      <td>-1.378100</td>\n",
       "      <td>-1.364904</td>\n",
       "      <td>-1.418625</td>\n",
       "      <td>-0.362183</td>\n",
       "      <td>-0.284225</td>\n",
       "      <td>-0.271500</td>\n",
       "      <td>-1.142886</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>53-5022.00</td>\n",
       "      <td>Motorboat Operators</td>\n",
       "      <td>-1.102791</td>\n",
       "      <td>-1.189825</td>\n",
       "      <td>-0.923864</td>\n",
       "      <td>-0.857729</td>\n",
       "      <td>-0.551636</td>\n",
       "      <td>0.449734</td>\n",
       "      <td>-0.266884</td>\n",
       "      <td>-0.538133</td>\n",
       "      <td>...</td>\n",
       "      <td>3.029988</td>\n",
       "      <td>1.807394</td>\n",
       "      <td>-0.117258</td>\n",
       "      <td>-0.514568</td>\n",
       "      <td>-0.471132</td>\n",
       "      <td>-0.362183</td>\n",
       "      <td>-0.284225</td>\n",
       "      <td>-0.141068</td>\n",
       "      <td>0.335894</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>53-6021.00</td>\n",
       "      <td>Parking Attendants</td>\n",
       "      <td>-2.198529</td>\n",
       "      <td>-1.189825</td>\n",
       "      <td>-1.730392</td>\n",
       "      <td>-1.551460</td>\n",
       "      <td>-0.271902</td>\n",
       "      <td>-0.765287</td>\n",
       "      <td>-1.137158</td>\n",
       "      <td>-1.792522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144769</td>\n",
       "      <td>-0.263948</td>\n",
       "      <td>-1.050281</td>\n",
       "      <td>-1.089119</td>\n",
       "      <td>-0.874089</td>\n",
       "      <td>-1.944712</td>\n",
       "      <td>-0.605432</td>\n",
       "      <td>-0.642732</td>\n",
       "      <td>-0.990313</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>53-7051.00</td>\n",
       "      <td>Industrial Truck and Tractor Operators</td>\n",
       "      <td>-1.417659</td>\n",
       "      <td>-1.524121</td>\n",
       "      <td>-1.574290</td>\n",
       "      <td>-2.078696</td>\n",
       "      <td>-0.685909</td>\n",
       "      <td>-0.545174</td>\n",
       "      <td>-1.827851</td>\n",
       "      <td>-1.629452</td>\n",
       "      <td>...</td>\n",
       "      <td>2.077561</td>\n",
       "      <td>0.481735</td>\n",
       "      <td>-1.378100</td>\n",
       "      <td>-0.939736</td>\n",
       "      <td>-0.874089</td>\n",
       "      <td>-1.495130</td>\n",
       "      <td>-0.492576</td>\n",
       "      <td>-0.512299</td>\n",
       "      <td>-1.283722</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   O*NET-SOC Code                                              Title  \\\n",
       "0      11-1011.00                                   Chief Executives   \n",
       "1      11-3071.00  Transportation, Storage, and Distribution Mana...   \n",
       "2      11-9031.00  Education and Childcare Administrators, Presch...   \n",
       "3      11-9151.00              Social and Community Service Managers   \n",
       "4      13-1031.00     Claims Adjusters, Examiners, and Investigators   \n",
       "..            ...                                                ...   \n",
       "58     53-2031.00                                  Flight Attendants   \n",
       "59     53-3033.00                                Light Truck Drivers   \n",
       "60     53-5022.00                                Motorboat Operators   \n",
       "61     53-6021.00                                 Parking Attendants   \n",
       "62     53-7051.00             Industrial Truck and Tractor Operators   \n",
       "\n",
       "    Reading Comprehension  Active Listening   Writing  Speaking  Mathematics  \\\n",
       "0                1.416147          1.658374  1.365633  1.917195     1.261042   \n",
       "1                0.471545          0.428166  0.442029  0.640730     0.757520   \n",
       "2                0.622682          0.481653  0.871310  0.696228     0.433029   \n",
       "3                0.622682          0.815949  0.871310  0.862724     0.701574   \n",
       "4                0.547113          0.401422  0.546097  0.529733     0.634437   \n",
       "..                    ...               ...       ...       ...          ...   \n",
       "58              -0.158189         -0.521234 -0.585643  0.349363    -0.685909   \n",
       "59              -1.102791         -1.015992 -1.079967 -1.038099    -0.417364   \n",
       "60              -1.102791         -1.189825 -0.923864 -0.857729    -0.551636   \n",
       "61              -2.198529         -1.189825 -1.730392 -1.551460    -0.271902   \n",
       "62              -1.417659         -1.524121 -1.574290 -2.078696    -0.685909   \n",
       "\n",
       "     Science  Critical Thinking  Active Learning  ...  Repairing  \\\n",
       "0   0.220817           1.625616         1.970645  ...  -0.462245   \n",
       "1  -0.360280           0.700087         0.603361  ...  -0.360652   \n",
       "2  -0.104950           0.589576         0.879327  ...  -0.462245   \n",
       "3   0.995613           0.755342         0.879327  ...  -0.462245   \n",
       "4  -0.377889           0.589576         0.164325  ...  -0.462245   \n",
       "..       ...                ...              ...  ...        ...   \n",
       "58 -0.325062           0.064649        -0.224536  ...  -0.462245   \n",
       "59 -0.659633          -0.957578        -1.328398  ...   2.077561   \n",
       "60  0.449734          -0.266884        -0.538133  ...   3.029988   \n",
       "61 -0.765287          -1.137158        -1.792522  ...  -0.144769   \n",
       "62 -0.545174          -1.827851        -1.629452  ...   2.077561   \n",
       "\n",
       "    Quality Control Analysis  Judgment and Decision Making  Systems Analysis  \\\n",
       "0                  -0.559854                      3.198755          3.231506   \n",
       "1                   0.576425                      0.525771          1.025229   \n",
       "2                   0.327864                      0.840981          0.634534   \n",
       "3                   0.173993                      1.143583          1.358469   \n",
       "4                   0.398881                      0.513163         -0.146855   \n",
       "..                       ...                           ...               ...   \n",
       "58                  0.765805                     -0.419860         -0.790353   \n",
       "59                  0.919676                     -1.378100         -1.364904   \n",
       "60                  1.807394                     -0.117258         -0.514568   \n",
       "61                 -0.263948                     -1.050281         -1.089119   \n",
       "62                  0.481735                     -1.378100         -0.939736   \n",
       "\n",
       "    Systems Evaluation  Time Management  Management of Financial Resources  \\\n",
       "0             2.796083         3.000691                           3.518175   \n",
       "1             1.216929         1.436145                           1.634337   \n",
       "2             0.901098         1.436145                           1.564887   \n",
       "3             1.445634         1.651944                           1.452030   \n",
       "4            -0.122629        -0.254284                           0.644672   \n",
       "..                 ...              ...                                ...   \n",
       "58           -0.732510        -0.146384                          -0.388400   \n",
       "59           -1.418625        -0.362183                          -0.284225   \n",
       "60           -0.471132        -0.362183                          -0.284225   \n",
       "61           -0.874089        -1.944712                          -0.605432   \n",
       "62           -0.874089        -1.495130                          -0.492576   \n",
       "\n",
       "    Management of Material Resources  Management of Personnel Resources  \\\n",
       "0                           3.370579                           3.269982   \n",
       "1                           1.785321                           1.403902   \n",
       "2                           1.735155                           1.650365   \n",
       "3                           0.992692                           2.096347   \n",
       "4                           0.169964                          -0.403496   \n",
       "..                               ...                                ...   \n",
       "58                         -0.271500                          -0.403496   \n",
       "59                         -0.271500                          -1.142886   \n",
       "60                         -0.141068                           0.335894   \n",
       "61                         -0.642732                          -0.990313   \n",
       "62                         -0.512299                          -1.283722   \n",
       "\n",
       "    Auto label value  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                1.0  \n",
       "..               ...  \n",
       "58               0.0  \n",
       "59               1.0  \n",
       "60               1.0  \n",
       "61               1.0  \n",
       "62               1.0  \n",
       "\n",
       "[63 rows x 38 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' We shall also create a standardized set for ALL of the training data '''\n",
    "\n",
    "scaler2 = StandardScaler(with_mean=True,with_std=True)\n",
    "scaler2.fit(strat_train_set.iloc[:,2:37])\n",
    "scaled_total_values = scaler2.transform(training_set.iloc[:,2:37])\n",
    "scaled_total_set = training_set.copy()\n",
    "\n",
    "temporary3 = pd.DataFrame(data=scaled_total_values)\n",
    "for i in range(2,37):\n",
    "    scaled_total_set[scaled_total_set.columns[i]] = temporary3[temporary3.columns[i-2]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d735dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  O*NET-SOC Code                                              Title  \\\n",
      "0     13-2081.00   Tax Examiners and Collectors, and Revenue Agents   \n",
      "1     19-1023.00                 Zoologists and Wildlife Biologists   \n",
      "2     43-2011.00  Switchboard Operators, Including Answering Ser...   \n",
      "3     35-9021.00                                        Dishwashers   \n",
      "4     23-1023.00         Judges, Magistrate Judges, and Magistrates   \n",
      "\n",
      "   Reading Comprehension  Active Listening   Writing  Speaking  Mathematics  \\\n",
      "0               0.622682          0.481653 -0.104328  0.349363     0.847035   \n",
      "1               1.252416          0.481653  1.196523  0.529733     0.567301   \n",
      "2              -0.787924         -0.855530 -1.236069 -1.038099    -1.245377   \n",
      "3              -1.896257         -1.858417 -2.055605 -1.912200    -1.670573   \n",
      "4               1.416147          2.995557  2.016059  1.917195    -0.417364   \n",
      "\n",
      "    Science  Critical Thinking  Active Learning  ...  Repairing  \\\n",
      "0 -0.765287           0.064649         0.553186  ...  -0.462245   \n",
      "1  2.650858           0.755342         0.716256  ...  -0.462245   \n",
      "2 -0.765287          -1.137158        -1.165328  ...  -0.462245   \n",
      "3 -0.765287          -2.007432        -1.478925  ...   2.077561   \n",
      "4  0.449734           3.007003         1.807575  ...  -0.462245   \n",
      "\n",
      "   Quality Control Analysis  Judgment and Decision Making  Systems Analysis  \\\n",
      "0                 -0.417819                      0.210561         -0.215801   \n",
      "1                  0.765805                      0.840981          1.071193   \n",
      "2                 -0.263948                     -1.378100         -0.939736   \n",
      "3                  0.623770                     -1.378100         -1.663671   \n",
      "4                 -1.743479                      1.937914          0.783918   \n",
      "\n",
      "   Systems Evaluation  Time Management  Management of Financial Resources  \\\n",
      "0           -0.057285        -0.595966                          -0.058512   \n",
      "1            0.901098         1.202362                           0.479727   \n",
      "2           -1.690893        -1.728913                          -1.039496   \n",
      "3           -1.560204        -1.728913                          -0.605432   \n",
      "4            0.487251         1.651944                          -0.605432   \n",
      "\n",
      "   Management of Material Resources  Management of Personnel Resources  \\\n",
      "0                         -0.642732                          -0.837741   \n",
      "1                          0.611428                           0.476730   \n",
      "2                         -1.274828                          -1.283722   \n",
      "3                         -0.512299                          -0.696904   \n",
      "4                         -0.642732                           0.617567   \n",
      "\n",
      "   Auto label value  \n",
      "0               1.0  \n",
      "1               0.0  \n",
      "2               1.0  \n",
      "3               1.0  \n",
      "4               0.0  \n",
      "\n",
      "[5 rows x 38 columns]\n",
      "  O*NET-SOC Code                     Title  Reading Comprehension  \\\n",
      "0     19-3011.00                Economists               1.416147   \n",
      "1     47-2211.00       Sheet Metal Workers              -1.266522   \n",
      "2     51-6031.00  Sewing Machine Operators              -1.896257   \n",
      "3     17-1012.00      Landscape Architects               0.471545   \n",
      "4     27-3042.00         Technical Writers               1.579878   \n",
      "\n",
      "   Active Listening   Writing  Speaking  Mathematics   Science  \\\n",
      "0          0.481653  1.196523  1.043094     1.965973  1.215725   \n",
      "1         -1.363659 -1.574290 -0.857729     0.847035 -0.104950   \n",
      "2         -2.032251 -1.730392 -2.245191    -0.685909 -0.765287   \n",
      "3          0.481653  0.715208  0.696228     0.701574  1.770408   \n",
      "4          0.321191  2.172161  0.349363    -2.095769 -0.545174   \n",
      "\n",
      "   Critical Thinking  Active Learning  ...  Repairing  \\\n",
      "0           1.280270         1.029854  ...  -0.462245   \n",
      "1          -0.791811        -1.002257  ...   2.864901   \n",
      "2          -2.007432        -1.629452  ...   0.807658   \n",
      "3           0.423810         0.716256  ...  -0.462245   \n",
      "4           0.423810         0.553186  ...  -0.462245   \n",
      "\n",
      "   Quality Control Analysis  Judgment and Decision Making  Systems Analysis  \\\n",
      "0                 -1.293701                      0.992282          1.507852   \n",
      "1                  2.103300                     -0.419860         -0.652460   \n",
      "2                  1.357617                     -1.529401         -1.089119   \n",
      "3                  0.765805                      0.677072          0.933301   \n",
      "4                  0.481735                     -0.268559         -0.514568   \n",
      "\n",
      "   Systems Evaluation  Time Management  Management of Financial Resources  \\\n",
      "0            1.304055        -0.146384                          -0.058512   \n",
      "1           -0.601821        -0.362183                          -0.605432   \n",
      "2           -1.560204        -1.728913                          -0.492576   \n",
      "3            1.304055         1.202362                           1.243680   \n",
      "4           -1.418625        -0.146384                          -0.926640   \n",
      "\n",
      "   Management of Material Resources  Management of Personnel Resources  \\\n",
      "0                         -0.271500                          -0.250923   \n",
      "1                         -0.010635                           0.335894   \n",
      "2                         -0.642732                          -1.283722   \n",
      "3                          1.494356                           0.617567   \n",
      "4                         -0.773164                          -0.556068   \n",
      "\n",
      "   Auto label value  \n",
      "0               0.0  \n",
      "1               1.0  \n",
      "2               1.0  \n",
      "3               0.0  \n",
      "4               1.0  \n",
      "\n",
      "[5 rows x 38 columns]\n",
      "  O*NET-SOC Code                                              Title  \\\n",
      "0     11-1011.00                                   Chief Executives   \n",
      "1     11-3071.00  Transportation, Storage, and Distribution Mana...   \n",
      "2     11-9031.00  Education and Childcare Administrators, Presch...   \n",
      "3     11-9151.00              Social and Community Service Managers   \n",
      "4     13-1031.00     Claims Adjusters, Examiners, and Investigators   \n",
      "\n",
      "   Reading Comprehension  Active Listening   Writing  Speaking  Mathematics  \\\n",
      "0               1.416147          1.658374  1.365633  1.917195     1.261042   \n",
      "1               0.471545          0.428166  0.442029  0.640730     0.757520   \n",
      "2               0.622682          0.481653  0.871310  0.696228     0.433029   \n",
      "3               0.622682          0.815949  0.871310  0.862724     0.701574   \n",
      "4               0.547113          0.401422  0.546097  0.529733     0.634437   \n",
      "\n",
      "    Science  Critical Thinking  Active Learning  ...  Repairing  \\\n",
      "0  0.220817           1.625616         1.970645  ...  -0.462245   \n",
      "1 -0.360280           0.700087         0.603361  ...  -0.360652   \n",
      "2 -0.104950           0.589576         0.879327  ...  -0.462245   \n",
      "3  0.995613           0.755342         0.879327  ...  -0.462245   \n",
      "4 -0.377889           0.589576         0.164325  ...  -0.462245   \n",
      "\n",
      "   Quality Control Analysis  Judgment and Decision Making  Systems Analysis  \\\n",
      "0                 -0.559854                      3.198755          3.231506   \n",
      "1                  0.576425                      0.525771          1.025229   \n",
      "2                  0.327864                      0.840981          0.634534   \n",
      "3                  0.173993                      1.143583          1.358469   \n",
      "4                  0.398881                      0.513163         -0.146855   \n",
      "\n",
      "   Systems Evaluation  Time Management  Management of Financial Resources  \\\n",
      "0            2.796083         3.000691                           3.518175   \n",
      "1            1.216929         1.436145                           1.634337   \n",
      "2            0.901098         1.436145                           1.564887   \n",
      "3            1.445634         1.651944                           1.452030   \n",
      "4           -0.122629        -0.254284                           0.644672   \n",
      "\n",
      "   Management of Material Resources  Management of Personnel Resources  \\\n",
      "0                          3.370579                           3.269982   \n",
      "1                          1.785321                           1.403902   \n",
      "2                          1.735155                           1.650365   \n",
      "3                          0.992692                           2.096347   \n",
      "4                          0.169964                          -0.403496   \n",
      "\n",
      "   Auto label value  \n",
      "0               0.0  \n",
      "1               0.0  \n",
      "2               0.0  \n",
      "3               0.0  \n",
      "4               1.0  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_train_set.head())\n",
    "print(scaled_test_set.head())\n",
    "print(scaled_total_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8abf8d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_set.to_csv(\"scaled_training_set.csv\",index=False)\n",
    "scaled_total_set.to_csv(\"scaled_total_set.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5c7ed",
   "metadata": {},
   "source": [
    "### We now have a fully scaled training and test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78aad85",
   "metadata": {},
   "source": [
    "### We can now perform Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dfe4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We begin by creating a centred training set:\n",
    "\n",
    "X = strat_train_set.drop([\"Title\",\"O*NET-SOC Code\"],axis=1)\n",
    "\n",
    "#We now use the Scikit learn toolkit to visualise how the explained variance ratio changes with no. dimensions:\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "dim = range(len(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea62cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.array(dim),np.array(cumsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Having visualized the effect of dimensionality, we can implement this to our dataset:\n",
    "\n",
    "pca2 = PCA(n_components=0.95)\n",
    "X_reduced = pca2.fit_transform(X)\n",
    "print(X_reduced[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badabc02",
   "metadata": {},
   "source": [
    "### We shall now fit a GP classifier to the unreduced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30b04605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e827c85b964b3bb66dee4683886ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntProgress(value=0, max=1000), HTML(value=''))), Box(children=(HTML(value=''),)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<paramz.optimization.optimization.opt_lbfgsb at 0x238f87d4820>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Begin by creating numpy arrays for our input X and output Y:\n",
    "\n",
    "X = np.array([scaled_train_set.iloc[:,2:37]])\n",
    "Y = np.array([scaled_train_set.iloc[:,37]])\n",
    "#X = np.transpose(X)\n",
    "#Y = np.transpose(Y)\n",
    "X = np.reshape(X,(50,35)) #Reshape to go from 3d matrix to 2d\n",
    "Y = np.reshape(Y,(50,1)) # ^\n",
    "\n",
    "#Now generate a kernel:\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "import GPy\n",
    "\n",
    "kernel = GPy.kern.RBF(input_dim=35, variance=100., lengthscale=100.)\n",
    "m_gpy = GPy.models.GPClassification(X,Y,kernel)\n",
    "m_gpy.optimize(messages=True)\n",
    "#m_gpy.optimize_restarts(num_restarts = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5691efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We shall request values for the variance and lengthscale:\n",
    "\n",
    "m_var = input(\"What is the rbf.variance?\")\n",
    "m_length = input(\"What is the rbf.lengthscale?\")\n",
    "\n",
    "m_var = float(m_var)\n",
    "m_length = float(m_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e436ff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate this model in scikit learn\n",
    "\n",
    "\n",
    "sci_kernel = m_var * RBF(m_length)\n",
    "gpc = GaussianProcessClassifier(kernel=sci_kernel,optimizer=None).fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13de51ce",
   "metadata": {},
   "source": [
    "### Lets now apply k-fold cross validation on the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56997c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(scaled_train_set.iloc[:,2:37])\n",
    "#X_train = np.transpose(X_train)\n",
    "y_train = np.array(scaled_train_set.iloc[:,37])\n",
    "#y_train = np.transpose(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6974f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train,y_train):\n",
    "    clone_gpc = clone(gpc)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train[test_index]\n",
    "    \n",
    "    clone_gpc.fit(X_train_folds,y_train_folds)\n",
    "    y_pred = clone_gpc.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct/len(y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68786926",
   "metadata": {},
   "source": [
    "### What about an F1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185668f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_train_pred = cross_val_predict(gpc,X_train,y_train,cv=5)\n",
    "f1_score(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c6f32",
   "metadata": {},
   "source": [
    "### And how about an AUC value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40910d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def calc_AUC(gpc,X_train,y_train):\n",
    "    y_probas = cross_val_predict(gpc,X_train,y_train,cv=5,method=\"predict_proba\")\n",
    "    y_scores = y_probas[:,1]\n",
    "    return roc_auc_score(y_train,y_scores)\n",
    "\n",
    "calc_AUC(gpc,X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1ddfdf",
   "metadata": {},
   "source": [
    "### And a log-likelihood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424fa99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpc.log_marginal_likelihood(theta=None, eval_gradient=False, clone_kernel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d78e0",
   "metadata": {},
   "source": [
    "### It is worth using the model to predict values for the test set to ensure it is working as I want it to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d045d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(scaled_test_set.iloc[:,2:37])\n",
    "y_test = np.array(scaled_test_set.iloc[:,37])\n",
    "\n",
    "y_pred = gpc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f0c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f8dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd5b80",
   "metadata": {},
   "source": [
    "### We now have a fully working GP classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52436a7e",
   "metadata": {},
   "source": [
    "### Lets now consider the interpretability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c840583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We shall use the feature permutation method:\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "feature_importance = pd.DataFrame({\"Features\":np.array(training_set.columns[2:37])})\n",
    "\n",
    "r = permutation_importance(gpc,X_test,y_test,n_repeats=30,random_state=0)\n",
    "feature_importance[\"Importances\"] = abs(r.importances_mean)\n",
    "feature_importance = feature_importance.sort_values(by=['Importances'])\n",
    "#feature_importance = feature_importance\n",
    "print(feature_importance)\n",
    "#print(r.importances_mean)\n",
    "\n",
    "#for i in r.importances_mean.argsort()[::-1]:\n",
    "#    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "#        print(f\"{feature_importance.Features[i]:<8}\"\n",
    "#        f\"{r.importances_mean[i]:.3f}\"\n",
    "#        f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb49c78",
   "metadata": {},
   "source": [
    "### Now that we have the feature importances, lets calculate the entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ce2fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the moment we won't normalise the distribution - might have to do this in the future (ask Mike)\n",
    "\n",
    "def log_calc(my_list):    #This function deals with values of 0\n",
    "    my_output = [0]*len(my_list)\n",
    "    for i in range(len(my_list)):\n",
    "        if my_list[i] != 0.0:\n",
    "            my_output[i] = np.log(my_list[i])\n",
    "    return my_output        \n",
    "            \n",
    "temp = abs(r.importances_mean)\n",
    "tempnew = temp/sum(temp)\n",
    "vector1 = np.array(tempnew)\n",
    "vector2 = np.array(log_calc(abs(r.importances_mean)))\n",
    "entropy = -1*np.dot(vector1,vector2)\n",
    "print(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16486e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create a function that does all of this:\n",
    "\n",
    "def calc_entropy(gpc,X_test,y_test):\n",
    "    r = permutation_importance(gpc,X_test,y_test,n_repeats=30,random_state=0)\n",
    "    temp = abs(r.importances_mean)\n",
    "    tempnew = temp/sum(temp)\n",
    "    vector1 = np.array(tempnew)\n",
    "    vector2 = np.array(log_calc(abs(r.importances_mean)))\n",
    "    return -1*np.dot(vector1,vector2)\n",
    "\n",
    "calc_entropy(gpc,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d928b",
   "metadata": {},
   "source": [
    "### Lets now implement a gridsearch method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9ca5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(GaussianProcessClassifier(optimizer=None),{'kernel': [1*RBF(1),1*RBF(2)]},cv=5,return_train_score=False,scoring='roc_auc')\n",
    "clf.fit(X,Y)\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearchdf = pd.DataFrame(clf.cv_results_)\n",
    "gridsearchdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e52523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets try manually creating the functions:\n",
    "\n",
    "n_lengthscale = 10\n",
    "n_const = 10\n",
    "\n",
    "#The above values control the number of different hyperparaemters we want to test on\n",
    "\n",
    "lengthscale = np.linspace(0.01*m_length,1.99*m_length,n_lengthscale)\n",
    "const = np.linspace(0.01*m_var,1.99*m_var,n_const)\n",
    "\n",
    "resultsdf = pd.DataFrame({'length_scale':[0.0]*(n_lengthscale*n_const),'const':[0.0]*(n_lengthscale*n_const),'AUC':[0.0]*(n_lengthscale*n_const),\"log-likelihood\":[0.0]*(n_lengthscale*n_const),\"entropy\":[0.0]*(n_lengthscale*n_const)})\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "for i in lengthscale:\n",
    "    for j in const:\n",
    "        kernel = j*RBF(i)\n",
    "        gpc = GaussianProcessClassifier(kernel=kernel,optimizer=None).fit(X, Y)\n",
    "        \n",
    "        #y_probas = cross_val_predict(gpc,X_train,y_train,cv=5,method=\"predict_proba\")\n",
    "        #y_scores = y_probas[:,1]\n",
    "        resultsdf.iloc[iteration]['AUC'] = calc_AUC(gpc,X_train,y_train)\n",
    "        \n",
    "        resultsdf.iloc[iteration]['log-likelihood'] = gpc.log_marginal_likelihood(theta=None, eval_gradient=False, clone_kernel=True)\n",
    "        \n",
    "        resultsdf.iloc[iteration]['length_scale'] = i\n",
    "        resultsdf.iloc[iteration]['const'] = j\n",
    "        \n",
    "        \n",
    "        resultsdf.iloc[iteration]['entropy'] = calc_entropy(gpc,X_test,y_test)\n",
    "        \n",
    "\n",
    "        #r = permutation_importance(gpc,X_test,y_test,n_repeats=30,random_state=0)\n",
    "        #temp = abs(r.importances_mean)\n",
    "        #tempnew = temp/sum(temp)\n",
    "        #vector1 = np.array(tempnew)\n",
    "        #vector2 = np.array(log_calc(abs(r.importances_mean)))\n",
    "        #resultsdf.iloc[iteration]['entropy'] = -1*np.dot(vector1,vector2)\n",
    "        \n",
    "        iteration+=1\n",
    "\n",
    "print(resultsdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0abaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsdf = resultsdf.sort_values(by=['entropy'])\n",
    "resultsdf = resultsdf.dropna() #Drop NaNs from too small variance models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc61202",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Consider dropping innacurate models. We do not care about these models and they could potentially alter the clustering '''\n",
    "\n",
    "max_accuracy = resultsdf['log-likelihood'].max()\n",
    "resultsdf = resultsdf.loc[resultsdf['log-likelihood'] > 1.2*max_accuracy]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a1cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultsdf.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db17fd48",
   "metadata": {},
   "source": [
    "### Lets visualise the accuracy vs interpretability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c63e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt = resultsdf.plot.scatter(x=\"entropy\",y=\"log-likelihood\")\n",
    "plt.scatter(resultsdf['entropy'],resultsdf['log-likelihood'])\n",
    "plt.xlabel(\"Feature entropy\")\n",
    "plt.ylabel(\"log-likelihood\")\n",
    "#plt.show()\n",
    "plt.savefig('clustergraph.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c3ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('clustergraph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6620d052",
   "metadata": {},
   "source": [
    "### We shall now apply K-means to identify the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b309e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = input(\"How many clusters?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b110ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=int(n))\n",
    "c_predicted = km.fit_predict(resultsdf[[\"log-likelihood\",\"entropy\"]])\n",
    "resultsdf[\"cluster\"]=c_predicted\n",
    "resultsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc95e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First create a dictionary for colours:\n",
    "\n",
    "colour_dict = {\n",
    "  0: \"blue\",\n",
    "  1: \"red\",\n",
    "  2: \"green\",\n",
    "  3: \"cyan\",\n",
    "  4: \"magenta\",\n",
    "  5: \"yellow\",\n",
    "  6: \"black\",\n",
    "}\n",
    "\n",
    "data_frames = []\n",
    "\n",
    "for i in range(int(n)):\n",
    "    data_frames.append(resultsdf[resultsdf.cluster == i])\n",
    "    plt.scatter(data_frames[i].entropy,data_frames[i][\"log-likelihood\"],color=colour_dict[i])\n",
    "\n",
    "#df1 = resultsdf[resultsdf.cluster == 0]\n",
    "#df2 = resultsdf[resultsdf.cluster == 1]\n",
    "#df3 = resultsdf[resultsdf.cluster == 2]\n",
    "#df4 = resultsdf[resultsdf.cluster == 3]\n",
    "\n",
    "#plt.scatter(df1.entropy,df1[\"log-likelihood\"],color=\"blue\")\n",
    "#plt.scatter(df2.entropy,df2[\"log-likelihood\"],color=\"red\")\n",
    "#plt.scatter(df3.entropy,df3[\"log-likelihood\"],color=\"green\")\n",
    "#plt.scatter(df4.entropy,df4[\"log-likelihood\"],color=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ea079",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' It is possible that the user will not be happy with how the data has been assigned.\n",
    "Offer an option for them to redo the clustering . '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35196a",
   "metadata": {},
   "source": [
    "### We now need to select the median  model (based on entropy) from each of these clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f780ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create a list of models and their accuracies:\n",
    "\n",
    "models = []\n",
    "accuracies = []\n",
    "\n",
    "\n",
    "#Can't use median function because it finds an average for even sets\n",
    "\n",
    "for i in range(int(n)):\n",
    "    index = int(data_frames[i].shape[0]/2)\n",
    "    observation = data_frames[i].iloc[index]\n",
    "    kernel = float(observation['const'])*RBF(float(observation['length_scale']))\n",
    "    gp = GaussianProcessClassifier(kernel=kernel,optimizer=None).fit(X, Y)\n",
    "    models.append(gp)\n",
    "    accuracies.append(observation['log-likelihood'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b0221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the moment, we shall generate an explanation based on feature importance across the different clusters:\n",
    "\n",
    "\n",
    "tables = []\n",
    "\n",
    "for i in range(int(n)):\n",
    "    tables.append(pd.DataFrame({\"Features\":np.array(training_set.columns[2:37])}))\n",
    "\n",
    "\n",
    "for i in range(int(n)):\n",
    "    r = permutation_importance(models[i],X_test,y_test,n_repeats=30,random_state=0)\n",
    "    #tables[i][\"Importances\"] = abs(r.importances_mean)\n",
    "    tables[i][\"Importances\"] = r.importances_mean\n",
    "    tables[i] = tables[i].sort_values(by=[\"Importances\"],ascending=False)\n",
    "    tables[i].reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "#for i in range(int(n)):\n",
    "    #r = permutation_importance(models[i],X_test,y_test,n_repeats=30,random_state=0)\n",
    "    #importance_table[\"Importances{}\".format(i)] = abs(r.importances_mean)\n",
    "    #importance_table = importance_table.sort_values(by=['Importances{}'.format(i)])\n",
    "\n",
    "#NOTE - I'm uneasy about using the same test sets as before, should I expand to the unknown jobs?\n",
    "\n",
    "importance_dict = {}\n",
    "for i in range(int(n)):\n",
    "    q = tables[i]\n",
    "    importance_dict[\"Importance{}\".format(i)] = q[\"Features\"]\n",
    "#q = tables[1]\n",
    "#importance_dict[\"Importance1\"] = q[\"Features\"]\n",
    "importance_table = pd.DataFrame(data=importance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d12e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a9c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(importance_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec713c4",
   "metadata": {},
   "source": [
    "### We now have a table of features sorted by how important they are for each cluster, based on the permutation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4994965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We shall generate one more table, which will have a row for each feature and a score for how important it is:\n",
    "\n",
    "final_importance_table = pd.DataFrame({\"Features\":np.array(training_set.columns[2:37]),\"Importance\":np.zeros(np.shape(training_set.columns[2]))})\n",
    "feature_list = final_importance_table['Features'].tolist()\n",
    "#final_importance_table.head()\n",
    "for i in feature_list:\n",
    "    for j in range(int(n)):\n",
    "        index_val = importance_table.index[importance_table[\"Importance{}\".format(j)]==i]\n",
    "        index_val = index_val*accuracies[j]/sum(accuracies)\n",
    "        final_importance_table.loc[final_importance_table[\"Features\"]==i,\"Importance\"] += index_val.tolist()[0]\n",
    "    \n",
    "final_importance_table = final_importance_table.sort_values(by=[\"Importance\"],ascending=True)\n",
    "final_importance_table.reset_index(drop = True, inplace = True)\n",
    "final_importance_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e26c97",
   "metadata": {},
   "source": [
    "### We now have a table which ranks features by importance across all the clusters! Note that is values each cluster equally - this might be something we can improve upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1470c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets divert our attention towards making predictions on our unknown jobs:\n",
    "\n",
    "unknown_jobs = df4[df4.isna().any(axis=1)] #This is our set of unknown jobs\n",
    "#SCALE THE DATA! - Do I need to fit a new scaler?\n",
    "X = scaler.transform(unknown_jobs.iloc[:,2:37])\n",
    "#X = np.array(unknown_jobs.iloc[:,2:37])\n",
    "print(X)\n",
    "#for i in int(n):\n",
    "    #models[i].predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = gpc.predict_proba(X)\n",
    "test1 = gpc.predict(X)\n",
    "test2 = gpc.predict_proba(X)\n",
    "print(test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7555bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now fill in the dataframe:\n",
    "\n",
    "unknown_jobs[\"Auto label value\"] = test1\n",
    "unknown_jobs[\"Auto probability\"] = test2[:,1]\n",
    "unknown_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b143b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_jobs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a8b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets think about how we can apply the model from each of our clusters and compute an average:\n",
    "\n",
    "for i in range(int(n)):\n",
    "    probs = models[i].predict_proba(X)\n",
    "    unknown_jobs[\"Auto probability{}\".format(i)] = probs[:,1]\n",
    "\n",
    "#We need a list of column titles:\n",
    "column_titles = []\n",
    "for i in range(int(n)):\n",
    "    column_titles.append(\"Auto probability{}\".format(i))\n",
    "\n",
    "#Now calculate mean automotability    \n",
    "\n",
    "unknown_jobs[\"Auto probability\"] = unknown_jobs[column_titles].mean(axis=1)\n",
    "\n",
    "#And finally apply a function to determine auto-label value:\n",
    "\n",
    "def label_auto(my_input):\n",
    "    if my_input - 0.5 < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "unknown_jobs[\"Auto label value\"] = unknown_jobs[\"Auto probability\"].apply(label_auto)\n",
    "\n",
    "unknown_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d836b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unknown_jobs[\"Title\"][\"i\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f475056f",
   "metadata": {},
   "source": [
    "### We have now generated values for automotability!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
