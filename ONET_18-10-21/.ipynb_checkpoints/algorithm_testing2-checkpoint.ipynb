{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e133cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This version hitches PIGEBaQ onto the permutation method '''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"Skills.xlsx\")\n",
    "#print(df.head())\n",
    "\n",
    "#Lets remove the importance values:\n",
    "\n",
    "df2 = df.loc[df[\"Scale Name\"] == \"Level\"]\n",
    "df2.reset_index(drop = True, inplace = True)\n",
    "#print(df2.head())\n",
    "\n",
    "#Lets now remove the irrelevent columns:\n",
    "\n",
    "df3 = df2.drop(columns = [\"Scale ID\",\"Scale Name\",\"N\",\"Recommend Suppress\",\"Not Relevant\",\"Date\",\"Domain Source\"])\n",
    "print(df3.head())\n",
    "\n",
    "#NOTE that we have ignored the suppress recomendations, we shall continue with this for now but will need to address this later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420df498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now discover a bit about our data set:\n",
    "\n",
    "df3.info()\n",
    "\n",
    "#We note that there are some occupations for which the standard error and bound values are missing. Lets supress these for now:\n",
    "\n",
    "df3.drop(columns = [\"Standard Error\",\"Lower CI Bound\",\"Upper CI Bound\"],inplace = True)\n",
    "print(df3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a1537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#I shall implement the drop_duplicates method:\n",
    "\n",
    "df4 = df3[[\"O*NET-SOC Code\",\"Title\"]]\n",
    "df4.drop_duplicates(inplace=True)\n",
    "df4.reset_index(drop = True, inplace = True)\n",
    "#print(df4.head())\n",
    "\n",
    "#We now need to add the variables. Begin by adding empty columns to the dataframe:\n",
    "\n",
    "n_jobs = len(set((df3[\"Title\"])))\n",
    "n_variables = len(set((df3[\"Element Name\"])))\n",
    "\n",
    "for i in range(n_jobs):\n",
    "    df4[df3[\"Element Name\"][i]] = \"\"\n",
    "\n",
    "#print(df4.head())\n",
    "#Now we need to fill these columns:\n",
    "\n",
    "x = df3.loc[df3[\"Title\"] == \"Chief Executives\"]\n",
    "y = x[\"Data Value\"]\n",
    "\n",
    "for i in range(n_variables):\n",
    "    df4[df4.columns[2+i]][0] = y[i]\n",
    "    \n",
    "#We now need to do this procedure for every job:\n",
    "\n",
    "for j in range(n_jobs):\n",
    "    x = df3.loc[df3[\"Title\"] == df4.iloc[j,1]]\n",
    "    y = x[\"Data Value\"]\n",
    "    y.reset_index(drop = True, inplace = True)\n",
    "    for i in range(n_variables):\n",
    "        df4[df4.columns[2+i]][j] = y[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0748248",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df4.head())\n",
    "print(df4.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194be949",
   "metadata": {},
   "source": [
    "### We now have the skills dataframe just as we want it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edae9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets understand our data a bit:\n",
    "\n",
    "df4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb3b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "hist = df4.iloc[:,20].hist(bins=20)\n",
    "\n",
    "#We can inspect the histogram of any variable we want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3628f6e5",
   "metadata": {},
   "source": [
    "### Let's now  import another dataframe with autovalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87641e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_excel(\"US_data_email.xls\")\n",
    "df5 = df5[[\"Occupation Name\",\"BLS codes\",\"Training set automatable labels\"]]\n",
    "print(df5.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40868f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422495f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets define a function so that we can make occupation ID's consistent:\n",
    "\n",
    "def title_set(my_string):\n",
    "    my_list = []\n",
    "    my_list[:0] = my_string\n",
    "    my_list.remove(\"_\")\n",
    "    my_list.append(\".00\")\n",
    "    my_output = \"\".join(my_list)\n",
    "    return my_output\n",
    "\n",
    "#print(title_set(\"45-4023_\"))\n",
    "\n",
    "df5.iloc[:,1] = df5.iloc[:,1].apply(title_set)\n",
    "print(df5.head())\n",
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88670d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now concatenate the auto labels to our 1st dataframe:\n",
    "import numpy as np\n",
    "df4[\"Auto label value\"] = np.nan\n",
    "for i in list(df5[\"BLS codes\"]):\n",
    "    df4.loc[df4[\"O*NET-SOC Code\"] == i,\"Auto label value\"] = list(df5.loc[df5[\"BLS codes\"] == i,\"Training set automatable labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.info()\n",
    "\n",
    "#Note - the auto value count is supposedly 330 non-null, even though it should be 70. After creating a csv from the dataframe,\n",
    "#I found that there were 70 non-null as expected. Worth bringing up with Mike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv(\"test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035d0d9",
   "metadata": {},
   "source": [
    "### START FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dec8cea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.418287</td>\n",
       "      <td>0.106315</td>\n",
       "      <td>0.367642</td>\n",
       "      <td>0.609699</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.353350</td>\n",
       "      <td>0.277904</td>\n",
       "      <td>-0.357989</td>\n",
       "      <td>0.899122</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.120200</td>\n",
       "      <td>0.397125</td>\n",
       "      <td>-0.023316</td>\n",
       "      <td>0.789937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.395666</td>\n",
       "      <td>-0.163691</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.734246</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.230537</td>\n",
       "      <td>0.238473</td>\n",
       "      <td>0.186635</td>\n",
       "      <td>0.045195</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature1  Feature2  Feature3  Feature4  Output\n",
       "0  0.418287  0.106315  0.367642  0.609699     0.0\n",
       "1  0.353350  0.277904 -0.357989  0.899122     0.0\n",
       "2  0.120200  0.397125 -0.023316  0.789937     0.0\n",
       "3  0.395666 -0.163691  0.999948  0.734246     0.0\n",
       "4  0.230537  0.238473  0.186635  0.045195     0.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df4 = pd.read_csv(\"ControlData1.csv\")\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e2d9a8",
   "metadata": {},
   "source": [
    "### We now have a dataset which encompass jobs titles, SOC codes, skill levels and hand picked auto labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d2e87",
   "metadata": {},
   "source": [
    "### Lets now split and standardize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc1e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To prevent information about the distribution of the test set leaking into the model, we shall first form a training set\n",
    "# and form a scaler operator from this, and then apply this to both training and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a0fc4bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Feature1  200 non-null    float64\n",
      " 1   Feature2  200 non-null    float64\n",
      " 2   Feature3  200 non-null    float64\n",
      " 3   Feature4  200 non-null    float64\n",
      " 4   Output    200 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 7.9 KB\n"
     ]
    }
   ],
   "source": [
    "#Lets now create a training set which includes only the jobs for which we have hand picked auto values:\n",
    "\n",
    "training_set = df4.dropna(axis=0,how=\"any\")\n",
    "training_set.reset_index(drop = True, inplace=True)\n",
    "#print(training_set.head())\n",
    "training_set.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6c955b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets apply stratified sampling on this set to create a training and test set\n",
    "#Code taken from Hands on Machine Learning book\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "for train_index, test_index in split.split(training_set,training_set[\"Output\"]):\n",
    "    strat_train_set = training_set.loc[train_index]\n",
    "    strat_test_set = training_set.loc[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "04871038",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.reset_index(drop=True,inplace=True)\n",
    "strat_test_set.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7615f630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.5\n",
       "1.0    0.5\n",
       "Name: Output, dtype: float64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set[\"Output\"].value_counts()/len(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4985df74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Now that we have our training set, lets create a standardiser for it:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=True,with_std=True)\n",
    "scaler.fit(strat_train_set.iloc[:,0:4])\n",
    "scaled_training_values = scaler.transform(strat_train_set.iloc[:,0:4])\n",
    "scaled_test_values = scaler.transform(strat_test_set.iloc[:,0:4])\n",
    "scaled_train_set = strat_train_set.copy()\n",
    "scaled_test_set = strat_test_set.copy()\n",
    "#print(strat_train_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "85fb4ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary = pd.DataFrame(data=scaled_training_values)\n",
    "temporary2 = pd.DataFrame(data=scaled_test_values) #we create temporary data frames from the numpy arrays we've just created\n",
    "#print(temporary)\n",
    "for i in range(0,4):\n",
    "    scaled_train_set[scaled_train_set.columns[i]] = temporary[temporary.columns[i]]\n",
    "    scaled_test_set[scaled_test_set.columns[i]] = temporary2[temporary2.columns[i]]\n",
    "\n",
    "#print(scaled_test_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0efe1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' We shall also create a standardized set for ALL of the training data '''\n",
    "\n",
    "scaler2 = StandardScaler(with_mean=True,with_std=True)\n",
    "scaler2.fit(strat_train_set.iloc[:,0:4])\n",
    "scaled_total_values = scaler2.transform(training_set.iloc[:,0:4])\n",
    "scaled_total_set = training_set.copy()\n",
    "\n",
    "temporary3 = pd.DataFrame(data=scaled_total_values)\n",
    "for i in range(0,4):\n",
    "    scaled_total_set[scaled_total_set.columns[i]] = temporary3[temporary3.columns[i]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8d735dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature1  Feature2  Feature3  Feature4  Output\n",
      "0 -1.525631 -1.383735 -0.260900 -0.162168     0.0\n",
      "1  0.468055  0.112434  0.678927  1.389194     1.0\n",
      "2 -1.540588 -0.443355  0.823097 -1.557709     0.0\n",
      "3  0.626085  0.545235  0.042940  1.150382     1.0\n",
      "4  1.119117  0.679486 -0.675603 -1.038366     1.0\n",
      "   Feature1  Feature2  Feature3  Feature4  Output\n",
      "0 -0.921259 -1.062053 -0.203980 -0.096627     0.0\n",
      "1  0.766802 -0.655023  0.974597  1.416129     1.0\n",
      "2  1.476870  0.476743  0.115846 -0.608097     1.0\n",
      "3  0.585031  1.298365  2.235713 -1.159922     1.0\n",
      "4 -0.516725 -0.443154 -0.545677  1.745898     0.0\n",
      "   Feature1  Feature2  Feature3  Feature4  Output\n",
      "0 -0.235739 -1.079865 -0.216082  0.471298     0.0\n",
      "1 -0.460010 -0.610156 -1.497311  1.454110     0.0\n",
      "2 -1.265228 -0.283802 -0.906387  1.083343     0.0\n",
      "3 -0.313863 -1.818978  0.900363  0.894231     0.0\n",
      "4 -0.884161 -0.718096 -0.535683 -1.445627     0.0\n"
     ]
    }
   ],
   "source": [
    "print(scaled_train_set.head())\n",
    "print(scaled_test_set.head())\n",
    "print(scaled_total_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a67dc1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160 entries, 0 to 159\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Feature1  160 non-null    float64\n",
      " 1   Feature2  160 non-null    float64\n",
      " 2   Feature3  160 non-null    float64\n",
      " 3   Feature4  160 non-null    float64\n",
      " 4   Output    160 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 6.4 KB\n"
     ]
    }
   ],
   "source": [
    "scaled_train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0469304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_total_set.to_csv(\"PIGEBAQ_testset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5c7ed",
   "metadata": {},
   "source": [
    "### We now have a fully scaled training and test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78aad85",
   "metadata": {},
   "source": [
    "### We can now perform Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dfe4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We begin by creating a centred training set:\n",
    "\n",
    "X = strat_train_set.drop([\"Title\",\"O*NET-SOC Code\"],axis=1)\n",
    "\n",
    "#We now use the Scikit learn toolkit to visualise how the explained variance ratio changes with no. dimensions:\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "dim = range(len(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea62cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.array(dim),np.array(cumsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Having visualized the effect of dimensionality, we can implement this to our dataset:\n",
    "\n",
    "pca2 = PCA(n_components=0.95)\n",
    "X_reduced = pca2.fit_transform(X)\n",
    "print(X_reduced[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badabc02",
   "metadata": {},
   "source": [
    "### We shall now fit a GP classifier to the unreduced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "30b04605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6672966f42934747890f8d006c747e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntProgress(value=0, max=1000), HTML(value=''))), Box(children=(HTML(value=''),)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<paramz.optimization.optimization.opt_lbfgsb at 0x23f037cf340>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Begin by creating numpy arrays for our input X and output Y:\n",
    "\n",
    "#X = np.array([scaled_train_set.iloc[:,0:4]])\n",
    "#Y = np.array([scaled_train_set.iloc[:,4]])\n",
    "X = np.array([scaled_total_set.iloc[:,0:4]])\n",
    "Y = np.array([scaled_total_set.iloc[:,4]])\n",
    "#X = np.transpose(X)\n",
    "#Y = np.transpose(Y)\n",
    "\n",
    "\n",
    "X = np.reshape(X,(200,4)) #Reshape to go from 3d matrix to 2d\n",
    "Y = np.reshape(Y,(200,1)) # ^\n",
    "\n",
    "#Now generate a kernel:\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "import GPy\n",
    "\n",
    "kernel = GPy.kern.RBF(input_dim=4, variance=100., lengthscale=100.)\n",
    "m_gpy = GPy.models.GPClassification(X,Y,kernel)\n",
    "m_gpy.optimize(messages=True)\n",
    "#m_gpy.optimize_restarts(num_restarts = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5691efad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the rbf.variance?7.85\n",
      "What is the rbf.lengthscale?5.40\n"
     ]
    }
   ],
   "source": [
    "#We shall request values for the variance and lengthscale:\n",
    "\n",
    "m_var = input(\"What is the rbf.variance?\")\n",
    "m_length = input(\"What is the rbf.lengthscale?\")\n",
    "\n",
    "m_var = float(m_var)\n",
    "m_length = float(m_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e436ff7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "#Instantiate this model in scikit learn\n",
    "\n",
    "\n",
    "sci_kernel = m_var * RBF(m_length)\n",
    "gpc = GaussianProcessClassifier(kernel=sci_kernel,optimizer=None).fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13de51ce",
   "metadata": {},
   "source": [
    "### Lets now apply k-fold cross validation on the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "56997c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(scaled_train_set.iloc[:,0:4])\n",
    "#X_train = np.transpose(X_train)\n",
    "y_train = np.array(scaled_train_set.iloc[:,4])\n",
    "#y_train = np.transpose(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6974f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.96875\n",
      "1.0\n",
      "0.96875\n",
      "0.96875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train,y_train):\n",
    "    clone_gpc = clone(gpc)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train[test_index]\n",
    "    \n",
    "    clone_gpc.fit(X_train_folds,y_train_folds)\n",
    "    y_pred = clone_gpc.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct/len(y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68786926",
   "metadata": {},
   "source": [
    "### What about an F1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "185668f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9813664596273292"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_train_pred = cross_val_predict(gpc,X_train,y_train,cv=5)\n",
    "f1_score(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c6f32",
   "metadata": {},
   "source": [
    "### And how about an AUC value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "40910d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99828125"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def calc_AUC(gpc,X_train,y_train):\n",
    "    y_probas = cross_val_predict(gpc,X_train,y_train,cv=5,method=\"predict_proba\")\n",
    "    y_scores = y_probas[:,1]\n",
    "    return roc_auc_score(y_train,y_scores)\n",
    "\n",
    "calc_AUC(gpc,X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1ddfdf",
   "metadata": {},
   "source": [
    "### And a log-likelihood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "424fa99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-35.18718167696032"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpc.log_marginal_likelihood(theta=None, eval_gradient=False, clone_kernel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d78e0",
   "metadata": {},
   "source": [
    "### It is worth using the model to predict values for the test set to ensure it is working as I want it to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b4d045d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(scaled_test_set.iloc[:,0:4])\n",
    "y_test = np.array(scaled_test_set.iloc[:,4])\n",
    "\n",
    "y_pred = gpc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "09f0c78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c8f8dc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95778469, 0.04221531],\n",
       "       [0.27236611, 0.72763389],\n",
       "       [0.02578567, 0.97421433],\n",
       "       [0.03023506, 0.96976494],\n",
       "       [0.88956533, 0.11043467],\n",
       "       [0.03906675, 0.96093325],\n",
       "       [0.9496806 , 0.0503194 ],\n",
       "       [0.14562705, 0.85437295],\n",
       "       [0.2577282 , 0.7422718 ],\n",
       "       [0.87227011, 0.12772989],\n",
       "       [0.23292703, 0.76707297],\n",
       "       [0.11116295, 0.88883705],\n",
       "       [0.92294662, 0.07705338],\n",
       "       [0.03426014, 0.96573986],\n",
       "       [0.96562843, 0.03437157],\n",
       "       [0.91972138, 0.08027862],\n",
       "       [0.03917346, 0.96082654],\n",
       "       [0.93483918, 0.06516082],\n",
       "       [0.98063221, 0.01936779],\n",
       "       [0.01470908, 0.98529092],\n",
       "       [0.99074961, 0.00925039],\n",
       "       [0.10885979, 0.89114021],\n",
       "       [0.02427739, 0.97572261],\n",
       "       [0.09608501, 0.90391499],\n",
       "       [0.08979051, 0.91020949],\n",
       "       [0.06523693, 0.93476307],\n",
       "       [0.03078612, 0.96921388],\n",
       "       [0.70994144, 0.29005856],\n",
       "       [0.19723988, 0.80276012],\n",
       "       [0.98012874, 0.01987126],\n",
       "       [0.39525373, 0.60474627],\n",
       "       [0.70132682, 0.29867318],\n",
       "       [0.67810825, 0.32189175],\n",
       "       [0.96014879, 0.03985121],\n",
       "       [0.98701858, 0.01298142],\n",
       "       [0.96813829, 0.03186171],\n",
       "       [0.88747902, 0.11252098],\n",
       "       [0.80932806, 0.19067194],\n",
       "       [0.17094855, 0.82905145],\n",
       "       [0.95203868, 0.04796132]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd5b80",
   "metadata": {},
   "source": [
    "### We now have a fully working GP classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52436a7e",
   "metadata": {},
   "source": [
    "### Lets now consider the interpretability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7c840583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Features  Importances\n",
      "3  Feature4     0.001667\n",
      "2  Feature3     0.044167\n",
      "1  Feature2     0.087500\n",
      "0  Feature1     0.343333\n"
     ]
    }
   ],
   "source": [
    "#We shall use the feature permutation method:\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "feature_importance = pd.DataFrame({\"Features\":np.array(training_set.columns[0:4])})\n",
    "\n",
    "r = permutation_importance(gpc,X_test,y_test,n_repeats=30,random_state=0)\n",
    "feature_importance[\"Importances\"] = abs(r.importances_mean)\n",
    "feature_importance = feature_importance.sort_values(by=['Importances'])\n",
    "#feature_importance = feature_importance\n",
    "print(feature_importance)\n",
    "#print(r.importances_mean)\n",
    "\n",
    "#for i in r.importances_mean.argsort()[::-1]:\n",
    "#    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "#        print(f\"{feature_importance.Features[i]:<8}\"\n",
    "#        f\"{r.importances_mean[i]:.3f}\"\n",
    "#        f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb49c78",
   "metadata": {},
   "source": [
    "### Now that we have the feature importances, lets calculate the entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "79ce2fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5286446286468482\n"
     ]
    }
   ],
   "source": [
    "# For the moment we won't normalise the distribution - might have to do this in the future (ask Mike)\n",
    "\n",
    "def log_calc(my_list):    #This function deals with values of 0\n",
    "    my_output = [0]*len(my_list)\n",
    "    for i in range(len(my_list)):\n",
    "        if my_list[i] != 0.0:\n",
    "            my_output[i] = np.log(my_list[i])\n",
    "    return my_output        \n",
    "            \n",
    "temp = abs(r.importances_mean)\n",
    "tempnew = temp/sum(temp)\n",
    "vector1 = np.array(tempnew)\n",
    "vector2 = np.array(log_calc(abs(r.importances_mean)))\n",
    "entropy = -1*np.dot(vector1,vector2)\n",
    "print(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "16486e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5286446286468482"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets create a function that does all of this:\n",
    "\n",
    "def calc_entropy(gpc,X_test,y_test):\n",
    "    r = permutation_importance(gpc,X_test,y_test,n_repeats=30,random_state=0)\n",
    "    temp = abs(r.importances_mean)\n",
    "    tempnew = temp/sum(temp)\n",
    "    vector1 = np.array(tempnew)\n",
    "    vector2 = np.array(log_calc(abs(r.importances_mean)))\n",
    "    return -1*np.dot(vector1,vector2)\n",
    "\n",
    "calc_entropy(gpc,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d928b",
   "metadata": {},
   "source": [
    "### Lets now implement a gridsearch method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c3e52523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   length_scale   const       AUC  log-likelihood   entropy\n",
      "0         0.054  0.0785  0.706094     -110.917979  1.576973\n",
      "1         0.054  1.8055  0.715000     -113.365135  1.576973\n",
      "2         0.054  3.5325  0.715000     -115.369438  1.576973\n",
      "3         0.054  5.2595  0.715000     -116.672978  1.576973\n",
      "4         0.054  6.9865  0.715000     -117.607966  1.576973\n"
     ]
    }
   ],
   "source": [
    "#Lets try manually creating the functions:\n",
    "\n",
    "n_lengthscale = 10\n",
    "n_const = 10\n",
    "\n",
    "#The above values control the number of different hyperparaemters we want to test on\n",
    "\n",
    "lengthscale = np.linspace(0.01*m_length,1.99*m_length,n_lengthscale)\n",
    "const = np.linspace(0.01*m_var,1.99*m_var,n_const)\n",
    "\n",
    "resultsdf = pd.DataFrame({'length_scale':[0.0]*(n_lengthscale*n_const),'const':[0.0]*(n_lengthscale*n_const),'AUC':[0.0]*(n_lengthscale*n_const),\"log-likelihood\":[0.0]*(n_lengthscale*n_const),\"entropy\":[0.0]*(n_lengthscale*n_const)})\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "for i in lengthscale:\n",
    "    for j in const:\n",
    "        kernel = j*RBF(i)\n",
    "        gpc = GaussianProcessClassifier(kernel=kernel,optimizer=None).fit(X, Y)\n",
    "        \n",
    "        #y_probas = cross_val_predict(gpc,X_train,y_train,cv=5,method=\"predict_proba\")\n",
    "        #y_scores = y_probas[:,1]\n",
    "        resultsdf.iloc[iteration]['AUC'] = calc_AUC(gpc,X_train,y_train)\n",
    "        \n",
    "        resultsdf.iloc[iteration]['log-likelihood'] = gpc.log_marginal_likelihood(theta=None, eval_gradient=False, clone_kernel=True)\n",
    "        \n",
    "        resultsdf.iloc[iteration]['length_scale'] = i\n",
    "        resultsdf.iloc[iteration]['const'] = j\n",
    "        \n",
    "        \n",
    "        resultsdf.iloc[iteration]['entropy'] = calc_entropy(gpc,X_test,y_test)\n",
    "        \n",
    "\n",
    "        #r = permutation_importance(gpc,X_test,y_test,n_repeats=30,random_state=0)\n",
    "        #temp = abs(r.importances_mean)\n",
    "        #tempnew = temp/sum(temp)\n",
    "        #vector1 = np.array(tempnew)\n",
    "        #vector2 = np.array(log_calc(abs(r.importances_mean)))\n",
    "        #resultsdf.iloc[iteration]['entropy'] = -1*np.dot(vector1,vector2)\n",
    "        \n",
    "        iteration+=1\n",
    "\n",
    "print(resultsdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "db0abaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsdf = resultsdf.sort_values(by=['entropy'])\n",
    "resultsdf = resultsdf.dropna() #Drop NaNs from too small variance models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0cc61202",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Consider dropping innacurate models. We do not care about these models and they could potentially alter the clustering '''\n",
    "\n",
    "max_accuracy = resultsdf['log-likelihood'].max()\n",
    "resultsdf = resultsdf.loc[resultsdf['log-likelihood'] > 1.2*max_accuracy]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "05a1cd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    length_scale    const       AUC  log-likelihood   entropy\n",
      "29         2.430  15.6215  0.998281      -21.382694  1.369002\n",
      "28         2.430  13.8945  0.998281      -21.919729  1.390333\n",
      "27         2.430  12.1675  0.998125      -22.574622  1.396001\n",
      "26         2.430  10.4405  0.997812      -23.394819  1.408616\n",
      "39         3.618  15.6215  0.998281      -23.580365  1.416452\n",
      "38         3.618  13.8945  0.998281      -24.307104  1.416452\n",
      "25         2.430   8.7135  0.997969      -24.459011  1.416750\n",
      "37         3.618  12.1675  0.998281      -25.184776  1.422992\n"
     ]
    }
   ],
   "source": [
    "print(resultsdf.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db17fd48",
   "metadata": {},
   "source": [
    "### Lets visualise the accuracy vs interpretability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6a8c63e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt = resultsdf.plot.scatter(x=\"entropy\",y=\"log-likelihood\")\n",
    "plt.scatter(resultsdf['entropy'],resultsdf['log-likelihood'])\n",
    "plt.xlabel(\"Feature entropy\")\n",
    "plt.ylabel(\"log-likelihood\")\n",
    "#plt.show()\n",
    "plt.savefig('clustergraph.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c3ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('clustergraph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6620d052",
   "metadata": {},
   "source": [
    "### We shall now apply K-means to identify the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7b309e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many clusters?3\n"
     ]
    }
   ],
   "source": [
    "n = input(\"How many clusters?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "99b110ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_scale</th>\n",
       "      <th>const</th>\n",
       "      <th>AUC</th>\n",
       "      <th>log-likelihood</th>\n",
       "      <th>entropy</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.430</td>\n",
       "      <td>15.6215</td>\n",
       "      <td>0.998281</td>\n",
       "      <td>-21.382694</td>\n",
       "      <td>1.369002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.430</td>\n",
       "      <td>13.8945</td>\n",
       "      <td>0.998281</td>\n",
       "      <td>-21.919729</td>\n",
       "      <td>1.390333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.430</td>\n",
       "      <td>12.1675</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>-22.574622</td>\n",
       "      <td>1.396001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.430</td>\n",
       "      <td>10.4405</td>\n",
       "      <td>0.997812</td>\n",
       "      <td>-23.394819</td>\n",
       "      <td>1.408616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3.618</td>\n",
       "      <td>15.6215</td>\n",
       "      <td>0.998281</td>\n",
       "      <td>-23.580365</td>\n",
       "      <td>1.416452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    length_scale    const       AUC  log-likelihood   entropy  cluster\n",
       "29         2.430  15.6215  0.998281      -21.382694  1.369002        2\n",
       "28         2.430  13.8945  0.998281      -21.919729  1.390333        2\n",
       "27         2.430  12.1675  0.998125      -22.574622  1.396001        0\n",
       "26         2.430  10.4405  0.997812      -23.394819  1.408616        0\n",
       "39         3.618  15.6215  0.998281      -23.580365  1.416452        0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=int(n))\n",
    "c_predicted = km.fit_predict(resultsdf[[\"log-likelihood\",\"entropy\"]])\n",
    "resultsdf[\"cluster\"]=c_predicted\n",
    "resultsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fc95e4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#First create a dictionary for colours:\n",
    "\n",
    "colour_dict = {\n",
    "  0: \"blue\",\n",
    "  1: \"red\",\n",
    "  2: \"green\",\n",
    "  3: \"cyan\",\n",
    "  4: \"magenta\",\n",
    "  5: \"yellow\",\n",
    "  6: \"black\",\n",
    "}\n",
    "\n",
    "data_frames = []\n",
    "\n",
    "for i in range(int(n)):\n",
    "    data_frames.append(resultsdf[resultsdf.cluster == i])\n",
    "    plt.scatter(data_frames[i].entropy,data_frames[i][\"log-likelihood\"],color=colour_dict[i])\n",
    "\n",
    "#df1 = resultsdf[resultsdf.cluster == 0]\n",
    "#df2 = resultsdf[resultsdf.cluster == 1]\n",
    "#df3 = resultsdf[resultsdf.cluster == 2]\n",
    "#df4 = resultsdf[resultsdf.cluster == 3]\n",
    "\n",
    "#plt.scatter(df1.entropy,df1[\"log-likelihood\"],color=\"blue\")\n",
    "#plt.scatter(df2.entropy,df2[\"log-likelihood\"],color=\"red\")\n",
    "#plt.scatter(df3.entropy,df3[\"log-likelihood\"],color=\"green\")\n",
    "#plt.scatter(df4.entropy,df4[\"log-likelihood\"],color=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ea079",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' It is possible that the user will not be happy with how the data has been assigned.\n",
    "Offer an option for them to redo the clustering . '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35196a",
   "metadata": {},
   "source": [
    "### We now need to select the median  model (based on entropy) from each of these clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1f780ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create a list of models and their accuracies:\n",
    "\n",
    "models = {}\n",
    "accuracies = []\n",
    "\n",
    "\n",
    "#Can't use median function because it finds an average for even sets\n",
    "\n",
    "for i in range(int(n)):\n",
    "    index = int(data_frames[i].shape[0]/2)\n",
    "    observation = data_frames[i].iloc[index]\n",
    "    #kernel = float(observation['const'])*RBF(float(observation['length_scale']))\n",
    "    #gp = GaussianProcessClassifier(kernel=kernel,optimizer=None).fit(X, Y)\n",
    "    models['model{}'.format(i)] = [observation['const'],observation['length_scale']]\n",
    "    accuracies.append(observation['log-likelihood'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55c8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can pull out the parameters we need\n",
    "\n",
    "print(models.get(\"model1\")[0])\n",
    "print(models.get(\"model1\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "90d51fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be our PIGEBaQ algorithm:\n",
    "\n",
    "import math\n",
    "\n",
    "def compute_zn(index,data,output_var,np_lengthscale,np_cov,np_mu):\n",
    "    x = np.array(data.iloc[[index]])\n",
    "\n",
    "    element1 = (output_var*math.sqrt(np.linalg.det(np_lengthscale)))/(math.sqrt(np.linalg.det(np_lengthscale+np_cov)))\n",
    "    element2 = np.linalg.inv(np_lengthscale+np_cov)\n",
    "    element3 = np.transpose(np_mu - x)\n",
    "    element4 = -0.5*np.matmul(np.transpose(-1*element3),np.matmul(element2,-1*element3))\n",
    "\n",
    "    zn = element1*math.exp(element4.item())*np.matmul(element2,element3)\n",
    "    return zn\n",
    "\n",
    "def compute_cov(x,y,var,l):  #x and y are each full observations (vectors)\n",
    "    d = 0\n",
    "    m = len(x)\n",
    "    for i in range(m):\n",
    "        d += (x[i]-y[i])**2\n",
    "    val = var*np.exp(-0.5*d/(l**2))\n",
    "    return val\n",
    "\n",
    "\n",
    "def PIGEBaQ(data,var,length):\n",
    "    \n",
    "    this_df = data.dropna()\n",
    "    this_df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    mu = list(this_df.mean(axis='index'))\n",
    "    del mu[-1]\n",
    "    m = len(mu)\n",
    "    n = len(this_df.index)\n",
    "    np_mu = np.array(mu)\n",
    "    \n",
    "    this_df2 = this_df.drop(columns=['Output'])\n",
    "    df_cov = this_df2.cov()\n",
    "    np_cov = df_cov.to_numpy()\n",
    "    \n",
    "    np_lengthscale = length*np.identity(m)\n",
    "    \n",
    "    Z = [0]*n\n",
    "    for i in range(0,n):\n",
    "        Z[i] = compute_zn(i,this_df2,var,np_lengthscale,np_cov,np_mu)\n",
    "    \n",
    "    Z = np.array(Z)\n",
    "    Z = np.transpose(Z)\n",
    "    Z = Z.reshape(m,n)\n",
    "    \n",
    "    X = this_df2.to_numpy() #Each row is an abservation, each column is a variable\n",
    "    \n",
    "    num = this_df2.shape[0]\n",
    "    K = np.empty([num,num])\n",
    "\n",
    "    #Now lets start filling this matrix:\n",
    "    \n",
    "    for i in range(num):\n",
    "        for j in range(num):\n",
    "            K[i,j] = compute_cov(X[i,:],X[j,:],var,length)\n",
    "    \n",
    "    f = this_df[\"Output\"].to_numpy()\n",
    "    f = f.reshape(n)\n",
    "    \n",
    "    E = np.matmul(Z,np.matmul(np.linalg.inv(K),f))\n",
    "    \n",
    "    output_df = pd.DataFrame({\"Skills\":this_df2.columns,\"Importance\":E})\n",
    "    output_df = output_df.sort_values(by=\"Importance\")\n",
    "    output_df.reset_index(drop=True, inplace = True)\n",
    "    \n",
    "    output_df['Importance'] = output_df['Importance']/math.sqrt(output_df['Importance'].pow(2).sum()) #Normalizes values\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b7e7f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data_PIG = scaled_total_set.drop(columns=['O*NET-SOC Code', 'Title'])\n",
    "input_data_PIG = scaled_total_set.copy()\n",
    "\n",
    "tables = []\n",
    "\n",
    "for i in range(int(n)):\n",
    "    tables.append(PIGEBaQ(input_data_PIG,models.get(\"model{}\".format(i))[0],models.get(\"model{}\".format(i))[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ea9dddad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skills</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feature3</td>\n",
       "      <td>-0.539591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feature1</td>\n",
       "      <td>-0.178142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feature4</td>\n",
       "      <td>-0.136442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feature2</td>\n",
       "      <td>0.811475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Skills  Importance\n",
       "0  Feature3   -0.539591\n",
       "1  Feature1   -0.178142\n",
       "2  Feature4   -0.136442\n",
       "3  Feature2    0.811475"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8bcef37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " <ipython-input-129-2c5ce980b0df>:13: SettingWithCopyWarning:\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feature3</td>\n",
       "      <td>-0.539591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feature1</td>\n",
       "      <td>-0.178142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feature4</td>\n",
       "      <td>-0.136442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feature2</td>\n",
       "      <td>0.811475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features  Importance\n",
       "0  Feature3   -0.539591\n",
       "1  Feature1   -0.178142\n",
       "2  Feature4   -0.136442\n",
       "3  Feature2    0.811475"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We shall now generate a single dataframe which has the weighted explanations:\n",
    "\n",
    "explanations_df = pd.DataFrame({\"Features\":np.array(scaled_total_set.columns[0:4])})\n",
    "explanations_df[\"Importance\"] = 0.0\n",
    "#explanations_df\n",
    "\n",
    "model = tables[0] #This is the relevant importance dataframe\n",
    "\n",
    "#explanations_df[\"Importance\"][0] = (accuracies[0]/sum(accuracies))*model['Importance'][model.index[model['Skills'] == explanations_df['Features'][0]]]\n",
    "for j in range(int(n)):\n",
    "    model = tables[j]\n",
    "    for i in range(int(explanations_df.shape[0])):\n",
    "        explanations_df[\"Importance\"][i] += (accuracies[j]/sum(accuracies))*model['Importance'][model.index[model['Skills'] == explanations_df['Features'][i]]]\n",
    "\n",
    "\n",
    "explanations_df = explanations_df.sort_values(by=[\"Importance\"],ascending=True)\n",
    "explanations_df.reset_index(drop = True, inplace = True)\n",
    "explanations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbca202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explanations_df.to_csv(\"perm_PIGEBaQ.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b0221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the moment, we shall generate an explanation based on feature importance across the different clusters:\n",
    "\n",
    "\n",
    "tables = []\n",
    "\n",
    "for i in range(int(n)):\n",
    "    tables.append(pd.DataFrame({\"Features\":np.array(training_set.columns[2:37])}))\n",
    "\n",
    "\n",
    "for i in range(int(n)):\n",
    "    r = permutation_importance(models[i],X_test,y_test,n_repeats=30,random_state=0)\n",
    "    #tables[i][\"Importances\"] = abs(r.importances_mean)\n",
    "    tables[i][\"Importances\"] = r.importances_mean\n",
    "    tables[i] = tables[i].sort_values(by=[\"Importances\"],ascending=False)\n",
    "    tables[i].reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "#for i in range(int(n)):\n",
    "    #r = permutation_importance(models[i],X_test,y_test,n_repeats=30,random_state=0)\n",
    "    #importance_table[\"Importances{}\".format(i)] = abs(r.importances_mean)\n",
    "    #importance_table = importance_table.sort_values(by=['Importances{}'.format(i)])\n",
    "\n",
    "#NOTE - I'm uneasy about using the same test sets as before, should I expand to the unknown jobs?\n",
    "\n",
    "importance_dict = {}\n",
    "for i in range(int(n)):\n",
    "    q = tables[i]\n",
    "    importance_dict[\"Importance{}\".format(i)] = q[\"Features\"]\n",
    "#q = tables[1]\n",
    "#importance_dict[\"Importance1\"] = q[\"Features\"]\n",
    "importance_table = pd.DataFrame(data=importance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d12e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a9c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(importance_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec713c4",
   "metadata": {},
   "source": [
    "### We now have a table of features sorted by how important they are for each cluster, based on the permutation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4994965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We shall generate one more table, which will have a row for each feature and a score for how important it is:\n",
    "\n",
    "final_importance_table = pd.DataFrame({\"Features\":np.array(training_set.columns[2:37]),\"Importance\":np.zeros(np.shape(training_set.columns[2]))})\n",
    "feature_list = final_importance_table['Features'].tolist()\n",
    "#final_importance_table.head()\n",
    "for i in feature_list:\n",
    "    for j in range(int(n)):\n",
    "        index_val = importance_table.index[importance_table[\"Importance{}\".format(j)]==i]\n",
    "        index_val = index_val*accuracies[j]/sum(accuracies)\n",
    "        final_importance_table.loc[final_importance_table[\"Features\"]==i,\"Importance\"] += index_val.tolist()[0]\n",
    "    \n",
    "final_importance_table = final_importance_table.sort_values(by=[\"Importance\"],ascending=True)\n",
    "final_importance_table.reset_index(drop = True, inplace = True)\n",
    "final_importance_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e26c97",
   "metadata": {},
   "source": [
    "### We now have a table which ranks features by importance across all the clusters! Note that is values each cluster equally - this might be something we can improve upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1470c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets divert our attention towards making predictions on our unknown jobs:\n",
    "\n",
    "unknown_jobs = df4[df4.isna().any(axis=1)] #This is our set of unknown jobs\n",
    "#SCALE THE DATA! - Do I need to fit a new scaler?\n",
    "X = scaler.transform(unknown_jobs.iloc[:,2:37])\n",
    "#X = np.array(unknown_jobs.iloc[:,2:37])\n",
    "print(X)\n",
    "#for i in int(n):\n",
    "    #models[i].predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = gpc.predict_proba(X)\n",
    "test1 = gpc.predict(X)\n",
    "test2 = gpc.predict_proba(X)\n",
    "print(test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7555bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now fill in the dataframe:\n",
    "\n",
    "unknown_jobs[\"Auto label value\"] = test1\n",
    "unknown_jobs[\"Auto probability\"] = test2[:,1]\n",
    "unknown_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b143b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_jobs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a8b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets think about how we can apply the model from each of our clusters and compute an average:\n",
    "\n",
    "for i in range(int(n)):\n",
    "    probs = models[i].predict_proba(X)\n",
    "    unknown_jobs[\"Auto probability{}\".format(i)] = probs[:,1]\n",
    "\n",
    "#We need a list of column titles:\n",
    "column_titles = []\n",
    "for i in range(int(n)):\n",
    "    column_titles.append(\"Auto probability{}\".format(i))\n",
    "\n",
    "#Now calculate mean automotability    \n",
    "\n",
    "unknown_jobs[\"Auto probability\"] = unknown_jobs[column_titles].mean(axis=1)\n",
    "\n",
    "#And finally apply a function to determine auto-label value:\n",
    "\n",
    "def label_auto(my_input):\n",
    "    if my_input - 0.5 < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "unknown_jobs[\"Auto label value\"] = unknown_jobs[\"Auto probability\"].apply(label_auto)\n",
    "\n",
    "unknown_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d836b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unknown_jobs[\"Title\"][\"i\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f475056f",
   "metadata": {},
   "source": [
    "### We have now generated values for automotability!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
