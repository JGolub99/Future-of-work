{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e133cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This version hitches PIGEBaQ onto the permutation method '''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"Skills.xlsx\")\n",
    "#print(df.head())\n",
    "\n",
    "#Lets remove the importance values:\n",
    "\n",
    "df2 = df.loc[df[\"Scale Name\"] == \"Level\"]\n",
    "df2.reset_index(drop = True, inplace = True)\n",
    "#print(df2.head())\n",
    "\n",
    "#Lets now remove the irrelevent columns:\n",
    "\n",
    "df3 = df2.drop(columns = [\"Scale ID\",\"Scale Name\",\"N\",\"Recommend Suppress\",\"Not Relevant\",\"Date\",\"Domain Source\"])\n",
    "print(df3.head())\n",
    "\n",
    "#NOTE that we have ignored the suppress recomendations, we shall continue with this for now but will need to address this later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420df498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now discover a bit about our data set:\n",
    "\n",
    "df3.info()\n",
    "\n",
    "#We note that there are some occupations for which the standard error and bound values are missing. Lets supress these for now:\n",
    "\n",
    "df3.drop(columns = [\"Standard Error\",\"Lower CI Bound\",\"Upper CI Bound\"],inplace = True)\n",
    "print(df3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a1537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#I shall implement the drop_duplicates method:\n",
    "\n",
    "df4 = df3[[\"O*NET-SOC Code\",\"Title\"]]\n",
    "df4.drop_duplicates(inplace=True)\n",
    "df4.reset_index(drop = True, inplace = True)\n",
    "#print(df4.head())\n",
    "\n",
    "#We now need to add the variables. Begin by adding empty columns to the dataframe:\n",
    "\n",
    "n_jobs = len(set((df3[\"Title\"])))\n",
    "n_variables = len(set((df3[\"Element Name\"])))\n",
    "\n",
    "for i in range(n_jobs):\n",
    "    df4[df3[\"Element Name\"][i]] = \"\"\n",
    "\n",
    "#print(df4.head())\n",
    "#Now we need to fill these columns:\n",
    "\n",
    "x = df3.loc[df3[\"Title\"] == \"Chief Executives\"]\n",
    "y = x[\"Data Value\"]\n",
    "\n",
    "for i in range(n_variables):\n",
    "    df4[df4.columns[2+i]][0] = y[i]\n",
    "    \n",
    "#We now need to do this procedure for every job:\n",
    "\n",
    "for j in range(n_jobs):\n",
    "    x = df3.loc[df3[\"Title\"] == df4.iloc[j,1]]\n",
    "    y = x[\"Data Value\"]\n",
    "    y.reset_index(drop = True, inplace = True)\n",
    "    for i in range(n_variables):\n",
    "        df4[df4.columns[2+i]][j] = y[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0748248",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df4.head())\n",
    "print(df4.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194be949",
   "metadata": {},
   "source": [
    "### We now have the skills dataframe just as we want it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edae9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets understand our data a bit:\n",
    "\n",
    "df4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb3b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "hist = df4.iloc[:,20].hist(bins=20)\n",
    "\n",
    "#We can inspect the histogram of any variable we want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3628f6e5",
   "metadata": {},
   "source": [
    "### Let's now  import another dataframe with autovalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87641e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_excel(\"US_data_email.xls\")\n",
    "df5 = df5[[\"Occupation Name\",\"BLS codes\",\"Training set automatable labels\"]]\n",
    "print(df5.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40868f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422495f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets define a function so that we can make occupation ID's consistent:\n",
    "\n",
    "def title_set(my_string):\n",
    "    my_list = []\n",
    "    my_list[:0] = my_string\n",
    "    my_list.remove(\"_\")\n",
    "    my_list.append(\".00\")\n",
    "    my_output = \"\".join(my_list)\n",
    "    return my_output\n",
    "\n",
    "#print(title_set(\"45-4023_\"))\n",
    "\n",
    "df5.iloc[:,1] = df5.iloc[:,1].apply(title_set)\n",
    "print(df5.head())\n",
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88670d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now concatenate the auto labels to our 1st dataframe:\n",
    "import numpy as np\n",
    "df4[\"Auto label value\"] = np.nan\n",
    "for i in list(df5[\"BLS codes\"]):\n",
    "    df4.loc[df4[\"O*NET-SOC Code\"] == i,\"Auto label value\"] = list(df5.loc[df5[\"BLS codes\"] == i,\"Training set automatable labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.info()\n",
    "\n",
    "#Note - the auto value count is supposedly 330 non-null, even though it should be 70. After creating a csv from the dataframe,\n",
    "#I found that there were 70 non-null as expected. Worth bringing up with Mike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv(\"test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035d0d9",
   "metadata": {},
   "source": [
    "### START FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec8cea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.835124</td>\n",
       "      <td>1.211726</td>\n",
       "      <td>1.624049</td>\n",
       "      <td>1.004157</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.071587</td>\n",
       "      <td>4.027580</td>\n",
       "      <td>2.457672</td>\n",
       "      <td>3.331458</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.426488</td>\n",
       "      <td>2.066718</td>\n",
       "      <td>4.414327</td>\n",
       "      <td>3.825741</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.352256</td>\n",
       "      <td>2.995869</td>\n",
       "      <td>4.370891</td>\n",
       "      <td>3.066830</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.517934</td>\n",
       "      <td>4.158626</td>\n",
       "      <td>3.029461</td>\n",
       "      <td>2.430427</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3  Output\n",
       "0  3.835124  1.211726  1.624049  1.004157     0.0\n",
       "1  2.071587  4.027580  2.457672  3.331458     1.0\n",
       "2  2.426488  2.066718  4.414327  3.825741     0.0\n",
       "3  1.352256  2.995869  4.370891  3.066830     0.0\n",
       "4  3.517934  4.158626  3.029461  2.430427     1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df4 = pd.read_csv(\"C:/Users/jacob/Documents/4YP data/DataSynthesis/4x400/data.csv\")\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e2d9a8",
   "metadata": {},
   "source": [
    "### We now have a dataset which encompass jobs titles, SOC codes, skill levels and hand picked auto labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d2e87",
   "metadata": {},
   "source": [
    "### Lets now split and standardize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc1e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To prevent information about the distribution of the test set leaking into the model, we shall first form a training set\n",
    "# and form a scaler operator from this, and then apply this to both training and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0fc4bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       400 non-null    float64\n",
      " 1   1       400 non-null    float64\n",
      " 2   2       400 non-null    float64\n",
      " 3   3       400 non-null    float64\n",
      " 4   Output  400 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 15.8 KB\n"
     ]
    }
   ],
   "source": [
    "#Lets now create a training set which includes only the jobs for which we have hand picked auto values:\n",
    "\n",
    "training_set = df4.dropna(axis=0,how=\"any\")\n",
    "training_set.reset_index(drop = True, inplace=True)\n",
    "#print(training_set.head())\n",
    "training_set.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c955b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets apply stratified sampling on this set to create a training and test set\n",
    "#Code taken from Hands on Machine Learning book\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "for train_index, test_index in split.split(training_set,training_set[\"Output\"]):\n",
    "    strat_train_set = training_set.loc[train_index]\n",
    "    strat_test_set = training_set.loc[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04871038",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.reset_index(drop=True,inplace=True)\n",
    "strat_test_set.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7615f630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.596875\n",
       "0.0    0.403125\n",
       "Name: Output, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set[\"Output\"].value_counts()/len(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4985df74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Now that we have our training set, lets create a standardiser for it:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=True,with_std=True)\n",
    "scaler.fit(strat_train_set.iloc[:,0:4])\n",
    "scaled_training_values = scaler.transform(strat_train_set.iloc[:,0:4])\n",
    "scaled_test_values = scaler.transform(strat_test_set.iloc[:,0:4])\n",
    "scaled_train_set = strat_train_set.copy()\n",
    "scaled_test_set = strat_test_set.copy()\n",
    "#print(strat_train_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85fb4ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary = pd.DataFrame(data=scaled_training_values)\n",
    "temporary2 = pd.DataFrame(data=scaled_test_values) #we create temporary data frames from the numpy arrays we've just created\n",
    "#print(temporary)\n",
    "for i in range(0,4):\n",
    "    scaled_train_set[scaled_train_set.columns[i]] = temporary[temporary.columns[i]]\n",
    "    scaled_test_set[scaled_test_set.columns[i]] = temporary2[temporary2.columns[i]]\n",
    "\n",
    "#print(scaled_test_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0efe1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' We shall also create a standardized set for ALL of the training data '''\n",
    "\n",
    "scaler2 = StandardScaler(with_mean=True,with_std=True)\n",
    "scaler2.fit(strat_train_set.iloc[:,0:4])\n",
    "scaled_total_values = scaler2.transform(training_set.iloc[:,0:4])\n",
    "scaled_total_set = training_set.copy()\n",
    "\n",
    "temporary3 = pd.DataFrame(data=scaled_total_values)\n",
    "for i in range(0,4):\n",
    "    scaled_total_set[scaled_total_set.columns[i]] = temporary3[temporary3.columns[i]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d735dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3  Output\n",
      "0  0.133053  0.932260 -0.013206  1.286128     1.0\n",
      "1 -0.980303 -0.641193  0.329682  1.391070     0.0\n",
      "2 -0.721283 -1.148982 -0.658306  0.501491     0.0\n",
      "3 -0.053673  1.535281 -0.261184 -0.415526     1.0\n",
      "4  0.563639  0.053504 -1.477383  0.799030     1.0\n",
      "          0         1         2         3  Output\n",
      "0 -1.789544  1.029578  0.099279 -1.489730     0.0\n",
      "1  0.806575 -0.671544 -0.214983 -0.691150     1.0\n",
      "2 -1.039657  1.619364 -0.033028 -0.067394     1.0\n",
      "3  0.938450  0.787295 -1.009988 -1.070019     1.0\n",
      "4  0.204042  1.436096 -1.405826 -1.045106     1.0\n",
      "          0         1         2         3  Output\n",
      "0  0.659998 -1.501486 -1.264812 -1.672219     0.0\n",
      "1 -0.871561  0.935219 -0.531009  0.314569     1.0\n",
      "2 -0.563344 -0.761617  1.191349  0.736533     0.0\n",
      "3 -1.496270  0.042426  1.153114  0.088659     0.0\n",
      "4  0.384532  1.048620 -0.027688 -0.454630     1.0\n"
     ]
    }
   ],
   "source": [
    "print(scaled_train_set.head())\n",
    "print(scaled_test_set.head())\n",
    "print(scaled_total_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a67dc1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 320 entries, 0 to 319\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       320 non-null    float64\n",
      " 1   1       320 non-null    float64\n",
      " 2   2       320 non-null    float64\n",
      " 3   3       320 non-null    float64\n",
      " 4   Output  320 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 12.6 KB\n"
     ]
    }
   ],
   "source": [
    "scaled_train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0469304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_total_set.to_csv(\"PIGEBAQ_testset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5c7ed",
   "metadata": {},
   "source": [
    "### We now have a fully scaled training and test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78aad85",
   "metadata": {},
   "source": [
    "### We can now perform Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dfe4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We begin by creating a centred training set:\n",
    "\n",
    "X = strat_train_set.drop([\"Title\",\"O*NET-SOC Code\"],axis=1)\n",
    "\n",
    "#We now use the Scikit learn toolkit to visualise how the explained variance ratio changes with no. dimensions:\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "dim = range(len(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea62cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.array(dim),np.array(cumsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Having visualized the effect of dimensionality, we can implement this to our dataset:\n",
    "\n",
    "pca2 = PCA(n_components=0.95)\n",
    "X_reduced = pca2.fit_transform(X)\n",
    "print(X_reduced[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badabc02",
   "metadata": {},
   "source": [
    "### We shall now fit a GP classifier to the unreduced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30b04605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74967fc9e86a4eb797ee85a29c5f62bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntProgress(value=0, max=1000), HTML(value=''))), Box(children=(HTML(value=''),)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<paramz.optimization.optimization.opt_lbfgsb at 0x2072dae57c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Begin by creating numpy arrays for our input X and output Y:\n",
    "\n",
    "#X = np.array([scaled_train_set.iloc[:,0:4]])\n",
    "#Y = np.array([scaled_train_set.iloc[:,4]])\n",
    "X = np.array([scaled_total_set.iloc[:,0:4]])\n",
    "Y = np.array([scaled_total_set.iloc[:,4]])\n",
    "#X = np.transpose(X)\n",
    "#Y = np.transpose(Y)\n",
    "\n",
    "\n",
    "X = np.reshape(X,(400,4)) #Reshape to go from 3d matrix to 2d\n",
    "Y = np.reshape(Y,(400,1)) # ^\n",
    "\n",
    "#Now generate a kernel:\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "import GPy\n",
    "\n",
    "kernel = GPy.kern.RBF(input_dim=4, variance=100., lengthscale=100.)\n",
    "m_gpy = GPy.models.GPClassification(X,Y,kernel)\n",
    "m_gpy.optimize(messages=True)\n",
    "#m_gpy.optimize_restarts(num_restarts = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5691efad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the rbf.variance?2.59\n",
      "What is the rbf.lengthscale?2.33\n"
     ]
    }
   ],
   "source": [
    "#We shall request values for the variance and lengthscale:\n",
    "\n",
    "m_var = input(\"What is the rbf.variance?\")\n",
    "m_length = input(\"What is the rbf.lengthscale?\")\n",
    "\n",
    "m_var = float(m_var)\n",
    "m_length = float(m_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e436ff7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "#Instantiate this model in scikit learn\n",
    "\n",
    "\n",
    "sci_kernel = m_var * RBF(m_length)\n",
    "gpc = GaussianProcessClassifier(kernel=sci_kernel,optimizer=None).fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13de51ce",
   "metadata": {},
   "source": [
    "### Lets now apply k-fold cross validation on the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56997c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(scaled_train_set.iloc[:,0:4])\n",
    "#X_train = np.transpose(X_train)\n",
    "y_train = np.array(scaled_train_set.iloc[:,4])\n",
    "#y_train = np.transpose(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6974f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953125\n",
      "0.984375\n",
      "0.90625\n",
      "0.984375\n",
      "0.875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train,y_train):\n",
    "    clone_gpc = clone(gpc)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train[test_index]\n",
    "    \n",
    "    clone_gpc.fit(X_train_folds,y_train_folds)\n",
    "    y_pred = clone_gpc.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct/len(y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68786926",
   "metadata": {},
   "source": [
    "### What about an F1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "185668f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.953125"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_train_pred = cross_val_predict(gpc,X_train,y_train,cv=5)\n",
    "f1_score(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c6f32",
   "metadata": {},
   "source": [
    "### And how about an AUC value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "40910d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9853890174114209"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def calc_AUC(gpc,X_train,y_train):\n",
    "    y_probas = cross_val_predict(gpc,X_train,y_train,cv=5,method=\"predict_proba\")\n",
    "    y_scores = y_probas[:,1]\n",
    "    return roc_auc_score(y_train,y_scores)\n",
    "\n",
    "calc_AUC(gpc,X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1ddfdf",
   "metadata": {},
   "source": [
    "### And a log-likelihood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "424fa99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-102.07240497260634"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpc.log_marginal_likelihood(theta=None, eval_gradient=False, clone_kernel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d78e0",
   "metadata": {},
   "source": [
    "### It is worth using the model to predict values for the test set to ensure it is working as I want it to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4d045d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(scaled_test_set.iloc[:,0:4])\n",
    "y_test = np.array(scaled_test_set.iloc[:,4])\n",
    "\n",
    "y_pred = gpc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09f0c78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0.\n",
      " 0. 1. 1. 0. 1. 1. 0. 0.]\n",
      "[0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c8f8dc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90097646, 0.09902354],\n",
       "       [0.071068  , 0.928932  ],\n",
       "       [0.41592497, 0.58407503],\n",
       "       [0.01441868, 0.98558132],\n",
       "       [0.05739527, 0.94260473],\n",
       "       [0.13271286, 0.86728714],\n",
       "       [0.7132241 , 0.2867759 ],\n",
       "       [0.03872004, 0.96127996],\n",
       "       [0.2529531 , 0.7470469 ],\n",
       "       [0.22225483, 0.77774517],\n",
       "       [0.03317073, 0.96682927],\n",
       "       [0.92052666, 0.07947334],\n",
       "       [0.1902619 , 0.8097381 ],\n",
       "       [0.11770583, 0.88229417],\n",
       "       [0.58577065, 0.41422935],\n",
       "       [0.93637312, 0.06362688],\n",
       "       [0.68202937, 0.31797063],\n",
       "       [0.03384754, 0.96615246],\n",
       "       [0.76077422, 0.23922578],\n",
       "       [0.04625596, 0.95374404],\n",
       "       [0.01283088, 0.98716912],\n",
       "       [0.93925819, 0.06074181],\n",
       "       [0.07852023, 0.92147977],\n",
       "       [0.04369392, 0.95630608],\n",
       "       [0.29686984, 0.70313016],\n",
       "       [0.44367483, 0.55632517],\n",
       "       [0.00834391, 0.99165609],\n",
       "       [0.90872824, 0.09127176],\n",
       "       [0.48010069, 0.51989931],\n",
       "       [0.23360073, 0.76639927],\n",
       "       [0.70576455, 0.29423545],\n",
       "       [0.07653143, 0.92346857],\n",
       "       [0.00660504, 0.99339496],\n",
       "       [0.69053746, 0.30946254],\n",
       "       [0.06776953, 0.93223047],\n",
       "       [0.00670403, 0.99329597],\n",
       "       [0.72746802, 0.27253198],\n",
       "       [0.25208162, 0.74791838],\n",
       "       [0.12095198, 0.87904802],\n",
       "       [0.01782706, 0.98217294],\n",
       "       [0.16970862, 0.83029138],\n",
       "       [0.98563178, 0.01436822],\n",
       "       [0.98957793, 0.01042207],\n",
       "       [0.89956139, 0.10043861],\n",
       "       [0.01347129, 0.98652871],\n",
       "       [0.63193761, 0.36806239],\n",
       "       [0.30945089, 0.69054911],\n",
       "       [0.00839308, 0.99160692],\n",
       "       [0.85101922, 0.14898078],\n",
       "       [0.51311151, 0.48688849],\n",
       "       [0.19479083, 0.80520917],\n",
       "       [0.00572846, 0.99427154],\n",
       "       [0.0447082 , 0.9552918 ],\n",
       "       [0.18417964, 0.81582036],\n",
       "       [0.66580238, 0.33419762],\n",
       "       [0.96527726, 0.03472274],\n",
       "       [0.00816776, 0.99183224],\n",
       "       [0.91113855, 0.08886145],\n",
       "       [0.99367151, 0.00632849],\n",
       "       [0.08105857, 0.91894143],\n",
       "       [0.95419245, 0.04580755],\n",
       "       [0.30122482, 0.69877518],\n",
       "       [0.33285359, 0.66714641],\n",
       "       [0.01831447, 0.98168553],\n",
       "       [0.94136849, 0.05863151],\n",
       "       [0.00979719, 0.99020281],\n",
       "       [0.84279206, 0.15720794],\n",
       "       [0.97535853, 0.02464147],\n",
       "       [0.05567895, 0.94432105],\n",
       "       [0.88933263, 0.11066737],\n",
       "       [0.0323281 , 0.9676719 ],\n",
       "       [0.94832053, 0.05167947],\n",
       "       [0.65671771, 0.34328229],\n",
       "       [0.07231393, 0.92768607],\n",
       "       [0.02589423, 0.97410577],\n",
       "       [0.19629825, 0.80370175],\n",
       "       [0.39871024, 0.60128976],\n",
       "       [0.01441352, 0.98558648],\n",
       "       [0.98299676, 0.01700324],\n",
       "       [0.98556605, 0.01443395]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd5b80",
   "metadata": {},
   "source": [
    "### We now have a fully working GP classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52436a7e",
   "metadata": {},
   "source": [
    "### Lets now consider the interpretability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c840583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Features  Importances\n",
      "2        2     0.008750\n",
      "3        3     0.030417\n",
      "1        1     0.147500\n",
      "0        0     0.390000\n"
     ]
    }
   ],
   "source": [
    "#We shall use the feature permutation method:\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "feature_importance = pd.DataFrame({\"Features\":np.array(training_set.columns[0:4])})\n",
    "\n",
    "r = permutation_importance(gpc,X_test,y_test,n_repeats=30,random_state=0)\n",
    "feature_importance[\"Importances\"] = abs(r.importances_mean)\n",
    "feature_importance = feature_importance.sort_values(by=['Importances'])\n",
    "#feature_importance = feature_importance\n",
    "print(feature_importance)\n",
    "#print(r.importances_mean)\n",
    "\n",
    "#for i in r.importances_mean.argsort()[::-1]:\n",
    "#    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "#        print(f\"{feature_importance.Features[i]:<8}\"\n",
    "#        f\"{r.importances_mean[i]:.3f}\"\n",
    "#        f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb49c78",
   "metadata": {},
   "source": [
    "### Now that we have the feature importances, lets calculate the entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "79ce2fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3824857911710033\n"
     ]
    }
   ],
   "source": [
    "# For the moment we won't normalise the distribution - might have to do this in the future (ask Mike)\n",
    "\n",
    "def log_calc(my_list):    #This function deals with values of 0\n",
    "    my_output = [0]*len(my_list)\n",
    "    for i in range(len(my_list)):\n",
    "        if my_list[i] != 0.0:\n",
    "            my_output[i] = np.log(my_list[i])\n",
    "    return my_output        \n",
    "            \n",
    "temp = abs(r.importances_mean)\n",
    "tempnew = temp/sum(temp)\n",
    "vector1 = np.array(tempnew)\n",
    "vector2 = np.array(log_calc(abs(r.importances_mean)))\n",
    "entropy = -1*np.dot(vector1,vector2)\n",
    "print(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "16486e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3824857911710033"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets create a function that does all of this:\n",
    "\n",
    "def calc_entropy(gpc,X_test,y_test):\n",
    "    r = permutation_importance(gpc,X_test,y_test,n_repeats=30,random_state=0)\n",
    "    temp = abs(r.importances_mean)\n",
    "    tempnew = temp/sum(temp)\n",
    "    vector1 = np.array(tempnew)\n",
    "    vector2 = np.array(log_calc(abs(r.importances_mean)))\n",
    "    return -1*np.dot(vector1,vector2)\n",
    "\n",
    "calc_entropy(gpc,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d928b",
   "metadata": {},
   "source": [
    "### Lets now implement a gridsearch method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c3e52523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   length_scale   const       AUC  log-likelihood   entropy\n",
      "0        0.0233  0.0259  0.507752     -277.262969  1.474790\n",
      "1        0.0233  0.5957  0.512906     -278.658661  1.474366\n",
      "2        0.0233  1.1655  0.512906     -280.937452  1.474366\n",
      "3        0.0233  1.7353  0.512906     -283.156881  1.474366\n",
      "4        0.0233  2.3051  0.512906     -285.108449  1.474366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "#Lets try manually creating the functions:\n",
    "\n",
    "n_lengthscale = 10\n",
    "n_const = 10\n",
    "\n",
    "#The above values control the number of different hyperparaemters we want to test on\n",
    "\n",
    "lengthscale = np.linspace(0.01*m_length,1.99*m_length,n_lengthscale)\n",
    "const = np.linspace(0.01*m_var,1.99*m_var,n_const)\n",
    "\n",
    "resultsdf = pd.DataFrame({'length_scale':[0.0]*(n_lengthscale*n_const),'const':[0.0]*(n_lengthscale*n_const),'AUC':[0.0]*(n_lengthscale*n_const),\"log-likelihood\":[0.0]*(n_lengthscale*n_const),\"entropy\":[0.0]*(n_lengthscale*n_const)})\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "for i in lengthscale:\n",
    "    for j in const:\n",
    "        kernel = j*RBF(i)\n",
    "        gpc = GaussianProcessClassifier(kernel=kernel,optimizer=None).fit(X, Y)\n",
    "        \n",
    "        #y_probas = cross_val_predict(gpc,X_train,y_train,cv=5,method=\"predict_proba\")\n",
    "        #y_scores = y_probas[:,1]\n",
    "        resultsdf.iloc[iteration]['AUC'] = calc_AUC(gpc,X_train,y_train)\n",
    "        \n",
    "        resultsdf.iloc[iteration]['log-likelihood'] = gpc.log_marginal_likelihood(theta=None, eval_gradient=False, clone_kernel=True)\n",
    "        \n",
    "        resultsdf.iloc[iteration]['length_scale'] = i\n",
    "        resultsdf.iloc[iteration]['const'] = j\n",
    "        \n",
    "        \n",
    "        resultsdf.iloc[iteration]['entropy'] = calc_entropy(gpc,X_test,y_test)\n",
    "        \n",
    "\n",
    "        #r = permutation_importance(gpc,X_test,y_test,n_repeats=30,random_state=0)\n",
    "        #temp = abs(r.importances_mean)\n",
    "        #tempnew = temp/sum(temp)\n",
    "        #vector1 = np.array(tempnew)\n",
    "        #vector2 = np.array(log_calc(abs(r.importances_mean)))\n",
    "        #resultsdf.iloc[iteration]['entropy'] = -1*np.dot(vector1,vector2)\n",
    "        \n",
    "        iteration+=1\n",
    "\n",
    "print(resultsdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "db0abaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsdf = resultsdf.sort_values(by=['entropy'])\n",
    "resultsdf = resultsdf.dropna() #Drop NaNs from too small variance models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0cc61202",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Consider dropping innacurate models. We do not care about these models and they could potentially alter the clustering '''\n",
    "\n",
    "max_accuracy = resultsdf['log-likelihood'].max()\n",
    "resultsdf = resultsdf.loc[resultsdf['log-likelihood'] > 1.2*max_accuracy]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05a1cd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    length_scale   const       AUC  log-likelihood   entropy\n",
      "59        2.5863  5.1541  0.985551      -92.073171  1.373708\n",
      "69        3.0989  5.1541  0.981777      -97.802886  1.380355\n",
      "57        2.5863  4.0145  0.984374      -96.465665  1.380575\n",
      "58        2.5863  4.5843  0.985105      -94.083335  1.386435\n",
      "45        2.0737  2.8749  0.987702      -96.966962  1.389198\n",
      "47        2.0737  4.0145  0.988717      -90.562028  1.390088\n",
      "46        2.0737  3.4447  0.988311      -93.403504  1.390310\n",
      "48        2.0737  4.5843  0.989042      -88.222682  1.396925\n",
      "49        2.0737  5.1541  0.989448      -86.249994  1.399218\n",
      "26        1.0485  3.4447  0.994927      -98.390247  1.404297\n",
      "27        1.0485  4.0145  0.995130      -95.403088  1.406370\n",
      "28        1.0485  4.5843  0.995211      -92.988376  1.413216\n",
      "38        1.5611  4.5843  0.992979      -84.700286  1.413859\n",
      "39        1.5611  5.1541  0.993303      -82.761083  1.413940\n",
      "29        1.0485  5.1541  0.995292      -90.988332  1.414200\n",
      "35        1.5611  2.8749  0.992370      -93.412239  1.415097\n",
      "36        1.5611  3.4447  0.992654      -89.842464  1.415317\n",
      "37        1.5611  4.0145  0.992816      -87.014115  1.415635\n",
      "34        1.5611  2.3051  0.991680      -98.123166  1.418176\n"
     ]
    }
   ],
   "source": [
    "print(resultsdf.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db17fd48",
   "metadata": {},
   "source": [
    "### Lets visualise the accuracy vs interpretability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a8c63e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcn0lEQVR4nO3deZRc5Xnn8e8PIew2QjRBIkSCjjBGcswmUIHNEoMFIzkhMTJrMFkwGHnGjDMmhx7DkXGCGQ+LiAMktrGCg4PXSZBQWGwEQgaxBrcsQAgQTAAztDhGgMUWYYR45o/7ttUS1V11q7vq1vL7nNOnb713e+oi9Oi+qyICMzOzPLYpOgAzM2s9Th5mZpabk4eZmeXm5GFmZrk5eZiZWW5OHmZmllshyUPSdEn3S3pQUp+kg1P5qZIelrRK0r2S9i8iPjMzG15Rbx6XAhdExHTgy+kzwNPAERGxL3AhsKCY8MzMbDjbFnTfAMan7R2BtQARce+gY+4HdmtwXGZmVgUVMcJc0u8BSwCRvf0cGhG/2OqYc4APRsRnKl1vwoQJMWXKlHqEambWtlasWPFiREys5dy6vXlIWgrsWmbXPOAo4OyIWCjpJODbwNGDzv0YcAZw+DDXnwvMBejp6aGvr28Uozcza3+SflH5qCHOLejN4xWgOyJCkoBXImJ82rcfcD3wBxHxRDXXK5VK4eRhZpaPpBURUarl3KIazNcCR6TtmcCTAJJ6gEXAn1WbOMzMrPGKajA/E7hC0rbAm6TqJ7KeVzsD38heSHi71qxoZmb1U0jyiIi7gRllyj8DVGwgNzOzYnmEuZmZ5VZUtZWZWdtYvLKf+UvWsHb9BiZ1d9E7expzDphcdFh15eRhZjYCi1f2c96iVWzYuAmA/vUbOG/RKoC2TiCutjIzG4H5S9b8JnEM2LBxE/OXrCkoosZw8jAzG4G16zfkKm8XTh5mZiMwqbsrV3m7cPIwMxuB3tnT6Bo7ZouyrrFj6J09raCIGsMN5mZmIzDQKO7eVmZmlsucAya3fbLYmqutzMwsNycPMzPLzcnDzMxyc/IwM7PcnDzMzCw3Jw8zM8vNycPMzHIrLHlImi7pfkkPSuqTdPBW+w+S9LakE4qK0czMyivyzeNS4IKImE62/OylAzskjQEuAW4tJjQzMxtOkckjgPFpe0dg7aB9nwcWAi80OigzM6usyOlJvgAskXQZWRI7FEDSZOCTwMeAgwqLzszMhlTX5CFpKbBrmV3zgKOAsyNioaSTgG8DRwOXA1+MiHckDXftucBcgJ6enlGO3MzMhqOIKObG0itAd0SEsizxSkSMl/Q0MJA1JgD/CcyNiMVDXatUKkVfX1/dYzYzayeSVkREqZZzi6y2WgscAdwBzASeBIiIPQYOkPQd4KbhEoeZmTVekcnjTOAKSdsCb5KqoMzMrPkVljwi4m5gRoVjTmtMNGZmlodHmJuZWW5eSdDMbAQWr+zvuCVowcnDzKxmi1f2c96iVWzYuAmA/vUbOG/RKoC2TyCutjIzq9H8JWt+kzgGbNi4iflL1hQUUeM4eZiZ1Wjt+g25ytuJk4eZWY0mdXflKm8nTh5mZjXqnT2NrrFjtijrGjuG3tnTCoqocdxgbmZWo4FGcfe2MjOzXOYcMLkjksXWXG1lZma5OXmYmVluTh5mZpabk4eZmeXm5GFmZrk5eZiZWW5OHmZmlpuTh5mZ5VZI8pA0XdL9kh6U1Cfp4EH7jkzlqyXdWUR8ZmY2vKJGmF8KXBARP5H0h+nzkZK6gW8AH4+IZyXtUlB8ZmY2jKKqrQIYn7Z3BNam7U8BiyLiWYCIeKGA2MzMrIKi3jy+ACyRdBlZAjs0lU8Fxkq6A9gBuCIiri13AUlzgbkAPT099Y7XrGl06rKn1lzqljwkLQV2LbNrHnAUcHZELJR0EvBt4OgUz4y0vwu4T9L9EfHE1heJiAXAAoBSqRT1+RZmzaWTlz215lK35BERRw+1T9K1wP9IH/8VuDptPwe8FBFvAG9IWg7sD7wreZh1ouGWPXXysEYqqs1jLXBE2p4JPJm2/w04XNK2kt4HfBh4rID4zJpSJy97as2lqDaPM4ErJG0LvElqu4iIxyTdAjwMvANcHRGPFBSjWdOZ1N1Ff5lE0QnLnlpzKSR5RMTdZG0b5fbNB+Y3NiKz1tA7e9oWbR7QOcueWnPxSoJmLaSTlz215uLkYdZiOnXZU2suntvKzMxyc/IwM7PcXG1lZtZg7TBLgJOHmVkDtcssAa62MjNroOFmCWglTh5mZg3ULrMEOHmYmTXQULMBtNosAU4eZmYN1Dt7Gl1jx2xR1oqzBLjB3MysgdpllgAnDzOzBmuHWQJcbWVmZrk5eZiZWW5OHmZmlpuTh5mZ5VZY8pA0XdL9kh6U1Cfp4FS+o6QbJT0kabWkTxcVo5mZlVfkm8elwAURMR34cvoMcBbwaETsDxwJ/K2k7QqJ0MzMyioyeQQwPm3vCKwdVL6DJAHjgJeBtxsfnpmZDaXIcR5fAJZIuowsiR2ayv8BuIEsmewAnBwR7xQSoVkdtMN03GZ1TR6SlgK7ltk1DzgKODsiFko6Cfg2cDQwG3gQmAnsCdwm6a6IeHWra88F5gL09PTU7TuYjaZ2mY7bTBFRzI2lV4DuiIhURfVKRIyXdDNwcUTclY5bBpwbEQ8Mda1SqRR9fX2NCdxsBA67eBn9ZWZPndzdxT3nziwgIutkklZERKmWc4d985B0I1kbRFkR8YlabpqsBY4A7iB7y3gylT9L9lZyl6TfBqYBT43gPmZNo12m4zarVG11Wfp9HFn10/fS51OAX47w3mcCV0jaFniTVAUFXAh8R9IqQMAXI+LFEd7LrClM6u4q++bRatNxmw2bPCLiTgBJf7vVq82NkkZUTxQRdwMzypSvBWaN5Npmzap39rQt2jygNafjNqu2wXx7Se+PiKcAJO0BbF+/sMzaU7tMx21WbfI4G7hD0lNkVUm/y+ZqJjPLoR2m4zarKnlExC2S9gI+mIoej4hf1y8sMzNrZlUlD0ljgc8CH01Fd0j6VkRsrFtkZmbWtKqttvomMBb4Rvr8Z6nsM/UIyszMmlu1yeOgNFHhgGWSHqpHQGZm1vyqnRhxk6Q9Bz5Iej+waZjjzcysjVX75tEL/HSr3lZeZ8PMrENV29vq9tTbamAk0xr3tjIz61zubWVmZrm5t5WZmeXm3lZmZpabe1uZmVlu7m1lZma5ubeVmZnllmcN8xnAlHTOdElExLV1icrMrM0sXtnfVlPxV9tV97vAnsCDbG7rCKCm5CFpf+AqYBzwDHBqRLya9p0HnJHu85cRsaSWe5iZNYvFK/u3WASsf/0Gzlu0CqBlE0i1bx4l4EMRMeR65jldDZwTEXdKOp2sTeV8SR8C/gTYG5gELJU0NSLcOG9mLWv+kjVbrB4JsGHjJuYvWdOyyaPa3laPkK1hPlqmAsvT9m3A8Wn7WOBHEfHriHga+L/AwaN4XzOzhltbZt364cpbwbBvHpJuJKue2gF4VNIDwG8ayiPiEzXedzVZolgMnAjsnsonA/cPOu65VGZm1rImdXfRXyZRTOruKiCa0VGp2uqyWi8saSnl31bmAacDV0o6H7gBeKuG688lLYXb09NTa5hmZnXXO3vaFm0eAF1jx9A7e9owZzW3YZNHRNxZ64Uj4ugKh8wCkDQVOCaV9bP5LQRgt1RW7voLgAUApVJptNpizMxG3UC7Rsf0tpJ0d0QcLuk1suqr3+wCIiLG13JTSbtExAuStgG+RNbzCrK3kB9I+hpZg/lewAO13MPMrJnMOWBySyeLrVV68zg8/d5hlO97iqSz0vYi4Jp0n9WS/gV4FHgbOMs9rczMmo+G630r6beGOzkiXh71iGpQKpWir6+v6DCswdpt0JVZo0laERGlWs6t1GC+gqy6SmX2BfD+Wm5qNlLtOOjKrJVUqrbao1GBmOXRjoOuzFpJVYMElfnT1LUWST2SPHjPCtOOg67MWkm1I8y/ARwCfCp9fg34el0iMqvCUIOrWnnQlVkrqTZ5fDgizgLeBIiIXwHb1S0qswp6Z0+ja+yYLcpafdCVtb7FK/s57OJl7HHuzRx28TIWryw7TK0tVDsx4kZJY0hjPSRNBN6pW1RmFbTjoCtrbZ3WiaPa5HElcD2wi6SvAieQDe4zK0y7Dbqy1tZpnTiqTR7XkXXbPYqs2+4c4Jd1isnMrOV0WieOapPHImBORDwOIOl3yKZSn1GvwMzMWkk7zpw7nGobzBcD/yJpjKQpwBLgvHoFZWbWajqtE0dVbx4R8Y+StiNLIlOAz0bEvXWMy8yspXRaJ45Ks+r+1eCPQA/ZOuYfkfSRiPhaHWMzM2spndSJo9Kbx9az6S4aotzMzDpIpbmtLmhUIGZm1joqVVtdHhFfGLSW+RZGsIa5mZm1sErVVt9Nv2tey9zMzNpPpWqrFel3zWuZm5lZ+6lUbbWKMtVVAyJiv1puKml/snXLxwHPAKdGxKuS/gtwMdmki28BvRGxrJZ7mJlZ/VSqtvqjOt33auCciLhT0ulAL3A+8CLwxxGxVtI+ZIMR69bvzcuYmpnVplK11S+2LpP0RxFx0wjvOxVYnrZvI0sS50fEykHHrAa6JL0nIn49wvu9S6fNgGlmNpqqnZ5ksK+Mwn1XA8em7ROB3cscczzw86ESh6S5kvok9a1bty53AMPNgGlmZsOrJXmoqoOkpZIeKfNzLHA68DlJK8gGHL611bl7A5cAnx3q+hGxICJKEVGaOHFi7i/RaTNgmpmNpmpn1R1syL/QB4uIoyscMgtA0lTgmIFCSbuRrR3y5xHxHzXEV5VOmwHTzGw0VfXmIem4gR9gt7R9lKRdarnpwHmStiFbVOqq9LkbuBk4NyLuqeXa1eq0GTDNzEZTtW8eZwCHAD9Nn48kWxxqD0lfiYjvDnXiEE6RdFbaXgRck7b/O/AB4MuSvpzKZkXECzmvX1GnzYBpZjaaFDHkMI7NB0lLyKqRfpk+/zZwLXAKsDwi9qlrlBWUSqXo6+srMgQzs5YjaUVElGo5t9oG890HEkfyQip7GdhYy43NzKx1VVttdYekm4B/TZ9PSGXbA+vrEZiZmTWvapPHWcBxwOHp8z8DCyOr8/pYPQIzM7PmVe0ytCHpbrLxGAE8ENU0lpiZWVuqKnlIOgmYD9xBNkjw7yX1RsR1dYzNzKzpeE68TLXVVvOAgwa6zEqaCCwFnDzMrGN4TrzNqu1ttc1WYy1eynGumVlb8Jx4m1X75nFLGuvxw/T5ZODH9QnJzKw5eU68zaptMO+VdDxwWCpaEBHX1y8sM7Pm4znxNqt6YsSIWAgsrGMsZrm58dIaqXf2tC3aPKC6OfHa8c9ppWVoX6P8MrQi68E7vi5RmVXBjZfWaLXMideuf06rmtuq2Xluq8502MXLylYhTO7u4p5zZxYQkdm7NfOf00bMbWXWdNx4aa2gXf+cOnlYyxqqkbITGy+tebXrn1MnD2tZXtDLWkG7/jmtZRlas6bgBb2sFbTrn9NCGswl7U+29Ow44Bng1Ih4ddD+HuBR4G8i4rJK13ODuZlZfiNpMC/qzeNq4JyIuFPS6UAvcP6g/V8DflJIZDYq2rFfu5ltVlSbx1Rgedq+DTh+YIekOcDTwOrGh2WjYaBfe//6DQSb+7UvXtlfdGhmNkqKSh6rgWPT9onA7gCSxgFfBC6odAFJcyX1Sepbt25d3QK1/Dx5nFn7q1vykLRU0iNlfo4FTgc+J2kFsAPZIlMAfwP8XUS8Xun6EbEgIkoRUZo4cWK9vobVoF37tZvZZnVr84iIoyscMgtA0lTgmFT2YeAESZcC3cA7kt6MiH+oV5w2+jx5nFn7K6TaStIu6fc2wJfIel4REb8fEVMiYgpwOfC/nThaT7v2azezzYpq8zhF0hPA48Ba4JqC4rA6mHPAZC46bl8md3chsjl8LjpuX/e2MmsjnhjRzKxDeWJEMzNrKCcPMzPLzcnDzMxyc/IwM7PcnDzMzCw3Jw8zM8vNycPMzHJz8jAzs9ycPMzMLDcvQ2tmDefFwlqfk4eZNdTAYmEDa74MLBYGOIG0EFdbmVlDebGw9uDkYWYN5cXC2oOTh5k11FCLgnmxsNbi5GFmDeXFwtqDG8zNrKEGGsXd26q1FZI8JO1PtvTsOOAZ4NSIeDXt2w/4FjAeeAc4KCLeLCJOM6uPOQdMdrJocUVVW10NnBsR+wLXA70AkrYFvgf814jYGzgS2FhQjGZmNoSiksdUYHnavg04Pm3PAh6OiIcAIuKliNhU5nwzMytQUcljNXBs2j4R2D1tTwVC0hJJP5f0PwuJzszMhlW3Ng9JS4Fdy+yaB5wOXCnpfOAG4K1B8RwOHAT8J3B7WqD99jLXnwvMBejp6Rn9L2BmZkOqW/KIiKMrHDILQNJU4JhU9hywPCJeTPt+DBwIvCt5RMQCYAFAqVSKUQrbzMyqUEi1laRd0u9tgC+R9bwCWALsK+l9qfH8CODRImI0M7OhFTXO4xRJZ6XtRcA1ABHxK0lfA34GBPDjiLi5oBibmmclNbMiKaL1a3xKpVL09fUVHUbDbD0rKWQjdC86bl8nEDOrWmpTLtVyrqcnaUGeldTMiubk0YI8K6mZFc3JowV5VlIzK5qTRwvyrKRmVjTPqtuCOm1WUvcsM2s+Th4tqlNmJfV612bNydVW1tTcs8ysOTl5WFNzzzKz5uTkYU3NPcvMmpOThzU19ywza05uMLem1mk9y8xahZOHNb1O6Vlm1kpcbWVmZrk5eZiZWW6utmoxHm1tZs3AyaOFeLS1mTULV1u1EI+2NrNmUdQa5vtLuk/SKkk3ShqfysdK+udU/pik84qIr1l5tLWZNYui3jyuBs6NiH2B64HeVH4i8J5UPgP4rKQpxYTYfDza2syaRVHJYyqwPG3fBhyftgPYXtK2QBfwFvBq48NrTh5tbWYDFq/s57CLl7HHuTdz2MXLWLyyv6H3Lyp5rAaOTdsnArun7euAN4DngWeByyLi5XIXkDRXUp+kvnXr1tU73qYw54DJXHTcvkzu7kLA5O4uLjpuXzeWm3WYgc4z/es3EGzuPNPIBKKIqM+FpaXArmV2zQPWAFcCOwM3AH8ZETtLOgz4HHAasBNwF/AHEfHUcPcqlUrR19c3itGbmTWvwy5eRn+Zts7J3V3cc+7Mqq8jaUVElGqJoW5ddSPi6AqHzAKQNBU4JpV9CrglIjYCL0i6BygBwyYPMyuGxx0Voxk6zxTV22qX9Hsb4EvAVWnXs8DMtG974CPA40XEaGbDa4aqk07VDJ1nimrzOEXSE2SJYS1wTSr/OjBO0mrgZ8A1EfFwQTGa2TA87qg4zdB5ppAR5hFxBXBFmfLXyRrQzazJNUPVSadqhqUKPD2JmdVkUndX2UZbjztqjKKXKvD0JGZWk2aoOrHi+M3DzGrSDFUnVhwnDzOrWdFVJ1YcV1uZmVluTh5mZpabk4eZmeXm5GFmZrk5eZiZWW51m1W3kSStA35RdBwNMgF4seggmoifx7v5mWzJz2NLg5/H70bExFou0hbJo5NI6qt1CuV25Ofxbn4mW/Lz2NJoPQ9XW5mZWW5OHmZmlpuTR+tZUHQATcbP4938TLbk57GlUXkebvMwM7Pc/OZhZma5OXk0CUn/JOkFSY8Msf9YSQ9LelBSn6TDB+27VNJqSY9JulKSGhd5fYzweVwi6ZH0c3Ljoq6vSs9k0HEHSXpb0gmDyv5C0pPp5y/qH239jfB53CJpvaSb6h9pY9T6PCRNl3Rf+jvk4ar/n4kI/zTBD/BR4EDgkSH2j2NzNeN+wONp+1DgHmBM+rkPOLLo71Pg8zgGuI1sxujtyZYzHl/092nEM0nHjAGWAT8GTkhlvwU8lX7vlLZ3Kvr7FPU8UvlRwB8DNxX9PYp+HsBUYK+0PQl4HuiudD+/eTSJiFgOvDzM/tcj/dcl+0txYDuA9wLbAe8BxgK/rGOoDTGC5/EhYHlEvB0RbwAPAx+va7ANUumZJJ8HFgIvDCqbDdwWES9HxK/IkmvLP5MRPA8i4nbgtTqFVohan0dEPBERT6bttWlfxYGDTh4tRNInJT0O3AycDhAR9wE/JfvXwvPAkoh4rLgoG6fc8wAeAj4u6X2SJgAfA3YvKsZGkjQZ+CTwza12TQb+36DPz6WytjbM8+hI1TwPSQeT/UP0Pypdz8mjhUTE9RHxQWAOcCGApA8AvwfsRvYXwkxJv19YkA1U7nlExK1kr+T3Aj8kq8bbVFSMDXY58MWIeKfoQJrE5fh5DHY5wzwPSb8DfBf4dDXPzCsJtqCIWC7p/elf1p8E7o+I1wEk/QQ4BLiryBgbafDziIgXI+KrwFcBJP0AeKLYCBumBPwo9ZeYAPyhpLeBfuDIQcftBtzR6OAKUPZ5RMTiQqMqzpDPQ9J4sjf4eRFxfzUX85tHi5D0gYFeVJIOJGvfeAl4FjhC0raSxgJHAG1fbTXU85A0RtLOqXw/ssb0W4uLtHEiYo+ImBIRU4DrgM+lvyiXALMk7SRpJ2BWKmtrwzyPjjTU85C0HXA9cG1EXFft9fzm0SQk/ZDsX4cTJD0H/DVZ4zcRcRVwPPDnkjYCG4CTIyIkXQfMBFaRNRrfEhE3FvAVRtUInsdY4K6UV14F/jQi3i7gK4y6Kp5JWRHxsqQLyXqeAXwlIio1rDa9Wp9HOvcu4IPAuHTuGRHR0gl1BM/jJLKeWjtLOi2VnRYRDw57v80dVszMzKrjaiszM8vNycPMzHJz8jAzs9ycPMzMLDcnDzMzy83Jw9qCpE1pht2Bnyk1XGOOpA/VIbyaSDpN0qSi4zArx+M8rF1siIjpI7zGHOAm4NFqT5C0bR3HkZwGPAKsLXPfMRHRKdOuWBPym4e1LUkzJN0paYWkJWnuHiSdKelnkh6StDBNongo8Algfnpz2VPSHZJK6ZwJkp5J26dJukHSMuB2SduntRQekLRS0rFDxNOb7vuwpAtS2RRl67D8Y1pP4VZJXWmthRLw/RRPl6RnlK1V8nPgREmnSFqlbN2SSwbd53VJf5eud7ukien7/HzQMXsN/myWl5OHtYuuQVVW16eR5n9PtmbBDOCfSPNdAYsi4qCI2J9sKpczIuJe4AagNyKmR0SlWUUPTNc+ApgHLIuIg8lm8Z0vafvBB0uaBewFHAxMB2ZI+mjavRfw9YjYG1gPHJ+miegDTk3xbEjHvhQRBwLLgUvIZheYDhwkaU46ZnugL13vTuCv0/d5RdL0dMyngWsqfEezIbnaytrFFtVWkvYB9gFuS1OVjCGbsh5gH0n/C+gmW1Sqlmkpbhs0xccs4BOSzkmf3wv0sOUcY7PSz8r0eRxZ0ngWeHrQVBArgCnD3Pf/pN8HAXdExDoASd8nm2JiMfDOoOO+ByxK21cDn5b0V8DJZInMrCZOHtauBKyOiEPK7PsOMCciHkpz+Rw5xDXeZvPb+Xu32vfGVvc6PiLWVIjnooj41haFWcP+rwcVbQK6hrnOG8PsG8rAHEQLyeY7WgasiIiXariWGeBqK2tfa4CJkg4BkDRW0t5p3w7A86lq69RB57yW9g14BpiRtk9gaEuAzw+a5feAIY45XdK4dMxkSbtU+A5bxzPYA2SzKU+QNAY4hayKCrL/rwfi/RRwN0BEvJni+CausrIRcvKwthQRb5H9BXqJpIeAB8nWewc4H/h3srXfHx902o+A3tTovSdwGfDfJK0kW/9gKBeSzV76sKTV6fPW8dwK/AC4T9Iqsimxh0oMA74DXDXQYL7V9Z4HziVbRfIhsjeJf0u73wAOlvQIWZvIVwad+n2yaq2OmKbe6sez6pq1GUmvR8S4IfadA+wYEec3OCxrM27zMOsQkq4H9iR7GzEbEb95mJlZbm7zMDOz3Jw8zMwsNycPMzPLzcnDzMxyc/IwM7PcnDzMzCy3/w+d7PJL2g6xlwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt = resultsdf.plot.scatter(x=\"entropy\",y=\"log-likelihood\")\n",
    "plt.scatter(resultsdf['entropy'],resultsdf['log-likelihood'])\n",
    "plt.xlabel(\"Feature entropy\")\n",
    "plt.ylabel(\"log-likelihood\")\n",
    "#plt.show()\n",
    "plt.savefig('clustergraph.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c3ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('clustergraph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6620d052",
   "metadata": {},
   "source": [
    "### We shall now apply K-means to identify the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7b309e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many clusters?2\n"
     ]
    }
   ],
   "source": [
    "n = input(\"How many clusters?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "99b110ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_scale</th>\n",
       "      <th>const</th>\n",
       "      <th>AUC</th>\n",
       "      <th>log-likelihood</th>\n",
       "      <th>entropy</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2.5863</td>\n",
       "      <td>5.1541</td>\n",
       "      <td>0.985551</td>\n",
       "      <td>-92.073171</td>\n",
       "      <td>1.373708</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>3.0989</td>\n",
       "      <td>5.1541</td>\n",
       "      <td>0.981777</td>\n",
       "      <td>-97.802886</td>\n",
       "      <td>1.380355</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2.5863</td>\n",
       "      <td>4.0145</td>\n",
       "      <td>0.984374</td>\n",
       "      <td>-96.465665</td>\n",
       "      <td>1.380575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2.5863</td>\n",
       "      <td>4.5843</td>\n",
       "      <td>0.985105</td>\n",
       "      <td>-94.083335</td>\n",
       "      <td>1.386435</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2.0737</td>\n",
       "      <td>2.8749</td>\n",
       "      <td>0.987702</td>\n",
       "      <td>-96.966962</td>\n",
       "      <td>1.389198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    length_scale   const       AUC  log-likelihood   entropy  cluster\n",
       "59        2.5863  5.1541  0.985551      -92.073171  1.373708        1\n",
       "69        3.0989  5.1541  0.981777      -97.802886  1.380355        1\n",
       "57        2.5863  4.0145  0.984374      -96.465665  1.380575        1\n",
       "58        2.5863  4.5843  0.985105      -94.083335  1.386435        1\n",
       "45        2.0737  2.8749  0.987702      -96.966962  1.389198        1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=int(n))\n",
    "c_predicted = km.fit_predict(resultsdf[[\"log-likelihood\",\"entropy\"]])\n",
    "resultsdf[\"cluster\"]=c_predicted\n",
    "resultsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fc95e4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#First create a dictionary for colours:\n",
    "\n",
    "colour_dict = {\n",
    "  0: \"blue\",\n",
    "  1: \"red\",\n",
    "  2: \"green\",\n",
    "  3: \"cyan\",\n",
    "  4: \"magenta\",\n",
    "  5: \"yellow\",\n",
    "  6: \"black\",\n",
    "}\n",
    "\n",
    "data_frames = []\n",
    "\n",
    "for i in range(int(n)):\n",
    "    data_frames.append(resultsdf[resultsdf.cluster == i])\n",
    "    plt.scatter(data_frames[i].entropy,data_frames[i][\"log-likelihood\"],color=colour_dict[i])\n",
    "\n",
    "#df1 = resultsdf[resultsdf.cluster == 0]\n",
    "#df2 = resultsdf[resultsdf.cluster == 1]\n",
    "#df3 = resultsdf[resultsdf.cluster == 2]\n",
    "#df4 = resultsdf[resultsdf.cluster == 3]\n",
    "\n",
    "#plt.scatter(df1.entropy,df1[\"log-likelihood\"],color=\"blue\")\n",
    "#plt.scatter(df2.entropy,df2[\"log-likelihood\"],color=\"red\")\n",
    "#plt.scatter(df3.entropy,df3[\"log-likelihood\"],color=\"green\")\n",
    "#plt.scatter(df4.entropy,df4[\"log-likelihood\"],color=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ea079",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' It is possible that the user will not be happy with how the data has been assigned.\n",
    "Offer an option for them to redo the clustering . '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35196a",
   "metadata": {},
   "source": [
    "### We now need to select the median  model (based on entropy) from each of these clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1f780ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create a list of models and their accuracies:\n",
    "\n",
    "models = {}\n",
    "accuracies = []\n",
    "\n",
    "\n",
    "#Can't use median function because it finds an average for even sets\n",
    "\n",
    "for i in range(int(n)):\n",
    "    index = int(data_frames[i].shape[0]/2)\n",
    "    observation = data_frames[i].iloc[index]\n",
    "    #kernel = float(observation['const'])*RBF(float(observation['length_scale']))\n",
    "    #gp = GaussianProcessClassifier(kernel=kernel,optimizer=None).fit(X, Y)\n",
    "    models['model{}'.format(i)] = [observation['const'],observation['length_scale']]\n",
    "    accuracies.append(observation['log-likelihood'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55c8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can pull out the parameters we need\n",
    "\n",
    "print(models.get(\"model1\")[0])\n",
    "print(models.get(\"model1\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "90d51fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be our PIGEBaQ algorithm:\n",
    "\n",
    "import math\n",
    "\n",
    "def compute_zn(index,data,output_var,np_lengthscale,np_cov,np_mu):\n",
    "    x = np.array(data.iloc[[index]])\n",
    "\n",
    "    element1 = (output_var*math.sqrt(np.linalg.det(np_lengthscale)))/(math.sqrt(np.linalg.det(np_lengthscale+np_cov)))\n",
    "    element2 = np.linalg.inv(np_lengthscale+np_cov)\n",
    "    element3 = np.transpose(np_mu - x)\n",
    "    element4 = -0.5*np.matmul(np.transpose(-1*element3),np.matmul(element2,-1*element3))\n",
    "\n",
    "    zn = element1*math.exp(element4.item())*np.matmul(element2,element3)\n",
    "    return zn\n",
    "\n",
    "def compute_cov(x,y,var,l):  #x and y are each full observations (vectors)\n",
    "    d = 0\n",
    "    m = len(x)\n",
    "    for i in range(m):\n",
    "        d += (x[i]-y[i])**2\n",
    "    val = var*np.exp(-0.5*d/(l**2))\n",
    "    return val\n",
    "\n",
    "\n",
    "def PIGEBaQ(data,var,length):\n",
    "    \n",
    "    this_df = data.dropna()\n",
    "    this_df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    mu = list(this_df.mean(axis='index'))\n",
    "    del mu[-1]\n",
    "    m = len(mu)\n",
    "    n = len(this_df.index)\n",
    "    np_mu = np.array(mu)\n",
    "    \n",
    "    this_df2 = this_df.drop(columns=['Output'])\n",
    "    df_cov = this_df2.cov()\n",
    "    np_cov = df_cov.to_numpy()\n",
    "    \n",
    "    np_lengthscale = length*np.identity(m)\n",
    "    \n",
    "    Z = [0]*n\n",
    "    for i in range(0,n):\n",
    "        Z[i] = compute_zn(i,this_df2,var,np_lengthscale,np_cov,np_mu)\n",
    "    \n",
    "    Z = np.array(Z)\n",
    "    Z = np.transpose(Z)\n",
    "    Z = Z.reshape(m,n)\n",
    "    \n",
    "    X = this_df2.to_numpy() #Each row is an abservation, each column is a variable\n",
    "    \n",
    "    num = this_df2.shape[0]\n",
    "    K = np.empty([num,num])\n",
    "\n",
    "    #Now lets start filling this matrix:\n",
    "    \n",
    "    for i in range(num):\n",
    "        for j in range(num):\n",
    "            K[i,j] = compute_cov(X[i,:],X[j,:],var,length)\n",
    "    \n",
    "    f = this_df[\"Output\"].to_numpy()\n",
    "    f = f.reshape(n)\n",
    "    \n",
    "    E = np.matmul(Z,np.matmul(np.linalg.inv(K),f))\n",
    "    \n",
    "    output_df = pd.DataFrame({\"Skills\":this_df2.columns,\"Importance\":E})\n",
    "    output_df = output_df.sort_values(by=\"Importance\")\n",
    "    output_df.reset_index(drop=True, inplace = True)\n",
    "    \n",
    "    output_df['Importance'] = output_df['Importance']/math.sqrt(output_df['Importance'].pow(2).sum()) #Normalizes values\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b7e7f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data_PIG = scaled_total_set.drop(columns=['O*NET-SOC Code', 'Title'])\n",
    "input_data_PIG = scaled_total_set.copy()\n",
    "\n",
    "tables = []\n",
    "\n",
    "for i in range(int(n)):\n",
    "    tables.append(PIGEBaQ(input_data_PIG,models.get(\"model{}\".format(i))[0],models.get(\"model{}\".format(i))[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ea9dddad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skills</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.795918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.575680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.116295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.146907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Skills  Importance\n",
       "0      0   -0.795918\n",
       "1      1   -0.575680\n",
       "2      2    0.116295\n",
       "3      3    0.146907"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8bcef37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " <ipython-input-84-2c5ce980b0df>:13: SettingWithCopyWarning:\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.795918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.575680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.116295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.146907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Features  Importance\n",
       "0        0   -0.795918\n",
       "1        1   -0.575680\n",
       "2        2    0.116295\n",
       "3        3    0.146907"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We shall now generate a single dataframe which has the weighted explanations:\n",
    "\n",
    "explanations_df = pd.DataFrame({\"Features\":np.array(scaled_total_set.columns[0:4])})\n",
    "explanations_df[\"Importance\"] = 0.0\n",
    "#explanations_df\n",
    "\n",
    "model = tables[0] #This is the relevant importance dataframe\n",
    "\n",
    "#explanations_df[\"Importance\"][0] = (accuracies[0]/sum(accuracies))*model['Importance'][model.index[model['Skills'] == explanations_df['Features'][0]]]\n",
    "for j in range(int(n)):\n",
    "    model = tables[j]\n",
    "    for i in range(int(explanations_df.shape[0])):\n",
    "        explanations_df[\"Importance\"][i] += (accuracies[j]/sum(accuracies))*model['Importance'][model.index[model['Skills'] == explanations_df['Features'][i]]]\n",
    "\n",
    "\n",
    "explanations_df = explanations_df.sort_values(by=[\"Importance\"],ascending=True)\n",
    "explanations_df.reset_index(drop = True, inplace = True)\n",
    "explanations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a4019a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations_df.to_csv(\"C:/Users/jacob/Documents/4YP data/DataSynthesis/4x400/interpretation.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbca202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explanations_df.to_csv(\"perm_PIGEBaQ.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b0221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the moment, we shall generate an explanation based on feature importance across the different clusters:\n",
    "\n",
    "\n",
    "tables = []\n",
    "\n",
    "for i in range(int(n)):\n",
    "    tables.append(pd.DataFrame({\"Features\":np.array(training_set.columns[2:37])}))\n",
    "\n",
    "\n",
    "for i in range(int(n)):\n",
    "    r = permutation_importance(models[i],X_test,y_test,n_repeats=30,random_state=0)\n",
    "    #tables[i][\"Importances\"] = abs(r.importances_mean)\n",
    "    tables[i][\"Importances\"] = r.importances_mean\n",
    "    tables[i] = tables[i].sort_values(by=[\"Importances\"],ascending=False)\n",
    "    tables[i].reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "#for i in range(int(n)):\n",
    "    #r = permutation_importance(models[i],X_test,y_test,n_repeats=30,random_state=0)\n",
    "    #importance_table[\"Importances{}\".format(i)] = abs(r.importances_mean)\n",
    "    #importance_table = importance_table.sort_values(by=['Importances{}'.format(i)])\n",
    "\n",
    "#NOTE - I'm uneasy about using the same test sets as before, should I expand to the unknown jobs?\n",
    "\n",
    "importance_dict = {}\n",
    "for i in range(int(n)):\n",
    "    q = tables[i]\n",
    "    importance_dict[\"Importance{}\".format(i)] = q[\"Features\"]\n",
    "#q = tables[1]\n",
    "#importance_dict[\"Importance1\"] = q[\"Features\"]\n",
    "importance_table = pd.DataFrame(data=importance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d12e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a9c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(importance_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec713c4",
   "metadata": {},
   "source": [
    "### We now have a table of features sorted by how important they are for each cluster, based on the permutation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4994965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We shall generate one more table, which will have a row for each feature and a score for how important it is:\n",
    "\n",
    "final_importance_table = pd.DataFrame({\"Features\":np.array(training_set.columns[2:37]),\"Importance\":np.zeros(np.shape(training_set.columns[2]))})\n",
    "feature_list = final_importance_table['Features'].tolist()\n",
    "#final_importance_table.head()\n",
    "for i in feature_list:\n",
    "    for j in range(int(n)):\n",
    "        index_val = importance_table.index[importance_table[\"Importance{}\".format(j)]==i]\n",
    "        index_val = index_val*accuracies[j]/sum(accuracies)\n",
    "        final_importance_table.loc[final_importance_table[\"Features\"]==i,\"Importance\"] += index_val.tolist()[0]\n",
    "    \n",
    "final_importance_table = final_importance_table.sort_values(by=[\"Importance\"],ascending=True)\n",
    "final_importance_table.reset_index(drop = True, inplace = True)\n",
    "final_importance_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e26c97",
   "metadata": {},
   "source": [
    "### We now have a table which ranks features by importance across all the clusters! Note that is values each cluster equally - this might be something we can improve upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1470c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets divert our attention towards making predictions on our unknown jobs:\n",
    "\n",
    "unknown_jobs = df4[df4.isna().any(axis=1)] #This is our set of unknown jobs\n",
    "#SCALE THE DATA! - Do I need to fit a new scaler?\n",
    "X = scaler.transform(unknown_jobs.iloc[:,2:37])\n",
    "#X = np.array(unknown_jobs.iloc[:,2:37])\n",
    "print(X)\n",
    "#for i in int(n):\n",
    "    #models[i].predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = gpc.predict_proba(X)\n",
    "test1 = gpc.predict(X)\n",
    "test2 = gpc.predict_proba(X)\n",
    "print(test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7555bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now fill in the dataframe:\n",
    "\n",
    "unknown_jobs[\"Auto label value\"] = test1\n",
    "unknown_jobs[\"Auto probability\"] = test2[:,1]\n",
    "unknown_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b143b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_jobs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a8b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets think about how we can apply the model from each of our clusters and compute an average:\n",
    "\n",
    "for i in range(int(n)):\n",
    "    probs = models[i].predict_proba(X)\n",
    "    unknown_jobs[\"Auto probability{}\".format(i)] = probs[:,1]\n",
    "\n",
    "#We need a list of column titles:\n",
    "column_titles = []\n",
    "for i in range(int(n)):\n",
    "    column_titles.append(\"Auto probability{}\".format(i))\n",
    "\n",
    "#Now calculate mean automotability    \n",
    "\n",
    "unknown_jobs[\"Auto probability\"] = unknown_jobs[column_titles].mean(axis=1)\n",
    "\n",
    "#And finally apply a function to determine auto-label value:\n",
    "\n",
    "def label_auto(my_input):\n",
    "    if my_input - 0.5 < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "unknown_jobs[\"Auto label value\"] = unknown_jobs[\"Auto probability\"].apply(label_auto)\n",
    "\n",
    "unknown_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d836b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unknown_jobs[\"Title\"][\"i\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f475056f",
   "metadata": {},
   "source": [
    "### We have now generated values for automotability!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
