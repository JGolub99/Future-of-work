{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e133cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This version hitches PIGEBaQ onto the permutation method '''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"Skills.xlsx\")\n",
    "#print(df.head())\n",
    "\n",
    "#Lets remove the importance values:\n",
    "\n",
    "df2 = df.loc[df[\"Scale Name\"] == \"Level\"]\n",
    "df2.reset_index(drop = True, inplace = True)\n",
    "#print(df2.head())\n",
    "\n",
    "#Lets now remove the irrelevent columns:\n",
    "\n",
    "df3 = df2.drop(columns = [\"Scale ID\",\"Scale Name\",\"N\",\"Recommend Suppress\",\"Not Relevant\",\"Date\",\"Domain Source\"])\n",
    "print(df3.head())\n",
    "\n",
    "#NOTE that we have ignored the suppress recomendations, we shall continue with this for now but will need to address this later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420df498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now discover a bit about our data set:\n",
    "\n",
    "df3.info()\n",
    "\n",
    "#We note that there are some occupations for which the standard error and bound values are missing. Lets supress these for now:\n",
    "\n",
    "df3.drop(columns = [\"Standard Error\",\"Lower CI Bound\",\"Upper CI Bound\"],inplace = True)\n",
    "print(df3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a1537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#I shall implement the drop_duplicates method:\n",
    "\n",
    "df4 = df3[[\"O*NET-SOC Code\",\"Title\"]]\n",
    "df4.drop_duplicates(inplace=True)\n",
    "df4.reset_index(drop = True, inplace = True)\n",
    "#print(df4.head())\n",
    "\n",
    "#We now need to add the variables. Begin by adding empty columns to the dataframe:\n",
    "\n",
    "n_jobs = len(set((df3[\"Title\"])))\n",
    "n_variables = len(set((df3[\"Element Name\"])))\n",
    "\n",
    "for i in range(n_jobs):\n",
    "    df4[df3[\"Element Name\"][i]] = \"\"\n",
    "\n",
    "#print(df4.head())\n",
    "#Now we need to fill these columns:\n",
    "\n",
    "x = df3.loc[df3[\"Title\"] == \"Chief Executives\"]\n",
    "y = x[\"Data Value\"]\n",
    "\n",
    "for i in range(n_variables):\n",
    "    df4[df4.columns[2+i]][0] = y[i]\n",
    "    \n",
    "#We now need to do this procedure for every job:\n",
    "\n",
    "for j in range(n_jobs):\n",
    "    x = df3.loc[df3[\"Title\"] == df4.iloc[j,1]]\n",
    "    y = x[\"Data Value\"]\n",
    "    y.reset_index(drop = True, inplace = True)\n",
    "    for i in range(n_variables):\n",
    "        df4[df4.columns[2+i]][j] = y[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0748248",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df4.head())\n",
    "print(df4.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194be949",
   "metadata": {},
   "source": [
    "### We now have the skills dataframe just as we want it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edae9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets understand our data a bit:\n",
    "\n",
    "df4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb3b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "hist = df4.iloc[:,20].hist(bins=20)\n",
    "\n",
    "#We can inspect the histogram of any variable we want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3628f6e5",
   "metadata": {},
   "source": [
    "### Let's now  import another dataframe with autovalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87641e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_excel(\"US_data_email.xls\")\n",
    "df5 = df5[[\"Occupation Name\",\"BLS codes\",\"Training set automatable labels\"]]\n",
    "print(df5.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40868f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422495f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets define a function so that we can make occupation ID's consistent:\n",
    "\n",
    "def title_set(my_string):\n",
    "    my_list = []\n",
    "    my_list[:0] = my_string\n",
    "    my_list.remove(\"_\")\n",
    "    my_list.append(\".00\")\n",
    "    my_output = \"\".join(my_list)\n",
    "    return my_output\n",
    "\n",
    "#print(title_set(\"45-4023_\"))\n",
    "\n",
    "df5.iloc[:,1] = df5.iloc[:,1].apply(title_set)\n",
    "print(df5.head())\n",
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88670d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now concatenate the auto labels to our 1st dataframe:\n",
    "import numpy as np\n",
    "df4[\"Auto label value\"] = np.nan\n",
    "for i in list(df5[\"BLS codes\"]):\n",
    "    df4.loc[df4[\"O*NET-SOC Code\"] == i,\"Auto label value\"] = list(df5.loc[df5[\"BLS codes\"] == i,\"Training set automatable labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.info()\n",
    "\n",
    "#Note - the auto value count is supposedly 330 non-null, even though it should be 70. After creating a csv from the dataframe,\n",
    "#I found that there were 70 non-null as expected. Worth bringing up with Mike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv(\"test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035d0d9",
   "metadata": {},
   "source": [
    "### START FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec8cea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "\n",
       "   caa  thall  output  \n",
       "0    0      1       1  \n",
       "1    0      2       1  \n",
       "2    0      2       1  \n",
       "3    0      2       1  \n",
       "4    0      2       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df4 = pd.read_csv(\"heart.csv\")\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e2d9a8",
   "metadata": {},
   "source": [
    "### We now have a dataset which encompass jobs titles, SOC codes, skill levels and hand picked auto labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d2e87",
   "metadata": {},
   "source": [
    "### Lets now split and standardize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc1e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To prevent information about the distribution of the test set leaking into the model, we shall first form a training set\n",
    "# and form a scaler operator from this, and then apply this to both training and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0fc4bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trtbps    303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalachh  303 non-null    int64  \n",
      " 8   exng      303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slp       303 non-null    int64  \n",
      " 11  caa       303 non-null    int64  \n",
      " 12  thall     303 non-null    int64  \n",
      " 13  output    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "#Lets now create a training set which includes only the jobs for which we have hand picked auto values:\n",
    "\n",
    "training_set = df4.dropna(axis=0,how=\"any\")\n",
    "training_set.reset_index(drop = True, inplace=True)\n",
    "#print(training_set.head())\n",
    "training_set.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c955b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets apply stratified sampling on this set to create a training and test set\n",
    "#Code taken from Hands on Machine Learning book\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "for train_index, test_index in split.split(training_set,training_set[\"output\"]):\n",
    "    strat_train_set = training_set.loc[train_index]\n",
    "    strat_test_set = training_set.loc[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04871038",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.reset_index(drop=True,inplace=True)\n",
    "strat_test_set.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7615f630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.545455\n",
       "0    0.454545\n",
       "Name: output, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set[\"output\"].value_counts()/len(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4985df74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Now that we have our training set, lets create a standardiser for it:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=True,with_std=True)\n",
    "scaler.fit(strat_train_set.iloc[:,0:13])\n",
    "scaled_training_values = scaler.transform(strat_train_set.iloc[:,0:13])\n",
    "scaled_test_values = scaler.transform(strat_test_set.iloc[:,0:13])\n",
    "scaled_train_set = strat_train_set.copy()\n",
    "scaled_test_set = strat_test_set.copy()\n",
    "#print(strat_train_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85fb4ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary = pd.DataFrame(data=scaled_training_values)\n",
    "temporary2 = pd.DataFrame(data=scaled_test_values) #we create temporary data frames from the numpy arrays we've just created\n",
    "#print(temporary)\n",
    "for i in range(0,13):\n",
    "    scaled_train_set[scaled_train_set.columns[i]] = temporary[temporary.columns[i]]\n",
    "    scaled_test_set[scaled_test_set.columns[i]] = temporary2[temporary2.columns[i]]\n",
    "\n",
    "#print(scaled_test_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0efe1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' We shall also create a standardized set for ALL of the training data '''\n",
    "\n",
    "scaler2 = StandardScaler(with_mean=True,with_std=True)\n",
    "scaler2.fit(strat_train_set.iloc[:,0:13])\n",
    "scaled_total_values = scaler2.transform(training_set.iloc[:,0:13])\n",
    "scaled_total_set = training_set.copy()\n",
    "\n",
    "temporary3 = pd.DataFrame(data=scaled_total_values)\n",
    "for i in range(0,13):\n",
    "    scaled_total_set[scaled_total_set.columns[i]] = temporary3[temporary3.columns[i]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d735dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaled_train_set.head())\n",
    "print(scaled_test_set.head())\n",
    "print(scaled_total_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67dc1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_total_set.to_csv(\"PIGEBAQ_testset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5c7ed",
   "metadata": {},
   "source": [
    "### We now have a fully scaled training and test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78aad85",
   "metadata": {},
   "source": [
    "### We can now perform Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dfe4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We begin by creating a centred training set:\n",
    "\n",
    "X = strat_train_set.drop([\"Title\",\"O*NET-SOC Code\"],axis=1)\n",
    "\n",
    "#We now use the Scikit learn toolkit to visualise how the explained variance ratio changes with no. dimensions:\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "dim = range(len(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea62cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.array(dim),np.array(cumsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Having visualized the effect of dimensionality, we can implement this to our dataset:\n",
    "\n",
    "pca2 = PCA(n_components=0.95)\n",
    "X_reduced = pca2.fit_transform(X)\n",
    "print(X_reduced[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badabc02",
   "metadata": {},
   "source": [
    "### We shall now fit a GP classifier to the unreduced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30b04605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\GPy\\core\\gp.py:85: UserWarning:Your kernel has a different input dimension 4 then the given X dimension 13. Be very sure this is what you want and you have not forgotten to set the right input dimenion in your kernel\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a434d713703400ab82b6970f4e89cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntProgress(value=0, max=1000), HTML(value=''))), Box(children=(HTML(value=''),)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<paramz.optimization.optimization.opt_lbfgsb at 0x1ebd9574a00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Begin by creating numpy arrays for our input X and output Y:\n",
    "\n",
    "X = np.array([scaled_train_set.iloc[:,0:13]])\n",
    "Y = np.array([scaled_train_set.iloc[:,13]])\n",
    "#X = np.array([scaled_total_set.iloc[:,0:4]])\n",
    "#Y = np.array([scaled_total_set.iloc[:,4]])\n",
    "#X = np.transpose(X)\n",
    "#Y = np.transpose(Y)\n",
    "\n",
    "\n",
    "X = np.reshape(X,(242,13)) #Reshape to go from 3d matrix to 2d\n",
    "Y = np.reshape(Y,(242,1)) # ^\n",
    "\n",
    "#Now generate a kernel:\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "import GPy\n",
    "\n",
    "kernel = GPy.kern.RBF(input_dim=4, variance=100., lengthscale=100.)\n",
    "m_gpy = GPy.models.GPClassification(X,Y,kernel)\n",
    "m_gpy.optimize(messages=True)\n",
    "#m_gpy.optimize_restarts(num_restarts = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5691efad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the rbf.variance?1.63\n",
      "What is the rbf.lengthscale?3.36\n"
     ]
    }
   ],
   "source": [
    "#We shall request values for the variance and lengthscale:\n",
    "\n",
    "m_var = input(\"What is the rbf.variance?\")\n",
    "m_length = input(\"What is the rbf.lengthscale?\")\n",
    "\n",
    "m_var = float(m_var)\n",
    "m_length = float(m_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e436ff7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "#Instantiate this model in scikit learn\n",
    "\n",
    "\n",
    "sci_kernel = m_var * RBF(m_length)\n",
    "gpc = GaussianProcessClassifier(kernel=sci_kernel,optimizer=None).fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13de51ce",
   "metadata": {},
   "source": [
    "### Lets now apply k-fold cross validation on the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56997c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(scaled_train_set.iloc[:,0:13])\n",
    "#X_train = np.transpose(X_train)\n",
    "y_train = np.array(scaled_train_set.iloc[:,13])\n",
    "#y_train = np.transpose(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6974f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8367346938775511\n",
      "0.8979591836734694\n",
      "0.6458333333333334\n",
      "0.8541666666666666\n",
      "0.875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train,y_train):\n",
    "    clone_gpc = clone(gpc)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train[test_index]\n",
    "    \n",
    "    clone_gpc.fit(X_train_folds,y_train_folds)\n",
    "    y_pred = clone_gpc.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct/len(y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68786926",
   "metadata": {},
   "source": [
    "### What about an F1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "185668f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.854014598540146"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_train_pred = cross_val_predict(gpc,X_train,y_train,cv=5)\n",
    "f1_score(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c6f32",
   "metadata": {},
   "source": [
    "### And how about an AUC value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40910d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9071625344352618"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def calc_AUC(gpc,X_train,y_train):\n",
    "    y_probas = cross_val_predict(gpc,X_train,y_train,cv=5,method=\"predict_proba\")\n",
    "    y_scores = y_probas[:,1]\n",
    "    return roc_auc_score(y_train,y_scores)\n",
    "\n",
    "calc_AUC(gpc,X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1ddfdf",
   "metadata": {},
   "source": [
    "### And a log-likelihood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "424fa99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-112.41854876343317"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpc.log_marginal_likelihood(theta=None, eval_gradient=False, clone_kernel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d78e0",
   "metadata": {},
   "source": [
    "### It is worth using the model to predict values for the test set to ensure it is working as I want it to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4d045d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(scaled_test_set.iloc[:,0:13])\n",
    "y_test = np.array(scaled_test_set.iloc[:,13])\n",
    "\n",
    "y_pred = gpc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09f0c78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0\n",
      " 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1]\n",
      "[0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1\n",
      " 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8f8dc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74839691, 0.25160309],\n",
       "       [0.61563949, 0.38436051],\n",
       "       [0.93580582, 0.06419418],\n",
       "       [0.3497081 , 0.6502919 ],\n",
       "       [0.36883347, 0.63116653],\n",
       "       [0.80322615, 0.19677385],\n",
       "       [0.30071769, 0.69928231],\n",
       "       [0.73495396, 0.26504604],\n",
       "       [0.21789697, 0.78210303],\n",
       "       [0.38015961, 0.61984039],\n",
       "       [0.76894594, 0.23105406],\n",
       "       [0.40854478, 0.59145522],\n",
       "       [0.85938416, 0.14061584],\n",
       "       [0.14181798, 0.85818202],\n",
       "       [0.07980804, 0.92019196],\n",
       "       [0.19790782, 0.80209218],\n",
       "       [0.18886308, 0.81113692],\n",
       "       [0.27394897, 0.72605103],\n",
       "       [0.43428369, 0.56571631],\n",
       "       [0.39170086, 0.60829914],\n",
       "       [0.42964415, 0.57035585],\n",
       "       [0.68420413, 0.31579587],\n",
       "       [0.15117193, 0.84882807],\n",
       "       [0.15850429, 0.84149571],\n",
       "       [0.32696014, 0.67303986],\n",
       "       [0.92875154, 0.07124846],\n",
       "       [0.61827059, 0.38172941],\n",
       "       [0.37197156, 0.62802844],\n",
       "       [0.74331757, 0.25668243],\n",
       "       [0.35252943, 0.64747057],\n",
       "       [0.65332826, 0.34667174],\n",
       "       [0.19871752, 0.80128248],\n",
       "       [0.56145547, 0.43854453],\n",
       "       [0.83371103, 0.16628897],\n",
       "       [0.86970914, 0.13029086],\n",
       "       [0.43775199, 0.56224801],\n",
       "       [0.46057311, 0.53942689],\n",
       "       [0.19200529, 0.80799471],\n",
       "       [0.10733283, 0.89266717],\n",
       "       [0.51121822, 0.48878178],\n",
       "       [0.44977611, 0.55022389],\n",
       "       [0.10200479, 0.89799521],\n",
       "       [0.05429956, 0.94570044],\n",
       "       [0.40805324, 0.59194676],\n",
       "       [0.73605757, 0.26394243],\n",
       "       [0.62381051, 0.37618949],\n",
       "       [0.15096553, 0.84903447],\n",
       "       [0.42002261, 0.57997739],\n",
       "       [0.36943602, 0.63056398],\n",
       "       [0.14662992, 0.85337008],\n",
       "       [0.40616752, 0.59383248],\n",
       "       [0.17128943, 0.82871057],\n",
       "       [0.32245795, 0.67754205],\n",
       "       [0.94412424, 0.05587576],\n",
       "       [0.10388111, 0.89611889],\n",
       "       [0.06358765, 0.93641235],\n",
       "       [0.16538366, 0.83461634],\n",
       "       [0.37775412, 0.62224588],\n",
       "       [0.92361356, 0.07638644],\n",
       "       [0.83145673, 0.16854327],\n",
       "       [0.1401791 , 0.8598209 ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd5b80",
   "metadata": {},
   "source": [
    "### We now have a fully working GP classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52436a7e",
   "metadata": {},
   "source": [
    "### Lets now consider the interpretability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c840583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Features  Importances\n",
      "5        fbs     0.000000\n",
      "3     trtbps     0.001639\n",
      "7   thalachh     0.002186\n",
      "8       exng     0.002186\n",
      "9    oldpeak     0.002186\n",
      "12     thall     0.003279\n",
      "6    restecg     0.006011\n",
      "2         cp     0.007650\n",
      "10       slp     0.014754\n",
      "0        age     0.017486\n",
      "11       caa     0.024590\n",
      "4       chol     0.037705\n",
      "1        sex     0.061202\n"
     ]
    }
   ],
   "source": [
    "#We shall use the feature permutation method:\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "feature_importance = pd.DataFrame({\"Features\":np.array(training_set.columns[0:13])})\n",
    "\n",
    "r = permutation_importance(gpc,X_test,y_test,n_repeats=30,random_state=0)\n",
    "feature_importance[\"Importances\"] = abs(r.importances_mean)\n",
    "feature_importance = feature_importance.sort_values(by=['Importances'])\n",
    "#feature_importance = feature_importance\n",
    "print(feature_importance)\n",
    "#print(r.importances_mean)\n",
    "\n",
    "#for i in r.importances_mean.argsort()[::-1]:\n",
    "#    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "#        print(f\"{feature_importance.Features[i]:<8}\"\n",
    "#        f\"{r.importances_mean[i]:.3f}\"\n",
    "#        f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb49c78",
   "metadata": {},
   "source": [
    "### Now that we have the feature importances, lets calculate the entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79ce2fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.627413374706037\n"
     ]
    }
   ],
   "source": [
    "# For the moment we won't normalise the distribution - might have to do this in the future (ask Mike)\n",
    "\n",
    "def log_calc(my_list):    #This function deals with values of 0\n",
    "    my_output = [0]*len(my_list)\n",
    "    for i in range(len(my_list)):\n",
    "        if my_list[i] != 0.0:\n",
    "            my_output[i] = np.log(my_list[i])\n",
    "    return my_output        \n",
    "            \n",
    "temp = abs(r.importances_mean)\n",
    "tempnew = temp/sum(temp)\n",
    "vector1 = np.array(tempnew)\n",
    "vector2 = np.array(log_calc(abs(r.importances_mean)))\n",
    "entropy = -1*np.dot(vector1,vector2)\n",
    "print(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16486e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.627413374706037"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets create a function that does all of this:\n",
    "\n",
    "def calc_entropy(gpc,X_test,y_test):\n",
    "    r = permutation_importance(gpc,X_test,y_test,n_repeats=30,random_state=0)\n",
    "    temp = abs(r.importances_mean)\n",
    "    tempnew = temp/sum(temp)\n",
    "    vector1 = np.array(tempnew)\n",
    "    vector2 = np.array(log_calc(abs(r.importances_mean)))\n",
    "    return -1*np.dot(vector1,vector2)\n",
    "\n",
    "calc_entropy(gpc,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d928b",
   "metadata": {},
   "source": [
    "### Lets now implement a gridsearch method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3e52523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      " C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning:A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   length_scale   const  AUC  log-likelihood   entropy\n",
      "0        0.0336  0.0163  0.5     -167.738575  3.456861\n",
      "1        0.0336  0.3749  0.5     -168.058849  3.461877\n",
      "2        0.0336  0.7335  0.5     -168.775741  3.467472\n",
      "3        0.0336  1.0921  0.5     -169.610189  3.467472\n",
      "4        0.0336  1.4507  0.5     -170.443632  3.467472\n"
     ]
    }
   ],
   "source": [
    "#Lets try manually creating the functions:\n",
    "\n",
    "n_lengthscale = 10\n",
    "n_const = 10\n",
    "\n",
    "#The above values control the number of different hyperparaemters we want to test on\n",
    "\n",
    "lengthscale = np.linspace(0.01*m_length,1.99*m_length,n_lengthscale)\n",
    "const = np.linspace(0.01*m_var,1.99*m_var,n_const)\n",
    "\n",
    "resultsdf = pd.DataFrame({'length_scale':[0.0]*(n_lengthscale*n_const),'const':[0.0]*(n_lengthscale*n_const),'AUC':[0.0]*(n_lengthscale*n_const),\"log-likelihood\":[0.0]*(n_lengthscale*n_const),\"entropy\":[0.0]*(n_lengthscale*n_const)})\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "for i in lengthscale:\n",
    "    for j in const:\n",
    "        kernel = j*RBF(i)\n",
    "        gpc = GaussianProcessClassifier(kernel=kernel,optimizer=None).fit(X, Y)\n",
    "        \n",
    "        #y_probas = cross_val_predict(gpc,X_train,y_train,cv=5,method=\"predict_proba\")\n",
    "        #y_scores = y_probas[:,1]\n",
    "        resultsdf.iloc[iteration]['AUC'] = calc_AUC(gpc,X_train,y_train)\n",
    "        \n",
    "        resultsdf.iloc[iteration]['log-likelihood'] = gpc.log_marginal_likelihood(theta=None, eval_gradient=False, clone_kernel=True)\n",
    "        \n",
    "        resultsdf.iloc[iteration]['length_scale'] = i\n",
    "        resultsdf.iloc[iteration]['const'] = j\n",
    "        \n",
    "        \n",
    "        resultsdf.iloc[iteration]['entropy'] = calc_entropy(gpc,X_test,y_test)\n",
    "        \n",
    "\n",
    "        #r = permutation_importance(gpc,X_test,y_test,n_repeats=30,random_state=0)\n",
    "        #temp = abs(r.importances_mean)\n",
    "        #tempnew = temp/sum(temp)\n",
    "        #vector1 = np.array(tempnew)\n",
    "        #vector2 = np.array(log_calc(abs(r.importances_mean)))\n",
    "        #resultsdf.iloc[iteration]['entropy'] = -1*np.dot(vector1,vector2)\n",
    "        \n",
    "        iteration+=1\n",
    "\n",
    "print(resultsdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db0abaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsdf = resultsdf.sort_values(by=['entropy'])\n",
    "resultsdf = resultsdf.dropna() #Drop NaNs from too small variance models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cc61202",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Consider dropping innacurate models. We do not care about these models and they could potentially alter the clustering '''\n",
    "\n",
    "max_accuracy = resultsdf['log-likelihood'].max()\n",
    "resultsdf = resultsdf.loc[resultsdf['log-likelihood'] > 1.2*max_accuracy]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a1cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultsdf.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db17fd48",
   "metadata": {},
   "source": [
    "### Lets visualise the accuracy vs interpretability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a8c63e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt = resultsdf.plot.scatter(x=\"entropy\",y=\"log-likelihood\")\n",
    "plt.scatter(resultsdf['entropy'],resultsdf['log-likelihood'])\n",
    "plt.xlabel(\"Feature entropy\")\n",
    "plt.ylabel(\"log-likelihood\")\n",
    "#plt.show()\n",
    "plt.savefig('clustergraph.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c3ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('clustergraph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6620d052",
   "metadata": {},
   "source": [
    "### We shall now apply K-means to identify the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b309e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many clusters?3\n"
     ]
    }
   ],
   "source": [
    "n = input(\"How many clusters?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99b110ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_scale</th>\n",
       "      <th>const</th>\n",
       "      <th>AUC</th>\n",
       "      <th>log-likelihood</th>\n",
       "      <th>entropy</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.2512</td>\n",
       "      <td>2.1679</td>\n",
       "      <td>0.897452</td>\n",
       "      <td>-118.355811</td>\n",
       "      <td>3.290960</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.2512</td>\n",
       "      <td>3.2437</td>\n",
       "      <td>0.895661</td>\n",
       "      <td>-116.473269</td>\n",
       "      <td>3.389863</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2.9904</td>\n",
       "      <td>3.2437</td>\n",
       "      <td>0.903444</td>\n",
       "      <td>-109.617974</td>\n",
       "      <td>3.461402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.2512</td>\n",
       "      <td>1.8093</td>\n",
       "      <td>0.897934</td>\n",
       "      <td>-119.508909</td>\n",
       "      <td>3.461542</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.2512</td>\n",
       "      <td>2.5265</td>\n",
       "      <td>0.896901</td>\n",
       "      <td>-117.529793</td>\n",
       "      <td>3.465600</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    length_scale   const       AUC  log-likelihood   entropy  cluster\n",
       "36        2.2512  2.1679  0.897452     -118.355811  3.290960        2\n",
       "39        2.2512  3.2437  0.895661     -116.473269  3.389863        2\n",
       "49        2.9904  3.2437  0.903444     -109.617974  3.461402        0\n",
       "35        2.2512  1.8093  0.897934     -119.508909  3.461542        2\n",
       "37        2.2512  2.5265  0.896901     -117.529793  3.465600        2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=int(n))\n",
    "c_predicted = km.fit_predict(resultsdf[[\"log-likelihood\",\"entropy\"]])\n",
    "resultsdf[\"cluster\"]=c_predicted\n",
    "resultsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc95e4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#First create a dictionary for colours:\n",
    "\n",
    "colour_dict = {\n",
    "  0: \"blue\",\n",
    "  1: \"red\",\n",
    "  2: \"green\",\n",
    "  3: \"cyan\",\n",
    "  4: \"magenta\",\n",
    "  5: \"yellow\",\n",
    "  6: \"black\",\n",
    "}\n",
    "\n",
    "data_frames = []\n",
    "\n",
    "for i in range(int(n)):\n",
    "    data_frames.append(resultsdf[resultsdf.cluster == i])\n",
    "    plt.scatter(data_frames[i].entropy,data_frames[i][\"log-likelihood\"],color=colour_dict[i])\n",
    "\n",
    "#df1 = resultsdf[resultsdf.cluster == 0]\n",
    "#df2 = resultsdf[resultsdf.cluster == 1]\n",
    "#df3 = resultsdf[resultsdf.cluster == 2]\n",
    "#df4 = resultsdf[resultsdf.cluster == 3]\n",
    "\n",
    "#plt.scatter(df1.entropy,df1[\"log-likelihood\"],color=\"blue\")\n",
    "#plt.scatter(df2.entropy,df2[\"log-likelihood\"],color=\"red\")\n",
    "#plt.scatter(df3.entropy,df3[\"log-likelihood\"],color=\"green\")\n",
    "#plt.scatter(df4.entropy,df4[\"log-likelihood\"],color=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ea079",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' It is possible that the user will not be happy with how the data has been assigned.\n",
    "Offer an option for them to redo the clustering . '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35196a",
   "metadata": {},
   "source": [
    "### We now need to select the median  model (based on entropy) from each of these clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f780ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create a list of models and their accuracies:\n",
    "\n",
    "models = {}\n",
    "accuracies = []\n",
    "\n",
    "\n",
    "#Can't use median function because it finds an average for even sets\n",
    "\n",
    "for i in range(int(n)):\n",
    "    index = int(data_frames[i].shape[0]/2)\n",
    "    observation = data_frames[i].iloc[index]\n",
    "    #kernel = float(observation['const'])*RBF(float(observation['length_scale']))\n",
    "    #gp = GaussianProcessClassifier(kernel=kernel,optimizer=None).fit(X, Y)\n",
    "    models['model{}'.format(i)] = [observation['const'],observation['length_scale']]\n",
    "    accuracies.append(observation['log-likelihood'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d55c8c5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-a225b886739c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#We can pull out the parameters we need\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#We can pull out the parameters we need\n",
    "\n",
    "print(models.get(\"model1\")[0])\n",
    "print(models.get(\"model1\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90d51fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be our PIGEBaQ algorithm:\n",
    "\n",
    "import math\n",
    "\n",
    "def compute_zn(index,data,output_var,np_lengthscale,np_cov,np_mu):\n",
    "    x = np.array(data.iloc[[index]])\n",
    "\n",
    "    element1 = (output_var*math.sqrt(np.linalg.det(np_lengthscale)))/(math.sqrt(np.linalg.det(np_lengthscale+np_cov)))\n",
    "    element2 = np.linalg.inv(np_lengthscale+np_cov)\n",
    "    element3 = np.transpose(np_mu - x)\n",
    "    element4 = -0.5*np.matmul(np.transpose(-1*element3),np.matmul(element2,-1*element3))\n",
    "\n",
    "    zn = element1*math.exp(element4.item())*np.matmul(element2,element3)\n",
    "    return zn\n",
    "\n",
    "def compute_cov(x,y,var,l):  #x and y are each full observations (vectors)\n",
    "    d = 0\n",
    "    m = len(x)\n",
    "    for i in range(m):\n",
    "        d += (x[i]-y[i])**2\n",
    "    val = var*np.exp(-0.5*d/(l**2))\n",
    "    return val\n",
    "\n",
    "\n",
    "def PIGEBaQ(data,var,length):\n",
    "    \n",
    "    this_df = data.dropna()\n",
    "    this_df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    mu = list(this_df.mean(axis='index'))\n",
    "    del mu[-1]\n",
    "    m = len(mu)\n",
    "    n = len(this_df.index)\n",
    "    np_mu = np.array(mu)\n",
    "    \n",
    "    this_df2 = this_df.drop(columns=['output'])\n",
    "    df_cov = this_df2.cov()\n",
    "    np_cov = df_cov.to_numpy()\n",
    "    \n",
    "    np_lengthscale = length*np.identity(m)\n",
    "    \n",
    "    Z = [0]*n\n",
    "    for i in range(0,n):\n",
    "        Z[i] = compute_zn(i,this_df2,var,np_lengthscale,np_cov,np_mu)\n",
    "    \n",
    "    Z = np.array(Z)\n",
    "    Z = np.transpose(Z)\n",
    "    Z = Z.reshape(m,n)\n",
    "    \n",
    "    X = this_df2.to_numpy() #Each row is an abservation, each column is a variable\n",
    "    \n",
    "    num = this_df2.shape[0]\n",
    "    K = np.empty([num,num])\n",
    "\n",
    "    #Now lets start filling this matrix:\n",
    "    \n",
    "    for i in range(num):\n",
    "        for j in range(num):\n",
    "            K[i,j] = compute_cov(X[i,:],X[j,:],var,length)\n",
    "    \n",
    "    f = this_df[\"output\"].to_numpy()\n",
    "    f = f.reshape(n)\n",
    "    \n",
    "    E = np.matmul(Z,np.matmul(np.linalg.inv(K),f))\n",
    "    \n",
    "    output_df = pd.DataFrame({\"Skills\":this_df2.columns,\"Importance\":E})\n",
    "    output_df = output_df.sort_values(by=\"Importance\")\n",
    "    output_df.reset_index(drop=True, inplace = True)\n",
    "    \n",
    "    output_df['Importance'] = output_df['Importance']/math.sqrt(output_df['Importance'].pow(2).sum()) #Normalizes values\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7e7f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data_PIG = scaled_total_set.drop(columns=['O*NET-SOC Code', 'Title'])\n",
    "input_data_PIG = scaled_total_set.copy()\n",
    "\n",
    "tables = []\n",
    "\n",
    "for i in range(int(n)):\n",
    "    tables.append(PIGEBaQ(input_data_PIG,models.get(\"model{}\".format(i))[0],models.get(\"model{}\".format(i))[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9dddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8bcef37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " <ipython-input-49-732b71a8cd4d>:13: SettingWithCopyWarning:\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caa</td>\n",
       "      <td>-0.275374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>-0.088086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slp</td>\n",
       "      <td>-0.063883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thall</td>\n",
       "      <td>0.012639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cp</td>\n",
       "      <td>0.027390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exng</td>\n",
       "      <td>0.032299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fbs</td>\n",
       "      <td>0.055711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thalachh</td>\n",
       "      <td>0.064513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>restecg</td>\n",
       "      <td>0.082729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>0.117791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trtbps</td>\n",
       "      <td>0.209427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.298252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chol</td>\n",
       "      <td>0.608818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Features  Importance\n",
       "0        caa   -0.275374\n",
       "1        age   -0.088086\n",
       "2        slp   -0.063883\n",
       "3      thall    0.012639\n",
       "4         cp    0.027390\n",
       "5       exng    0.032299\n",
       "6        fbs    0.055711\n",
       "7   thalachh    0.064513\n",
       "8    restecg    0.082729\n",
       "9    oldpeak    0.117791\n",
       "10    trtbps    0.209427\n",
       "11       sex    0.298252\n",
       "12      chol    0.608818"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We shall now generate a single dataframe which has the weighted explanations:\n",
    "\n",
    "explanations_df = pd.DataFrame({\"Features\":np.array(scaled_total_set.columns[0:13])})\n",
    "explanations_df[\"Importance\"] = 0.0\n",
    "#explanations_df\n",
    "\n",
    "model = tables[0] #This is the relevant importance dataframe\n",
    "\n",
    "#explanations_df[\"Importance\"][0] = (accuracies[0]/sum(accuracies))*model['Importance'][model.index[model['Skills'] == explanations_df['Features'][0]]]\n",
    "for j in range(int(n)):\n",
    "    model = tables[j]\n",
    "    for i in range(int(explanations_df.shape[0])):\n",
    "        explanations_df[\"Importance\"][i] += (accuracies[j]/sum(accuracies))*model['Importance'][model.index[model['Skills'] == explanations_df['Features'][i]]]\n",
    "\n",
    "\n",
    "explanations_df = explanations_df.sort_values(by=[\"Importance\"],ascending=True)\n",
    "explanations_df.reset_index(drop = True, inplace = True)\n",
    "explanations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dac760",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(scaled_total_set['chol'], scaled_total_set['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6cbca202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explanations_df.to_csv(\"heart_importances.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b0221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the moment, we shall generate an explanation based on feature importance across the different clusters:\n",
    "\n",
    "\n",
    "tables = []\n",
    "\n",
    "for i in range(int(n)):\n",
    "    tables.append(pd.DataFrame({\"Features\":np.array(training_set.columns[2:37])}))\n",
    "\n",
    "\n",
    "for i in range(int(n)):\n",
    "    r = permutation_importance(models[i],X_test,y_test,n_repeats=30,random_state=0)\n",
    "    #tables[i][\"Importances\"] = abs(r.importances_mean)\n",
    "    tables[i][\"Importances\"] = r.importances_mean\n",
    "    tables[i] = tables[i].sort_values(by=[\"Importances\"],ascending=False)\n",
    "    tables[i].reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "#for i in range(int(n)):\n",
    "    #r = permutation_importance(models[i],X_test,y_test,n_repeats=30,random_state=0)\n",
    "    #importance_table[\"Importances{}\".format(i)] = abs(r.importances_mean)\n",
    "    #importance_table = importance_table.sort_values(by=['Importances{}'.format(i)])\n",
    "\n",
    "#NOTE - I'm uneasy about using the same test sets as before, should I expand to the unknown jobs?\n",
    "\n",
    "importance_dict = {}\n",
    "for i in range(int(n)):\n",
    "    q = tables[i]\n",
    "    importance_dict[\"Importance{}\".format(i)] = q[\"Features\"]\n",
    "#q = tables[1]\n",
    "#importance_dict[\"Importance1\"] = q[\"Features\"]\n",
    "importance_table = pd.DataFrame(data=importance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d12e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a9c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(importance_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec713c4",
   "metadata": {},
   "source": [
    "### We now have a table of features sorted by how important they are for each cluster, based on the permutation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4994965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We shall generate one more table, which will have a row for each feature and a score for how important it is:\n",
    "\n",
    "final_importance_table = pd.DataFrame({\"Features\":np.array(training_set.columns[2:37]),\"Importance\":np.zeros(np.shape(training_set.columns[2]))})\n",
    "feature_list = final_importance_table['Features'].tolist()\n",
    "#final_importance_table.head()\n",
    "for i in feature_list:\n",
    "    for j in range(int(n)):\n",
    "        index_val = importance_table.index[importance_table[\"Importance{}\".format(j)]==i]\n",
    "        index_val = index_val*accuracies[j]/sum(accuracies)\n",
    "        final_importance_table.loc[final_importance_table[\"Features\"]==i,\"Importance\"] += index_val.tolist()[0]\n",
    "    \n",
    "final_importance_table = final_importance_table.sort_values(by=[\"Importance\"],ascending=True)\n",
    "final_importance_table.reset_index(drop = True, inplace = True)\n",
    "final_importance_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e26c97",
   "metadata": {},
   "source": [
    "### We now have a table which ranks features by importance across all the clusters! Note that is values each cluster equally - this might be something we can improve upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1470c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets divert our attention towards making predictions on our unknown jobs:\n",
    "\n",
    "unknown_jobs = df4[df4.isna().any(axis=1)] #This is our set of unknown jobs\n",
    "#SCALE THE DATA! - Do I need to fit a new scaler?\n",
    "X = scaler.transform(unknown_jobs.iloc[:,2:37])\n",
    "#X = np.array(unknown_jobs.iloc[:,2:37])\n",
    "print(X)\n",
    "#for i in int(n):\n",
    "    #models[i].predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = gpc.predict_proba(X)\n",
    "test1 = gpc.predict(X)\n",
    "test2 = gpc.predict_proba(X)\n",
    "print(test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7555bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now fill in the dataframe:\n",
    "\n",
    "unknown_jobs[\"Auto label value\"] = test1\n",
    "unknown_jobs[\"Auto probability\"] = test2[:,1]\n",
    "unknown_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b143b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_jobs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a8b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets think about how we can apply the model from each of our clusters and compute an average:\n",
    "\n",
    "for i in range(int(n)):\n",
    "    probs = models[i].predict_proba(X)\n",
    "    unknown_jobs[\"Auto probability{}\".format(i)] = probs[:,1]\n",
    "\n",
    "#We need a list of column titles:\n",
    "column_titles = []\n",
    "for i in range(int(n)):\n",
    "    column_titles.append(\"Auto probability{}\".format(i))\n",
    "\n",
    "#Now calculate mean automotability    \n",
    "\n",
    "unknown_jobs[\"Auto probability\"] = unknown_jobs[column_titles].mean(axis=1)\n",
    "\n",
    "#And finally apply a function to determine auto-label value:\n",
    "\n",
    "def label_auto(my_input):\n",
    "    if my_input - 0.5 < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "unknown_jobs[\"Auto label value\"] = unknown_jobs[\"Auto probability\"].apply(label_auto)\n",
    "\n",
    "unknown_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d836b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unknown_jobs[\"Title\"][\"i\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f475056f",
   "metadata": {},
   "source": [
    "### We have now generated values for automotability!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
