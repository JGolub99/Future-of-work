{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e133cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  O*NET-SOC Code             Title Element ID           Element Name  \\\n",
      "0     11-1011.00  Chief Executives    2.A.1.a  Reading Comprehension   \n",
      "1     11-1011.00  Chief Executives    2.A.1.b       Active Listening   \n",
      "2     11-1011.00  Chief Executives    2.A.1.c                Writing   \n",
      "3     11-1011.00  Chief Executives    2.A.1.d               Speaking   \n",
      "4     11-1011.00  Chief Executives    2.A.1.e            Mathematics   \n",
      "\n",
      "   Data Value  Standard Error  Lower CI Bound  Upper CI Bound  \n",
      "0        4.75            0.16            4.43            5.07  \n",
      "1        4.88            0.23            4.43            5.32  \n",
      "2        4.38            0.18            4.02            4.73  \n",
      "3        4.88            0.13            4.63            5.12  \n",
      "4        3.62            0.26            3.11            4.14  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"Skills.xlsx\")\n",
    "#print(df.head())\n",
    "\n",
    "#Lets remove the importance values:\n",
    "\n",
    "df2 = df.loc[df[\"Scale Name\"] == \"Level\"]\n",
    "df2.reset_index(drop = True, inplace = True)\n",
    "#print(df2.head())\n",
    "\n",
    "#Lets now remove the irrelevent columns:\n",
    "\n",
    "df3 = df2.drop(columns = [\"Scale ID\",\"Scale Name\",\"N\",\"Recommend Suppress\",\"Not Relevant\",\"Date\",\"Domain Source\"])\n",
    "print(df3.head())\n",
    "\n",
    "#NOTE that we have ignored the suppress recomendations, we shall continue with this for now but will need to address this later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "420df498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30555 entries, 0 to 30554\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   O*NET-SOC Code  30555 non-null  object \n",
      " 1   Title           30555 non-null  object \n",
      " 2   Element ID      30555 non-null  object \n",
      " 3   Element Name    30555 non-null  object \n",
      " 4   Data Value      30555 non-null  float64\n",
      " 5   Standard Error  28700 non-null  float64\n",
      " 6   Lower CI Bound  28700 non-null  float64\n",
      " 7   Upper CI Bound  28700 non-null  float64\n",
      "dtypes: float64(4), object(4)\n",
      "memory usage: 1.9+ MB\n",
      "  O*NET-SOC Code             Title Element ID           Element Name  \\\n",
      "0     11-1011.00  Chief Executives    2.A.1.a  Reading Comprehension   \n",
      "1     11-1011.00  Chief Executives    2.A.1.b       Active Listening   \n",
      "2     11-1011.00  Chief Executives    2.A.1.c                Writing   \n",
      "3     11-1011.00  Chief Executives    2.A.1.d               Speaking   \n",
      "4     11-1011.00  Chief Executives    2.A.1.e            Mathematics   \n",
      "\n",
      "   Data Value  \n",
      "0        4.75  \n",
      "1        4.88  \n",
      "2        4.38  \n",
      "3        4.88  \n",
      "4        3.62  \n"
     ]
    }
   ],
   "source": [
    "#Lets now discover a bit about our data set:\n",
    "\n",
    "df3.info()\n",
    "\n",
    "#We note that there are some occupations for which the standard error and bound values are missing. Lets supress these for now:\n",
    "\n",
    "df3.drop(columns = [\"Standard Error\",\"Lower CI Bound\",\"Upper CI Bound\"],inplace = True)\n",
    "print(df3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55a1537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-398803c0bc0e>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4.drop_duplicates(inplace=True)\n",
      "<ipython-input-3-398803c0bc0e>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4[df3[\"Element Name\"][i]] = \"\"\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3437: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#I shall implement the drop_duplicates method:\n",
    "\n",
    "df4 = df3[[\"O*NET-SOC Code\",\"Title\"]]\n",
    "df4.drop_duplicates(inplace=True)\n",
    "df4.reset_index(drop = True, inplace = True)\n",
    "#print(df4.head())\n",
    "\n",
    "#We now need to add the variables. Begin by adding empty columns to the dataframe:\n",
    "\n",
    "n_jobs = len(set((df3[\"Title\"])))\n",
    "n_variables = len(set((df3[\"Element Name\"])))\n",
    "\n",
    "for i in range(n_jobs):\n",
    "    df4[df3[\"Element Name\"][i]] = \"\"\n",
    "\n",
    "#print(df4.head())\n",
    "#Now we need to fill these columns:\n",
    "\n",
    "x = df3.loc[df3[\"Title\"] == \"Chief Executives\"]\n",
    "y = x[\"Data Value\"]\n",
    "\n",
    "for i in range(n_variables):\n",
    "    df4[df4.columns[2+i]][0] = y[i]\n",
    "    \n",
    "#We now need to do this procedure for every job:\n",
    "\n",
    "for j in range(n_jobs):\n",
    "    x = df3.loc[df3[\"Title\"] == df4.iloc[j,1]]\n",
    "    y = x[\"Data Value\"]\n",
    "    y.reset_index(drop = True, inplace = True)\n",
    "    for i in range(n_variables):\n",
    "        df4[df4.columns[2+i]][j] = y[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0748248",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df4.head())\n",
    "print(df4.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194be949",
   "metadata": {},
   "source": [
    "### We now have the skills dataframe just as we want it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edae9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets understand our data a bit:\n",
    "\n",
    "df4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb3b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "hist = df4.iloc[:,20].hist(bins=20)\n",
    "\n",
    "#We can inspect the histogram of any variable we want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3628f6e5",
   "metadata": {},
   "source": [
    "### Let's now  import another dataframe with autovalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87641e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Occupation Name BLS codes  \\\n",
      "0                            Recreational Therapists  29-1125_   \n",
      "1  First-Line Supervisors of Mechanics Installers...  49-1011_   \n",
      "2                     Emergency Management Directors  11-9161_   \n",
      "3   Mental Health and Substance Abuse Social Workers  21-1023_   \n",
      "4                                       Audiologists  29-1181_   \n",
      "\n",
      "   Training set automatable labels  \n",
      "0                              NaN  \n",
      "1                              NaN  \n",
      "2                              NaN  \n",
      "3                              NaN  \n",
      "4                              NaN  \n"
     ]
    }
   ],
   "source": [
    "df5 = pd.read_excel(\"US_data_email.xls\")\n",
    "df5 = df5[[\"Occupation Name\",\"BLS codes\",\"Training set automatable labels\"]]\n",
    "print(df5.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40868f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "422495f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Occupation Name   BLS codes  \\\n",
      "0                            Recreational Therapists  29-1125.00   \n",
      "1  First-Line Supervisors of Mechanics Installers...  49-1011.00   \n",
      "2                     Emergency Management Directors  11-9161.00   \n",
      "3   Mental Health and Substance Abuse Social Workers  21-1023.00   \n",
      "4                                       Audiologists  29-1181.00   \n",
      "\n",
      "   Training set automatable labels  \n",
      "0                              NaN  \n",
      "1                              NaN  \n",
      "2                              NaN  \n",
      "3                              NaN  \n",
      "4                              NaN  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 702 entries, 0 to 701\n",
      "Data columns (total 3 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Occupation Name                  702 non-null    object \n",
      " 1   BLS codes                        702 non-null    object \n",
      " 2   Training set automatable labels  70 non-null     float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 16.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#Lets define a function so that we can make occupation ID's consistent:\n",
    "\n",
    "def title_set(my_string):\n",
    "    my_list = []\n",
    "    my_list[:0] = my_string\n",
    "    my_list.remove(\"_\")\n",
    "    my_list.append(\".00\")\n",
    "    my_output = \"\".join(my_list)\n",
    "    return my_output\n",
    "\n",
    "#print(title_set(\"45-4023_\"))\n",
    "\n",
    "df5.iloc[:,1] = df5.iloc[:,1].apply(title_set)\n",
    "print(df5.head())\n",
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88670d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-27a20ac659ae>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4[\"Auto label value\"] = np.nan\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1700: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, v, pi)\n"
     ]
    }
   ],
   "source": [
    "#Lets now concatenate the auto labels to our 1st dataframe:\n",
    "import numpy as np\n",
    "df4[\"Auto label value\"] = np.nan\n",
    "for i in list(df5[\"BLS codes\"]):\n",
    "    df4.loc[df4[\"O*NET-SOC Code\"] == i,\"Auto label value\"] = list(df5.loc[df5[\"BLS codes\"] == i,\"Training set automatable labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.info()\n",
    "\n",
    "#Note - the auto value count is supposedly 330 non-null, even though it should be 70. After creating a csv from the dataframe,\n",
    "#I found that there were 70 non-null as expected. Worth bringing up with Mike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv(\"test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e2d9a8",
   "metadata": {},
   "source": [
    "### We now have a dataset which encompass jobs titles, SOC codes, skill levels and hand picked auto labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d2e87",
   "metadata": {},
   "source": [
    "### Lets now split and standardize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc1e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To prevent information about the distribution of the test set leaking into the model, we shall first form a training set\n",
    "# and form a scaler operator from this, and then apply this to both training and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0fc4bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63 entries, 0 to 62\n",
      "Data columns (total 38 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   O*NET-SOC Code                     63 non-null     object \n",
      " 1   Title                              63 non-null     object \n",
      " 2   Reading Comprehension              63 non-null     object \n",
      " 3   Active Listening                   63 non-null     object \n",
      " 4   Writing                            63 non-null     object \n",
      " 5   Speaking                           63 non-null     object \n",
      " 6   Mathematics                        63 non-null     object \n",
      " 7   Science                            63 non-null     object \n",
      " 8   Critical Thinking                  63 non-null     object \n",
      " 9   Active Learning                    63 non-null     object \n",
      " 10  Learning Strategies                63 non-null     object \n",
      " 11  Monitoring                         63 non-null     object \n",
      " 12  Social Perceptiveness              63 non-null     object \n",
      " 13  Coordination                       63 non-null     object \n",
      " 14  Persuasion                         63 non-null     object \n",
      " 15  Negotiation                        63 non-null     object \n",
      " 16  Instructing                        63 non-null     object \n",
      " 17  Service Orientation                63 non-null     object \n",
      " 18  Complex Problem Solving            63 non-null     object \n",
      " 19  Operations Analysis                63 non-null     object \n",
      " 20  Technology Design                  63 non-null     object \n",
      " 21  Equipment Selection                63 non-null     object \n",
      " 22  Installation                       63 non-null     object \n",
      " 23  Programming                        63 non-null     object \n",
      " 24  Operations Monitoring              63 non-null     object \n",
      " 25  Operation and Control              63 non-null     object \n",
      " 26  Equipment Maintenance              63 non-null     object \n",
      " 27  Troubleshooting                    63 non-null     object \n",
      " 28  Repairing                          63 non-null     object \n",
      " 29  Quality Control Analysis           63 non-null     object \n",
      " 30  Judgment and Decision Making       63 non-null     object \n",
      " 31  Systems Analysis                   63 non-null     object \n",
      " 32  Systems Evaluation                 63 non-null     object \n",
      " 33  Time Management                    63 non-null     object \n",
      " 34  Management of Financial Resources  63 non-null     object \n",
      " 35  Management of Material Resources   63 non-null     object \n",
      " 36  Management of Personnel Resources  63 non-null     object \n",
      " 37  Auto label value                   63 non-null     float64\n",
      "dtypes: float64(1), object(37)\n",
      "memory usage: 18.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Lets now create a training set which includes only the jobs for which we have hand picked auto values:\n",
    "\n",
    "training_set = df4.dropna(axis=0,how=\"any\")\n",
    "training_set.reset_index(drop = True, inplace=True)\n",
    "#print(training_set.head())\n",
    "training_set.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c955b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets apply stratified sampling on this set to create a training and test set\n",
    "#Code taken from Hands on Machine Learning book\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "for train_index, test_index in split.split(training_set,training_set[\"Auto label value\"]):\n",
    "    strat_train_set = training_set.loc[train_index]\n",
    "    strat_test_set = training_set.loc[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04871038",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.reset_index(drop=True,inplace=True)\n",
    "strat_test_set.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7615f630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.54\n",
       "0.0    0.46\n",
       "Name: Auto label value, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set[\"Auto label value\"].value_counts()/len(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4985df74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Now that we have our training set, lets create a standardiser for it:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=True,with_std=True)\n",
    "scaler.fit(strat_train_set.iloc[:,2:37])\n",
    "scaled_training_values = scaler.transform(strat_train_set.iloc[:,2:37])\n",
    "scaled_test_values = scaler.transform(strat_test_set.iloc[:,2:37])\n",
    "scaled_train_set = strat_train_set.copy()\n",
    "scaled_test_set = strat_test_set.copy()\n",
    "#print(strat_train_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85fb4ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary = pd.DataFrame(data=scaled_training_values)\n",
    "temporary2 = pd.DataFrame(data=scaled_test_values) #we create temporary data frames from the numpy arrays we've just created\n",
    "#print(temporary)\n",
    "for i in range(2,37):\n",
    "    scaled_train_set[scaled_train_set.columns[i]] = temporary[temporary.columns[i-2]]\n",
    "    scaled_test_set[scaled_test_set.columns[i]] = temporary2[temporary2.columns[i-2]]\n",
    "\n",
    "#print(scaled_test_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d735dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaled_train_set.head())\n",
    "print(scaled_test_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5c7ed",
   "metadata": {},
   "source": [
    "### We now have a fully scaled training and test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78aad85",
   "metadata": {},
   "source": [
    "### We can now perform Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dfe4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We begin by creating a centred training set:\n",
    "\n",
    "X = strat_train_set.drop([\"Title\",\"O*NET-SOC Code\"],axis=1)\n",
    "\n",
    "#We now use the Scikit learn toolkit to visualise how the explained variance ratio changes with no. dimensions:\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "dim = range(len(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea62cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.array(dim),np.array(cumsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Having visualized the effect of dimensionality, we can implement this to our dataset:\n",
    "\n",
    "pca2 = PCA(n_components=0.95)\n",
    "X_reduced = pca2.fit_transform(X)\n",
    "print(X_reduced[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badabc02",
   "metadata": {},
   "source": [
    "### We shall now fit a GP classifier to the unreduced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30b04605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'copy_X_train': True,\n",
       " 'kernel': 1**2 * RBF(length_scale=1),\n",
       " 'max_iter_predict': 100,\n",
       " 'multi_class': 'one_vs_rest',\n",
       " 'n_jobs': None,\n",
       " 'n_restarts_optimizer': 0,\n",
       " 'optimizer': 'fmin_l_bfgs_b',\n",
       " 'random_state': None,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Begin by creating numpy arrays for our input X and output Y:\n",
    "\n",
    "X = np.array([scaled_train_set.iloc[:,2:37]])\n",
    "Y = np.array([scaled_train_set.iloc[:,37]])\n",
    "#X = np.transpose(X)\n",
    "#Y = np.transpose(Y)\n",
    "X = np.reshape(X,(50,35)) #Reshape to go from 3d matrix to 2d\n",
    "Y = np.reshape(Y,(50,1)) # ^\n",
    "\n",
    "#Now generate a kernel:\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "length_scale = 1.\n",
    "kernel = 1. * RBF(length_scale)\n",
    "gpc = GaussianProcessClassifier(kernel=kernel,optimizer='fmin_l_bfgs_b').fit(X, Y)  #This one finds optimal hyperparameters\n",
    "#gpc = GaussianProcessClassifier(kernel=kernel,optimizer=None).fit(X, Y)\n",
    "gpc.get_params(deep=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13de51ce",
   "metadata": {},
   "source": [
    "### Lets now apply k-fold cross validation on the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56997c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(scaled_train_set.iloc[:,2:37])\n",
    "#X_train = np.transpose(X_train)\n",
    "y_train = np.array(scaled_train_set.iloc[:,37])\n",
    "#y_train = np.transpose(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6974f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "0.9\n",
      "0.8\n",
      "0.8\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train,y_train):\n",
    "    clone_gpc = clone(gpc)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train[test_index]\n",
    "    \n",
    "    clone_gpc.fit(X_train_folds,y_train_folds)\n",
    "    y_pred = clone_gpc.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct/len(y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68786926",
   "metadata": {},
   "source": [
    "### What about an F1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "185668f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_train_pred = cross_val_predict(gpc,X_train,y_train,cv=5)\n",
    "f1_score(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c6f32",
   "metadata": {},
   "source": [
    "### And how about an AUC value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40910d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9404186795491143"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def calc_AUC(gpc,X_train,y_train):\n",
    "    y_probas = cross_val_predict(gpc,X_train,y_train,cv=5,method=\"predict_proba\")\n",
    "    y_scores = y_probas[:,1]\n",
    "    return roc_auc_score(y_train,y_scores)\n",
    "\n",
    "calc_AUC(gpc,X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1ddfdf",
   "metadata": {},
   "source": [
    "### And a log-likelihood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "424fa99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-25.3684417051231"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpc.log_marginal_likelihood(theta=None, eval_gradient=False, clone_kernel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d78e0",
   "metadata": {},
   "source": [
    "### It is worth using the model to predict values for the test set to ensure it is working as I want it to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4d045d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(scaled_test_set.iloc[:,2:37])\n",
    "y_test = np.array(scaled_test_set.iloc[:,37])\n",
    "\n",
    "y_pred = gpc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f0c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f8dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd5b80",
   "metadata": {},
   "source": [
    "### We now have a fully working GP classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52436a7e",
   "metadata": {},
   "source": [
    "### Lets now consider the interpretability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c840583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Features  Importances\n",
      "4                         Mathematics     0.005128\n",
      "20                       Installation     0.007692\n",
      "5                             Science     0.017949\n",
      "17                Operations Analysis     0.020513\n",
      "13                        Negotiation     0.020513\n",
      "30                 Systems Evaluation     0.025641\n",
      "6                   Critical Thinking     0.025641\n",
      "8                 Learning Strategies     0.025641\n",
      "16            Complex Problem Solving     0.025641\n",
      "11                       Coordination     0.028205\n",
      "10              Social Perceptiveness     0.028205\n",
      "27           Quality Control Analysis     0.030769\n",
      "23              Operation and Control     0.030769\n",
      "33   Management of Material Resources     0.030769\n",
      "22              Operations Monitoring     0.038462\n",
      "34  Management of Personnel Resources     0.038462\n",
      "32  Management of Financial Resources     0.043590\n",
      "18                  Technology Design     0.043590\n",
      "9                          Monitoring     0.046154\n",
      "28       Judgment and Decision Making     0.048718\n",
      "12                         Persuasion     0.051282\n",
      "7                     Active Learning     0.053846\n",
      "1                    Active Listening     0.053846\n",
      "24              Equipment Maintenance     0.056410\n",
      "26                          Repairing     0.058974\n",
      "25                    Troubleshooting     0.058974\n",
      "19                Equipment Selection     0.069231\n",
      "29                   Systems Analysis     0.074359\n",
      "31                    Time Management     0.079487\n",
      "14                        Instructing     0.079487\n",
      "21                        Programming     0.087179\n",
      "2                             Writing     0.089744\n",
      "0               Reading Comprehension     0.089744\n",
      "15                Service Orientation     0.102564\n",
      "3                            Speaking     0.107692\n"
     ]
    }
   ],
   "source": [
    "#We shall use the feature permutation method:\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "feature_importance = pd.DataFrame({\"Features\":np.array(training_set.columns[2:37])})\n",
    "\n",
    "r = permutation_importance(gpc,X_test,y_test,n_repeats=30,random_state=0)\n",
    "feature_importance[\"Importances\"] = abs(r.importances_mean)\n",
    "feature_importance = feature_importance.sort_values(by=['Importances'])\n",
    "#feature_importance = feature_importance\n",
    "print(feature_importance)\n",
    "#print(r.importances_mean)\n",
    "\n",
    "#for i in r.importances_mean.argsort()[::-1]:\n",
    "#    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "#        print(f\"{feature_importance.Features[i]:<8}\"\n",
    "#        f\"{r.importances_mean[i]:.3f}\"\n",
    "#        f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb49c78",
   "metadata": {},
   "source": [
    "### Now that we have the feature importances, lets calculate the entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79ce2fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8734014150784395\n"
     ]
    }
   ],
   "source": [
    "# For the moment we won't normalise the distribution - might have to do this in the future (ask Mike)\n",
    "\n",
    "def log_calc(my_list):    #This function deals with values of 0\n",
    "    my_output = [0]*len(my_list)\n",
    "    for i in range(len(my_list)):\n",
    "        if my_list[i] != 0.0:\n",
    "            my_output[i] = np.log(my_list[i])\n",
    "    return my_output        \n",
    "            \n",
    "temp = abs(r.importances_mean)\n",
    "tempnew = temp/sum(temp)\n",
    "vector1 = np.array(tempnew)\n",
    "vector2 = np.array(log_calc(abs(r.importances_mean)))\n",
    "entropy = -1*np.dot(vector1,vector2)\n",
    "print(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16486e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8734014150784395"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets create a function that does all of this:\n",
    "\n",
    "def calc_entropy(gpc,X_test,y_test):\n",
    "    r = permutation_importance(gpc,X_test,y_test,n_repeats=30,random_state=0)\n",
    "    temp = abs(r.importances_mean)\n",
    "    tempnew = temp/sum(temp)\n",
    "    vector1 = np.array(tempnew)\n",
    "    vector2 = np.array(log_calc(abs(r.importances_mean)))\n",
    "    return -1*np.dot(vector1,vector2)\n",
    "\n",
    "calc_entropy(gpc,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d928b",
   "metadata": {},
   "source": [
    "### Lets now implement a gridsearch method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9ca5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(GaussianProcessClassifier(optimizer=None),{'kernel': [1*RBF(1),1*RBF(2)]},cv=5,return_train_score=False,scoring='roc_auc')\n",
    "clf.fit(X,Y)\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearchdf = pd.DataFrame(clf.cv_results_)\n",
    "gridsearchdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3e52523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\jacob\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   length_scale       const       AUC  log-likelihood   entropy\n",
      "0           7.5  120.000000  0.953301      -25.546832  3.196589\n",
      "1           7.5  123.333333  0.954911      -25.543991  3.197071\n",
      "2           7.5  126.666667  0.954911      -25.541634  3.164043\n",
      "3           7.5  130.000000  0.954911      -25.539723  3.162693\n",
      "4           7.5  133.333333  0.954911      -25.538226  3.166456\n"
     ]
    }
   ],
   "source": [
    "#Lets try manually creating the functions:\n",
    "\n",
    "n_lengthscale = 10\n",
    "n_const = 10\n",
    "\n",
    "#The above values control the number of different hyperparaemters we want to test on\n",
    "\n",
    "lengthscale = np.linspace(7.5,8.5,n_lengthscale)\n",
    "const = np.linspace(120.0,150.0,n_const)\n",
    "\n",
    "resultsdf = pd.DataFrame({'length_scale':[0.0]*(n_lengthscale*n_const),'const':[0.0]*(n_lengthscale*n_const),'AUC':[0.0]*(n_lengthscale*n_const),\"log-likelihood\":[0.0]*(n_lengthscale*n_const),\"entropy\":[0.0]*(n_lengthscale*n_const)})\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "for i in lengthscale:\n",
    "    for j in const:\n",
    "        kernel = j*RBF(i)\n",
    "        gpc = GaussianProcessClassifier(kernel=kernel,optimizer=None).fit(X, Y)\n",
    "        \n",
    "        #y_probas = cross_val_predict(gpc,X_train,y_train,cv=5,method=\"predict_proba\")\n",
    "        #y_scores = y_probas[:,1]\n",
    "        resultsdf.iloc[iteration]['AUC'] = calc_AUC(gpc,X_train,y_train)\n",
    "        \n",
    "        resultsdf.iloc[iteration]['log-likelihood'] = gpc.log_marginal_likelihood(theta=None, eval_gradient=False, clone_kernel=True)\n",
    "        \n",
    "        resultsdf.iloc[iteration]['length_scale'] = i\n",
    "        resultsdf.iloc[iteration]['const'] = j\n",
    "        \n",
    "        \n",
    "        resultsdf.iloc[iteration]['entropy'] = calc_entropy(gpc,X_test,y_test)\n",
    "        \n",
    "\n",
    "        #r = permutation_importance(gpc,X_test,y_test,n_repeats=30,random_state=0)\n",
    "        #temp = abs(r.importances_mean)\n",
    "        #tempnew = temp/sum(temp)\n",
    "        #vector1 = np.array(tempnew)\n",
    "        #vector2 = np.array(log_calc(abs(r.importances_mean)))\n",
    "        #resultsdf.iloc[iteration]['entropy'] = -1*np.dot(vector1,vector2)\n",
    "        \n",
    "        iteration+=1\n",
    "\n",
    "print(resultsdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db0abaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsdf = resultsdf.sort_values(by=['log-likelihood'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a1cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultsdf.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db17fd48",
   "metadata": {},
   "source": [
    "### Lets visualise the accuracy vs interpretability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a8c63e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAEGCAYAAABRvCMcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAApGUlEQVR4nO3de5xdZX3v8c83wwDDxQ4e4oWBkIBcjhBMzIAXLApYoK3CCFhvVQEV6dGe46XRRNACYomNFs85tFLk9KLFmkoggNhCMHijjTRDbiDgMYC0I0eREBGIcTL5nT/W2snOnr32XntmX9ae+b5fr/3K3muvteY3m2F+8zzP73keRQRmZmatNqPTAZiZ2fTghGNmZm3hhGNmZm3hhGNmZm3hhGNmZm2xR6cDKIIDDzwwZs+e3ekwzMy6yvDw8C8iYmbe851wgNmzZ7NmzZpOh2Fm1lUk/aSR892lZmZmbeGEY2ZmbeGEY2ZmbeGEY2ZmbeGEY2ZmbeEqtYJasXaEpbc/xE+3bOWg/j4Wnn4UQ/MHOh2WmdmEOeEU0Iq1Iyy+cSNbR8cAGNmylcU3bgRw0jGzruUutQJaevtDO5NNydbRMZbe/lCHIjIzmzwnnAL66ZatDR03M+sGTjgFdFB/X0PHzcy6QccSjqSlkh6UtEHSTZL60+OzJW2VtC59XFPnPh+VFJIOrDh+vKTtks5t4bfREgtPP4q+3p7djvX19rDw9KM6FJGZ2eR1soWzEjg2Io4DfgQsLntvU0TMSx8XZd1A0iHAacBjFcd7gM8CdzQ/7NYbmj/AlWfPZaC/DwED/X1cefZcFwyYWVfrWJVaRJQng9XARFoiVwEfA26uOP7HwHLg+IlF1z5Z5c+lh5nZVFGUsugLgGVlr+dIWgs8DVwSEd+rvEDSWcBIRKyXVH58AHgTcDI1Eo6kC4ELAWbNmtWM76Fhkyl/9jwdM+s2Le1Sk3SnpPuqPM4qO+diYDtwfXrocWBWRMwHPgJ8VdLzKu67D/AJ4FNVvuwXgI9HxI5asUXEtRExGBGDM2fm3s6hqSZa/lxKVCNbthLsSlQr1o60MFozs8lpaQsnIl5f631J5wFvAE6NiEiv2QZsS58PS9oEHAmUb1hzODAHKLVuDgbulXQCMAh8LT1+IPB7krZHxIrmfWfNMdHy51qJyq0cMyuqjnWpSTqDZPzltRHxXNnxmcDmiBiTdBhwBPBw+bURsRF4Qdk1jwKDEfELkkRUOv53wDeKmGwgKXMeqZJc6pU/e56OmXWjTlapXQ3sD6ysKH8+CdggaR1wA3BRRGwGkHSdpMGORNsCEy1/9jwdM+tGnaxSe0nG8eUkFWbV3ntvxvHZGcfPm2B4bVHq/mp08H/h6UftVmwAnqdjZsVXlCq1aWsi5c9D8wdY85PN/OMP/oOxCHokzlngMmozKzYnnALLKn1esXaE5cMjjCV1FoxFsHx4hMFDn++kY2aF5YRTULXm6LhKzcy6kRfvLKhaScVVambWjdzC6ZB6KwXUSioTLac2M+skt3A6IM9KAbVKn72atJl1IyecDsizpE2tpOLVpM2sG7lLrQPyjMHUmqPjhTvNrBs54XRA3jGYanN0JrPCtJlZJ7lLrQPyjsGsWDvCiUtWMWfRbZy4ZNXOls1EVpg2M+s0J5wOGJo/wDkLBuhJ9/GptlJAVmFBtZYRuCTazIrPCacDslYKKK9Sy2rJ9JRtNlfOJdFmVnROOB2Qp1ssq8UyFuGSaDPrSk44HZCnSi2rxVIqgXZJtJl1G1epdUCeKrVaWxDUW2HaZdNmVkRu4XRAniq1iU7uzLOKgZlZJzjhdEDeZDI0f4C7F53CVW+ZB8CHl63bWR6dxWXTZlZU7lLrkMpusdKcm2qrCjQy0dMrSZtZUTnhFEC1pPKhZeu49Jb7kWho7xuvJG1mReUutQKo1g0GsGXrKE89N1r1mqwWi1eSNrOicgunACbS3ZXVYqm16KeZWSc54RRAVjdYlnotlnpl02ZmneAutQKo1g1Wbp/eGTXXXTMz6wZOOAVQWsyzmp4ZYnQsaq67VqnaKtNmZp3mhFMQdz34RNXjO3YEoztit2O15tV44qeZFZUTTkFkFQ5E1aPZ53vip5kVlRNOQWRVnTW6HYEnfppZUXUk4UhaKulBSRsk3SSpPz0+W9JWSevSxzV17vNRSSHpwLJjr0uvvV/Sd1r8rTRNtcIBAa887ICG5tVkJSJP/DSzTutUC2clcGxEHAf8CFhc9t6miJiXPi7KuoGkQ4DTgMfKjvUDfwWcGRHHAG9uRfCtUK1wIIB7Hn2KcxYM5F7E0xM/zayoOjIPJyLuKHu5Gjh3Are5CvgYcHPZsbcDN0bEY+nX+fmEg+yA2zY8Pu7Y6Fhw24bHWfup03LdwxM/zayoijDx8wJgWdnrOZLWAk8Dl0TE9yovkHQWMBIR67X7GMeRQK+kbwP7A/8zIr5c7YtKuhC4EGDWrFnN+D4mLWsZm6eeG626sGcWT/w0syJqWcKRdCfwoipvXRwRN6fnXAxsB65P33scmBURT0paAKyQdExEPF12332AT5B0p1XaA1gAnAr0Af8maXVE/KjyxIi4FrgWYHBwMKsYrDBKKxHUWy3azKyoWpZwIuL1td6XdB7wBuDUiGRWY0RsA7alz4clbSJptawpu/RwYA5Qat0cDNwr6QTgP4EnI+JZ4FlJ3wVeRjJOVHj9fb1s2Vq9lVOucrVo7/BpZt2gU1VqZ5CMv5wZEc+VHZ8pqSd9fhhwBPBw+bURsTEiXhARsyNiNkmSeXlE/D+S8ZzXSNojbQm9AnigLd9UA7JWArj0zGPonVG9DLpSqczZEz3NrFt0agznamAvYGXaSlmdVqSdBFwuaRTYAVwUEZsBJF0HXBMRazLuSUQ8IOlfgA3p9ddFxH2t/VYak2dDtfLWyrPbtldt9fTv07vz3Eb2yzEz6xSlvVnT2uDgYKxZk5nHmurEJauqrgw90N/H3YtOGXd8xdoRFt6wntGx3f879c4QS9/8Mj68bF3V1QgEPLLk95sUtZnZeJKGI2Iw7/leaaDNGl0JYGj+APvuOb4hOrojWHr7Q57oaWZdwwmnzSaSIH6ZUUjw0y1bPdHTzLqGE06bTSRB7LNn9b1yDurvY2j+AFeePTf3SgRmZp1ShImf00qtlQCqlTev+clmnv3N2Lj79MzQziTliZ5m1g1cNEB7iwayVCsO6O0RYzuCHVX+E7kowMw6rdGiAbdwCuKyW+8fV4lW+bqc/0wws27jMZyCyFpHrRZP7jSzbuKE08W8ooCZdRMnnILo7+uterzWQjfeOtrMuokTTkFUW0etd4bqjtV462gz6xZOOAUxNH+ApW9+2W7zaUqva/GKAmbWLVyl1mKNbB2QNZ+mfLHPciJZ/PPEJau8JYGZFZ5bOC3UjK0DhuYPcM6CgapjOaXuNm9JYGbdwAmnhWptHdCIux58ou5YjgsIzKzo3KXWQo2uDJ3V/Za3MMAFBGZWZE44LXRQf1/VvW+qDfTX2pgt6z557mtmVhTuUmuhRlaGrtX9Vu0+lbwlgZkVnVs4TVbZLXbOggHuevCJulVqWd1hI1u28tF/Ws9Y2SKrA/19nHz0zFz3NTMrCiecJqrWLbZ8eCTX/jS1us3GKlb0PvnomVwxNLc5QZuZtYm71JpoMlVpebrNSv7xB/8xofjMzDrJLZwmqtUtVq7WZNDy43lbPGZm3cAJp4mykoRIkkxpV8+sarTKlQYOX/zNzOQyZ9FtHrsxs65Ss0tN0q2Sbsl6tCvIbrHw9KMyVwQodas10u32tlcckvm1JrpygZlZp9Qbw/kc8HngEWAr8KX08QywqbWhdZ+h+QOZKwKUutsamQx6xdBc/vCVs+hR9iYFXmHAzLpFzS61iPgOgKTPV+xbfaukNS2NrEsN1Jns2chkUEiSTqkibc6i26omNK8wYGbdIG+V2r6SDiu9kDQH2Lc1IXW3epM9Tz56ZtXrso6X69+n+iZtWcfNzIokb9HAh4FvS3qYZAz8UODClkXVxapVm5UP7N/14BNVr8s6Xi6rOM1Fa2bWDXIlnIj4F0lHAEenhx6MiG2T+cKSlgJvBH5DMh50fkRskTQbeAAoDUysjoiLatznoyRjTTMj4heSfgv4B2AWyff3uYj428nE2qisfW2g9hhOvb1zfrl1tOq1WcfNzIokV5eapF7g/cAn08f70mOTsRI4NiKOA34ELC57b1NEzEsftZLNIcBpwGNlhz8A/DAiXga8Dvi8pD0nGWvT1OoWq9w758PL1nHJio07z8ka5/GinWbWDfJ2qX0R6AX+Kn39zvTYeyf6hSPijrKXq4FzJ3Cbq4CPATeX3xrYX5KA/YDNwPaJxjlR1VorAM/8enwovT0ignHl0gFcv/oxBg99PkPzB1h4+lHjdv/0op1m1i3yJpzj0xZDySpJ65sYxwXAsrLXcyStBZ4GLomI71VeIOksYCQi1mv3suGrgVuAnwL7A2+JiB1Vrr+QdBxq1qxZzfo+gOytBvbuncHojvEDLvvuuUdmt1hpDk95N13eLavNzIokb8IZk3R4RGwCSCvWxupcg6Q7gRdVeeviiLg5PedikhbI9el7jwOzIuJJSQuAFZKOiYiny+67D/AJku60SqcD64BTgMOBlZK+V349QERcC1wLMDg42NRh96zJnZXHSrbUGYMpH/epNT5kZlZkeRPOQuCuiiq18+tdFBGvr/W+pPOANwCnRiS1Vmkxwrb0+bCkTcCRQPm8n8OBOUCpdXMwcK+kE9K4lqT3+7GkR0iKHe7J+b1OWrPnxTQyRlOv8MDMrFPyVql9K61SKw0WPNSEKrUzSMZfXhsRz5UdnwlsjoixtCV1BPBwRTwbgReUXfMoMJhWqT0GnAp8T9IL05h3u77VsiZ39vf1sm37jsyWTjW9Pco9RlNvnTYzs05qtErtU+mjGVVqV5OMsayUtE7SNenxk4ANktYBNwAXRcTmNI7rJA1WvdsunwZeLWkj8C3g4xHxi0nG2pCsyZ+XnnkMV549l4H+vqprrlXVQGffZLZHMDNrNUWOWYOSriOpUvv79NA7gbGImHCVWpEMDg7GmjXNXaknT9fWiUtWZW5BUG6gv4+7F51S97yspW8EPLLk93NGbmaWj6ThimXPaipKldqUk2dwv1qZczV5x4QaXafNzKyd8q6lNibp8NKLvFVqVtvQ/IHdutiyVoXOmzDqreNmZtZJLa1Ss/rKW0KVg/7QWMLwPB0zK7JcYzgAkvaiiVVqRdKpMZxq55189EzuevCJmte59NnMiqBVYzgAC4DZ6TXzJBERX24wvmkhb3lytfOWD49w5dlzMxOIS5/Nutd0/2Mxb5XaV0gmW65j19hNRMR/b11o7dPsFk5W9VlltVnWedKuLQcO2KeXP33jMTt/KPPe28yKJavLvNYfmEXXqhbOIPDSyNv/Ns3l3UY667zyT/mp50ZZeENSEDg0f6ChLarNrDiy5sldduv906bVk7dK7T6qr4lmVeTdRiBv9dnoWOycvOktCsy6U9YfhU89N7rbtiSLb9zIirUj7Q2uTWomHEm3SroFOBD4oaTbJd1SerQnxO6Ttzy52nlZSj+sjZQ+r1g7wolLVjFn0W2cuGTVlP0hNusGef8onMqrg9TrUvtcW6KYYvKWJ1eeN0NiLKPXsvyHda89ZuxsmleO8ZS4uMCsWPJO9Iap20VeM+FExHfaFchUk3cbgcp5OAu/vn7cnjmlBTyrDTr+enTcVj9A7XXVnHDM2q/aH6JPPbuN56r8P5y1M3C3q5lwJH0/Il4j6VfsvoykSKrUntfS6KaZ0g/kpbfcv3OPnPIWzIlLVuVOIi4uMCueyj9E5112R9WEM1XLs+q1cF6T/rt/e8KZnipr8y89c3wXGTSWRLyumlnxZe30m3V8sjo9D6he0cDzaz3aFeRUVuomy1Ol0kiFmtdVMyu+dladNvK7plXqlUUPk+y0OVzl0dy1YKaprLGWDy1bN66yrJEkUrkw6EB/X1dPMDObitr5h2ER9suq16U2p12BTFe1xlQqK8saXZwzb+GCmXVGOxfcLcK4bq6VBiQJeAcwJyI+LWkW8KKIuKel0U0DWWMtJZVFAU4iZlNLM/+frjVGU4Rx3bwrDfwV8Crg7enrXwF/2ZKIppk8kz9dWWZm9dQboynCuG7ehPOKiPgA8GuAiHgK2LNlUU0jQ/MHOGfBANW3Xku4sszM6qk3RlOEcd28i3eOSuohnYsjaSZQfcahNeyuB58gq+zelWVmlkeeMZpOd8nnbeH8L+Am4AWSPgN8H/izlkU1zdTqMnNlmZnl0Q0L++Zt4dxAUgp9KskqA0PAz1oU07STNZg30N/nZGNmuVRbq61WD0knJoHmbeHcCGyKiL+MiKuBLcDKlkU1zRRhMM/MulsjYzSdmgSat4WzAvgnSecChwC3AH/SqqCmk9JfGVtHx+hJV4semOKbMJlZa+Qdo+nU4r65Ek5EfEnSniSJZzbw/oj415ZFNU1Urv48FrGzZeNkY2at0qlJoPXWUvtI6QHsDcwC1gGvTI/ZJDSyrI2ZWbN0qsCg3hjO/mWP/UjGcn5cdswmIc+yNk46ZtZsnRo3rreW2mWt+KKSlgJvBH4DbALOj4gtkmYDDwCl1eRWR8RFVa6/FHgf8ER66BMR8c30vcXAe4Ax4L9HxO2t+B5g8lUejS5rY2bWDO1cw61cvQ3YvhARH5J0K4yfmxgRZ07w664EFkfEdkmfBRYDH0/f2xQR83Lc46qI2G0LbEkvBd4KHAMcBNwp6ciIqL+na4OasYVzni1nvayNmbVCJyaB1isa+Er67+dqntWgiLij7OVq4Nwm3fos4GsRsQ14RNKPgROAf2vS/XdqRpVH+V8ZWS2dIk3aMjObjHpdasPpv99pYQwXAMvKXs+RtBZ4GrgkIr6Xcd0HJb2LZF+ej6bruw2QJLCS/0yPjSPpQuBCgFmzZjUcdLOqPEp/ZVS2mMBzccyKotM7ZU4V9brUNlKlK60kIo6rce2dwIuqvHVxRNycnnMxsB24Pn3vcWBWRDwpaQGwQtIxEfF0xT2+CHw6je3TwOdJElduEXEtcC3A4OBgwzuIN3up7071qZpZbRPtPneSGq9el9obJnrjiHh9rfclnZfe/9SIiPSabcC29PmwpE3AkVTsLhoRPyu7z5eAb6QvR0gmppYcnB5rukaXkcij0wvrmdl4E+k+b8YY71RUsyw6In5S+QDmlj2fEElnAB8DzoyI58qOz0xXpUbSYcARwMNVrn9x2cs3Afelz28B3ippL0lz0utbsklcaVuBHiUbC/RInLPACcNsqplI93me7ZxXrB3hxCWrmLPotmkz7y7v0jblLmdXi2Kirgb2AlYmm4nuLH8+Cbhc0ijJ9gcXRcRmAEnXAddExBrgzyXNI+lSexR4P0BE3C/pn4AfknTVfaAVFWqQ/LAsHx5hLGmcMRbB8uERBg99ftuTjpvuZq0zke7zeklquraAJpJwau0VlktEvCTj+HJgecZ77y17/s4a9/4M8JnJxlhPp9YiqjRdf3DN2mUi3ef1klRRfn+0W97Vosu9v+lRdKFOrUVUKU/T3cwmbiI7ZdabyV+U3x/tlquFI+nsitcHA78ENkbEz1sRWNE1u0ptoqbrD65ZOzVa0FOv6rR/n16eem503HX9+/Q2J+CCytul9h7gVcBd6evXkWzINkfS5RHxlawLp6pWVKlNRFESn5ntrlaSioyJGFnHp4q8CWcP4L+WypElvRD4MvAK4LvsWpFg2ijKvJmiJD4zq628uCcrr/xy6/hWz1SSN+EcUj73Bfh5emxzWlE2LVX7C6bdFWNFSXxmlq3aSiLVTPWeibwJ59uSvgF8PX19bnpsX5Ltpo3OVYx5wqhZsVUr7qk0HXom8lapfQD4W2Be+vh7kjkuz0bEya0Jrfu4YszMqqlVxJO38m0qyLvFdEj6Psn+NQHcU1qOxnZxxZiZVZNV3DPQ38fdi07pQESdkauFI+kPSJaIORf4A+AHkpq1pcCU0altW82s2E4+emZDx6eqvF1qFwPHR8S7I+JdJHvMfLJ1YXWnTm3bambFdteDTzR0fKrKWzQwo2KC55NMbJWCKc0VY2ZWjbvbE3kTzr9Iuh34x/T1W4Bvtiak7uaKMTOr1OgE7am6IG+uVkpELCTZrOy49HFtRHy8lYGZmU0VjXS3l6ZXjKQTREvTK6bC9gW5V4uutZKzNWaq/vViZtU10t0+lVeSrrfF9K+ovsW0SKqln9eSqKYwbydgNj3l7W6fyuM99Xb83D8inlflsb+TzcR4cqiZ1TKVp1e40qzNpvJfL2Y2eVN5esVEdvy0SfB2AmZWy2SmVxR9fNgJp828nYCZ1TOR6RXdMD7sLrU2m8h2tWZm9XTD+LBbOB3gyaFm1mzdMD7sFo6Z2RTQDdVtTjhmZlNAN1S3uUvNzAqn6NVWRZS3uq2Tn628jxoMDg7GmjVrOh2GmTG+2gqSpU3e8cpZXDE0t3OBTQHVPtu+3p4JFy5JGo6Iwbznu0vNzAqlWrVVANevfqypC1iuWDvCiUtWMWfRbZy4ZNWUWByznk5XsjnhmFmhZFVVBTTtF+OKtSMsvGH9bisyL7xh/ZRPOp2uZOtIwpG0VNKDkjZIuklSf3p8tqStktalj2syrr9U0kjZeb+XHv8dScOSNqb/Tp/Nws2miFpVVc36xXjZrfczOrb7cMLoWHDZrfc35f5F1elKtk61cFYCx0bEccCPgMVl722KiHnp46Ia97iq7LzSZnC/AN4YEXOBdwNfaUn0ZtYyC08/CmW816xfjE89N9rQ8ami05VsHalSi4g7yl6uBs5t0n3Xlr28H+iTtFdEbGvG/c2s9YbmD7DmJ5u5fvVju+2N0s5fjFO1Sm4y67Q1QxHKoi8AlpW9niNpLfA0cElEfC/jug9KehewBvhoRDxV8f45wL1ZyUbShcCFALNmzZpM/GbWZFcMzWXw0Oe37Bdjf18vW7aOb8309/V2xZpkjaiWPO9e1JnRhpaVRUu6E3hRlbcujoib03MuBgaBsyMiJO0F7BcRT0paAKwAjomIpyvu/UKS7rMAPg28OCIuKHv/GOAW4LSI2FQvVpdFm00vK9aOsPDr6xndsev3X+8MsfTNL2Pp7Q9VXdF9oL+vY7+oJ6rZZdCVGi2LblkLJyJeX+t9SecBbwBOjTTrpa2RbenzYUmbgCNJWjHl9/5Z2X2+BHyj7PXBwE3Au/IkGzObfiq7lvr36SUCPrxsXdUtjqFYa5LlVbTtqjtVpXYG8DHgzIh4ruz4TEk96fPDgCOAh6tc/+Kyl28C7kuP9wO3AYsi4u6WfQNm1vWG5g9w96JTuOot8/j16A62bB3NTDZQrDXJ8up0GXSlTlWpXQ3sD6ysKH8+CdggaR1wA3BRRGwGkHSdpFLT7c/T0ucNwMnAh9PjHwReAnyqrGT6BW36nsysC1VrBVQq2ppkeXW6DLpSp6rUXpJxfDmwPOO995Y9f2fGOVcAVzQjRjObHmr9tS9oSSVXu6rgirbhYxGq1MzMOiZr2/dWFQm0swqu02XQlZxwzGxaa3croN0D+UXa8NEJx8ymtXa3Aoo2kN9OTjhmNu21sxWQ1YXXjVVwjfJq0WZmbVRtPTMBJx89szMBtZETjplZGw3NH+CcBQO7LVAawPLhkSm/PYITjplZm9314BPjJpm2cyO0TnHCMTNrs+laOOCEY2bWZkVbAaBdnHDMzNrs5KNnjttkrluXz2mEE46ZWRutWDvC8uGR3cZwBJyzoDgTNFvFCcfMrI2qrTQQJIUEU50TjplZG03XggFwwjEza6vpWjAATjhmZm1VbaWB6VAwAF5LzcysrfIuFtquPXPayQnHzKzN6i0W2s49c9rJXWpmZgVTa8+cbuaEY2ZWMFO1ks0Jx8ysYKZqJZvHcMysq1yyYiNf/cFj7Ein6vf1zuDKs4/r6rGNSu3e9rpdnHDMrGtcsmIj/7D6sd2ObR3dwUeWrQPGD6h3a6VXu7e9bhdFVO7KMP0MDg7GmjVrOh2GmdVx+OJvMpbxO6tHYkfEzl/OQNVWwpVnz+36X9xFIWk4Igbznu8Wjpl1jaxkU/5eqYR4794ZmZVeTjid4YRjZl2jR6qZdEq2jo6NSzYlpUqvbu1u62auUjOzrvG2Vxwy6Xsc1N+3c2LlyJatBLtaRSvWjkw+SMvkhGNmXeOKobn84StnMaNy97Iq+vt6M9csm6oTK4uuI11qkpYCbwR+A2wCzo+ILZJmAw8Apf/qqyPioirXXwq8DyhtIPGJiPhm2fuzgB8Cl0bE51r1fZhZ+10xNJcrhubufF25DAwkieXSM48Bdq/0OvnomSy9/SFGpujEyqLr1BjOSmBxRGyX9FlgMfDx9L1NETEvxz2uqpFM/gL458mHaWZFV6+EuPRvtcRUqdsnVhZdRxJORNxR9nI1cG6z7i1pCHgEeLZZ9zSzYqu3GCZUX5+s3FSYWFl0RRjDuYDdWyNzJK2V9B1Jv13jug9K2iDpbyQdACBpP5KW0mUtjNfMulCt7rKB/j7Pz2mDliUcSXdKuq/K46yycy4GtgPXp4ceB2ZFxHzgI8BXJT2vyu2/CBwOzEuv+Xx6/FKSrrZncsR3oaQ1ktY88cTU30vcbLrL6i47YJ9e7l50ipNNG7Qs4UTE6yPi2CqPmwEknQe8AXhHpMsdRMS2iHgyfT5MUlBwZJV7/ywixiJiB/Al4IT0rVcAfy7pUeBDwCckfTAjvmsjYjAiBmfOnNnE79zMimjh6UfR2zO+vO2ZX293OXSbdKRLTdIZwMeAMyPiubLjMyX1pM8PA44AHq5y/YvLXr4JuA8gIn47ImZHxGzgC8CfRcTVrfo+zKx7DM0fYN89xw9bj+4Il0O3Saeq1K4G9gJWSoJd5c8nAZdLGgV2ABdFxGYASdcB10TEGpJWzDwggEeB97f9OzCzrvPLraNVj7scuj06VaX2kozjy4HlGe+9t+z5O3N8jUsnGp+ZTU0H9fdVnYPT6nJoL6OTKEKVmplZWyw8/ajM1Qdaxcvo7OKEY2bTxtD8Aa48ey4D/X2I9pRDexmdXbxatJlNK3kmiTZT1vjQdBw3cgvHzKyFssaHpuMyOk44ZmYtVG3+T2+PpuUyOk44ZmatVrlnXP095KYkJxwzsxZaevtDjO7YPcNM18mmTjhmZi3kooFdnHDMzFrIRQO7OOGYmbVQJyabFpXn4ZiZtVC9HUmnEyccM7MWa/dk06Jyl5qZmbWFE46ZmbWFE46ZmbWFE46ZmbWFE46ZmbWFIqbpoj5lJD0B/KTFX+ZA4Bct/hrN0k2xQnfF202xQnfF202xQnfFmxXroRExM+9NnHDaRNKaiBjsdBx5dFOs0F3xdlOs0F3xdlOs0F3xNitWd6mZmVlbOOGYmVlbOOG0z7WdDqAB3RQrdFe83RQrdFe83RQrdFe8TYnVYzhmZtYWbuGYmVlbOOGYmVlbOOFMgqRDJN0l6YeS7pf0P6qcc4CkmyRtkHSPpGPL3jtD0kOSfixpURfE+6ikjZLWSVrT4lj3Tr/++jTWy6qcs5ekZenn9wNJs8veW5wef0jS6a2MdbLxSpotaWv6ua6TdE0BYj1J0r2Stks6t+K9d0v6v+nj3a2MtUnxjpV9trcUINaPpP8PbpD0LUmHlr1XxM+2VryNfbYR4ccEH8CLgZenz/cHfgS8tOKcpcCfps+PBr6VPu8BNgGHAXsC6yuvLVK86etHgQPb9NkK2C993gv8AHhlxTn/Dbgmff5WYFn6/KXp57kXMCf9nHsKHO9s4L42/tzmiXU2cBzwZeDcsuPPBx5O/z0gfX5AUeNN33umYJ/tycA+6fM/Kvs5KOpnWzXeiXy2buFMQkQ8HhH3ps9/BTwAVG568VJgVXrOg8BsSS8ETgB+HBEPR8RvgK8BZxU43raKxDPpy970UVnhchbw9+nzG4BTJSk9/rWI2BYRjwA/Jvm8ixpvW+WJNSIejYgNwI6Ky08HVkbE5oh4ClgJnFHgeNsqZ6x3RcRz6cvVwMHp86J+tlnxNswJp0nS7pH5JH8hlFsPnJ2ecwJwKMl/sAHgP8rO+0/G//JvmQnEC8kP4h2ShiVd2IYYeyStA35O8j9iZaw7P8OI2A78EvgvdOiznUS8AHMkrZX0HUm/XYBYsxT1s61lb0lrJK2WNNSSAMs0GOt7gH9On3fDZ1seLzT42TrhNIGk/YDlwIci4umKt5cA/el/0D8G1gJj7Y1wd5OI9zUR8XLgd4EPSDqplXFGxFhEzCNJeCeobDypiCYR7+PArIiYD3wE+Kqk57UoTGBafbaQrPc1CLwd+IKkw1sRY0neWCX9ITBI0o3dMZOMt6HP1glnkiT1kvzyvj4ibqx8PyKejojz0/+g7wJmkvTNjgCHlJ16cHqsqPESESPpvz8HbqLF3VRlMW0B7mJ898LOz1DSHsBvAU/Soc+2pNF4066/J9Nrh0nGnI7scKxZivrZ1rqm9HP7MPBtkpZ9y9WKVdLrgYuBMyNiW3q4sJ9tRrwNf7ZOOJOQ9r//H+CBiPiLjHP6Je2Zvnwv8N20VfHvwBGS5qTvvxVodQXNhOOVtK+k/dNz9gVOA+5rYawzJfWnz/uA3wEerDjtFqBUyXMusCqSkcxbgLcqqQqbAxwB3NOqWCcbb3ptT3rtYWm8D3c41iy3A6cpqWY8gOTn4PaWBJqaTLxpnHulzw8ETgR+2KJQc8UqaT7w1yS/vH9e9lYhP9useCf02eapLPAjs8LjNSTjGhuAdenj94CLgIvSc15FUg32EHAjZVUn6bk/IvmL9uIix0tSTbc+fdzf6nhJKo7WprHeB3wqPX55+oMPsDfwdZKigHuAw8quvzj9XB8CfrcNn+2E4wXOST/TdcC9wBsLEOvxJGMIz5K0Gu8vu/6C9Hv4MXB+QT7bqvECrwY2pj+3G4H3FCDWO4Gflf0/eEvBP9uq8U7ks/XSNmZm1hbuUjMzs7ZwwjEzs7ZwwjEzs7ZwwjEzs7ZwwjEzs7ZwwjFj3Kq361S28nQD9xiS9NIWhDchks6TdFCn4zAr2aPTAZgVxNZIVleYjCHgGzQwsVDSHpGsq9YK55HMrfhpla/bExEdXWLJph+3cMwySFqQLqY5LOl2SS9Oj79P0r8r2UNkuaR9JL0aOBNYmraQDpf0bUmD6TUHSno0fX6epFskrQK+la7i8DdK9iVZK6nqquGSFqZfd4PSfUuU7KXzgKQvKdnP5A5JfUr2hBkErk/j6VOyn9FnJd0LvFnS25Tsb3SfpM+WfZ1nJF2V3u9b6Wz0w9PrSuccUf7aLA8nHLNEX1l32k3pmnP/m2RvlQXA3wCfSc+9MSKOj4iXkWzx8J6I+FeSpWsWRsS8iNhU5+u9PL33a0lWRVgVESeQ7D2yNF0+aCdJp5EseXMCMA9YoF2Lpx4B/GVEHANsAc6JiBuANcA70ni2puc+GckCrN8FPguckt7veO1a7XdfYE16v++Q7I+0CfilpHnpOecDf1vnezTbjbvUzBK7dakpWTH3WGBlsgQdPSSrOgMcK+kKoB/Yj4mtd7UyIjanz08DzpT0J+nrvYFZJMmMsnNOI1mGhPTrHgE8BjwSEevS48Mkm5FlWZb+ezzw7Yh4AkDS9cBJwAqSPWVK5/0DyRJHANcB50v6CPAW2rR4q00dTjhm1YlkPa5XVXnv74ChiFgv6TzgdRn32M6uXoS9K957tuJrnRMRD9WJ58qI+OvdDibFDdvKDo0BfTXu82yN97KU1r9aDvwpyQZ9w5GucG2Wl7vUzKp7CJgp6VWQbOsg6Zj0vf2Bx9Nut3eUXfOr9L2SR4EF6fNza3yt24E/VtqUSlfnrXbOBUr2MkLSgKQX1PkeKuMpdw/w2nRsqQd4G0n3GSS/F0rxvh34PkBE/DqN44u4O80mwAnHrIpItv0+F/ispPUkq+S+On37kyQ7pd7N7ku5fw1YmA78Hw58DvgjSWuBA2t8uU+TbO27QdL96evKeO4Avgr8m6SNJFtUZyWTkr8DrikVDVTc73FgEcn+J+tJWiw3p28/S7IR130kYzyXl116PUmX2x11vrbZOF4t2sx2I+mZiNgv470/AX4rIj7Z5rBsCvAYjpnlIukm4HCSVo9Zw9zCMTOztvAYjpmZtYUTjpmZtYUTjpmZtYUTjpmZtYUTjpmZtcX/ByvG4KUzEXK1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt = resultsdf.plot.scatter(x=\"entropy\",y=\"log-likelihood\")\n",
    "plt.scatter(resultsdf['entropy'],resultsdf['log-likelihood'])\n",
    "plt.xlabel(\"Feature entropy\")\n",
    "plt.ylabel(\"log-likelihood\")\n",
    "plt.autoscale()\n",
    "plt.savefig(\"clustergraph.png\",bbox_inches='tight',dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c3ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('clustergraph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6620d052",
   "metadata": {},
   "source": [
    "### We shall now apply K-means to identify the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b309e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = input(\"How many clusters?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b110ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=int(n))\n",
    "c_predicted = km.fit_predict(resultsdf[[\"log-likelihood\",\"entropy\"]])\n",
    "resultsdf[\"cluster\"]=c_predicted\n",
    "resultsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc95e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = resultsdf[resultsdf.cluster == 0]\n",
    "df2 = resultsdf[resultsdf.cluster == 1]\n",
    "\n",
    "plt.scatter(df1.entropy,df1[\"log-likelihood\"],color=\"blue\")\n",
    "plt.scatter(df2.entropy,df2[\"log-likelihood\"],color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35196a",
   "metadata": {},
   "source": [
    "### We now need to select the most accurate model from each of these clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f780ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.sort_values(by=['log-likelihood'])\n",
    "df2 = df2.sort_values(by=['log-likelihood'])\n",
    "\n",
    "#Lets create a list of models:\n",
    "\n",
    "models = []\n",
    "kernel = df1.iloc[0]['const']*RBF(df1.iloc[0]['length_scale'])\n",
    "gpc1 = GaussianProcessClassifier(kernel=kernel,optimizer=None).fit(X, Y)\n",
    "models.append(gpc1)\n",
    "kernel = df2.iloc[0]['const']*RBF(df2.iloc[0]['length_scale'])\n",
    "gpc2 = GaussianProcessClassifier(kernel=kernel,optimizer=None).fit(X, Y)\n",
    "models.append(gpc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b0221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the moment, we shall generate an explanation based on feature importance across the different clusters:\n",
    "\n",
    "\n",
    "tables = []\n",
    "\n",
    "for i in range(int(n)):\n",
    "    tables.append(pd.DataFrame({\"Features\":np.array(training_set.columns[2:37])}))\n",
    "\n",
    "\n",
    "for i in range(int(n)):\n",
    "    r = permutation_importance(models[i],X_test,y_test,n_repeats=30,random_state=0)\n",
    "    tables[i][\"Importances\"] = abs(r.importances_mean)\n",
    "    tables[i] = tables[i].sort_values(by=[\"Importances\"],ascending=False)\n",
    "    tables[i].reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "#for i in range(int(n)):\n",
    "    #r = permutation_importance(models[i],X_test,y_test,n_repeats=30,random_state=0)\n",
    "    #importance_table[\"Importances{}\".format(i)] = abs(r.importances_mean)\n",
    "    #importance_table = importance_table.sort_values(by=['Importances{}'.format(i)])\n",
    "\n",
    "#NOTE - I'm uneasy about using the same test sets as before, should I expand to the unknown jobs?\n",
    "\n",
    "importance_dict = {}\n",
    "for i in range(int(n)):\n",
    "    q = tables[i]\n",
    "    importance_dict[\"Importance{}\".format(i)] = q[\"Features\"]\n",
    "#q = tables[1]\n",
    "#importance_dict[\"Importance1\"] = q[\"Features\"]\n",
    "importance_table = pd.DataFrame(data=importance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a9c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(importance_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec713c4",
   "metadata": {},
   "source": [
    "### We now have a table of features sorted by how important they are for each cluster, based on the permutation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4994965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We shall generate one more table, which will have a row for each feature and a score for how important it is:\n",
    "\n",
    "final_importance_table = pd.DataFrame({\"Features\":np.array(training_set.columns[2:37]),\"Importance\":np.zeros(np.shape(training_set.columns[2]))})\n",
    "feature_list = final_importance_table['Features'].tolist()\n",
    "#final_importance_table.head()\n",
    "for i in feature_list:\n",
    "    for j in range(int(n)):\n",
    "        index_val = importance_table.index[importance_table[\"Importance{}\".format(j)]==i]\n",
    "        final_importance_table.loc[final_importance_table[\"Features\"]==i,\"Importance\"] += index_val.tolist()[0]\n",
    "    \n",
    "final_importance_table = final_importance_table.sort_values(by=[\"Importance\"],ascending=True)\n",
    "final_importance_table.reset_index(drop = True, inplace = True)\n",
    "final_importance_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e26c97",
   "metadata": {},
   "source": [
    "### We now have a table which ranks features by importance across all the clusters! Note that is values each cluster equally - this might be something we can improve upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1470c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets divert our attention towards making predictions on our unknown jobs:\n",
    "\n",
    "unknown_jobs = df4[df4.isna().any(axis=1)] #This is our set of unknown jobs\n",
    "#SCALE THE DATA! - Do I need to fit a new scaler?\n",
    "X = scaler.transform(unknown_jobs.iloc[:,2:37])\n",
    "#X = np.array(unknown_jobs.iloc[:,2:37])\n",
    "print(X)\n",
    "#for i in int(n):\n",
    "    #models[i].predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = gpc.predict_proba(X)\n",
    "test1 = gpc.predict(X)\n",
    "test2 = gpc.predict_proba(X)\n",
    "print(test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7555bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now fill in the dataframe:\n",
    "\n",
    "unknown_jobs[\"Auto label value\"] = test1\n",
    "unknown_jobs[\"Auto probability\"] = test2[:,1]\n",
    "unknown_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b143b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_jobs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a8b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets think about how we can apply the model from each of our clusters and compute an average:\n",
    "\n",
    "for i in range(int(n)):\n",
    "    probs = models[i].predict_proba(X)\n",
    "    unknown_jobs[\"Auto probability{}\".format(i)] = probs[:,1]\n",
    "\n",
    "#We need a list of column titles:\n",
    "column_titles = []\n",
    "for i in range(int(n)):\n",
    "    column_titles.append(\"Auto probability{}\".format(i))\n",
    "\n",
    "#Now calculate mean automotability    \n",
    "\n",
    "unknown_jobs[\"Auto probability\"] = unknown_jobs[column_titles].mean(axis=1)\n",
    "\n",
    "#And finally apply a function to determine auto-label value:\n",
    "\n",
    "def label_auto(my_input):\n",
    "    if my_input - 0.5 < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "unknown_jobs[\"Auto label value\"] = unknown_jobs[\"Auto probability\"].apply(label_auto)\n",
    "\n",
    "unknown_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d836b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unknown_jobs[\"Title\"][\"i\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f475056f",
   "metadata": {},
   "source": [
    "### We have now generated values for automotability!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
